{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f69be91b-2ff3-415d-9d3f-ee5d8afdac1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3deeacf-a80e-4852-b991-bc7ece7c833e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaaaa4c5-871d-4a4d-bab0-4b18ac8f4f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the Datasets\n",
    "filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "# Building information\n",
    "b_1 = pd.read_csv(filepath + 'Building_1.csv')\n",
    "b_2 = pd.read_csv(filepath + 'Building_2.csv')\n",
    "b_3 = pd.read_csv(filepath + 'Building_3.csv')\n",
    "\n",
    "# Other information\n",
    "carbon_int = pd.read_csv(filepath + 'carbon_intensity.csv')\n",
    "pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "# Building level combine the dfs\n",
    "comb_b_1 = pd.concat([b_1.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_2 = pd.concat([b_2.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_3 = pd.concat([b_3.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Make a list of the buildings\n",
    "b_list = [comb_b_1,comb_b_2,comb_b_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9375f433-049f-4bef-bd38-7f04176885c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataframes contain inf\n",
    "\n",
    "# Building 1\n",
    "d = np.isfinite(comb_b_1) \n",
    "\n",
    "# Building 2\n",
    "d = np.isfinite(comb_b_2) \n",
    "\n",
    "\n",
    "# Building 3\n",
    "d = np.isfinite(comb_b_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86ddbdb-0110-437c-ac53-65d2eddc65de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the titles\n",
    "b_list_clear = []\n",
    "\n",
    "for b in b_list:\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    b.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in b.columns.values]\n",
    "    b_list_clear.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7414601-9b7a-4173-b2d9-e0ffc395c892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3c530e-34c0-4a9e-ac13-f4f78e2c18af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost Models\n",
    "\n",
    "def XGBoost_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50,\n",
    "           verbose=False)\n",
    "     \n",
    "    y_pred  = reg.predict(X_test)\n",
    "    \n",
    "    # Generate the df\n",
    "    df = pd.DataFrame(\n",
    "        {'Actual Value': y_test,\n",
    "        'Predicted Value': y_pred\n",
    "        })\n",
    "\n",
    "    return df, reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a84c794-ae07-4b51-9b8c-5c6722394b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM Models\n",
    "\n",
    "# Generating the LightGBM\n",
    "\n",
    "def LightGBM_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_mean  = grid_search_mean.predict(X_test)\n",
    "    \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred_mean\n",
    "            })\n",
    "     \n",
    "        return df, grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred\n",
    "            })\n",
    "     \n",
    "        return df, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f207434d-97f7-4cd8-bda9-238301ce8514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429e4788-f351-4756-a93f-7829aaebe1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.) Cooling Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Cooling_Load__kWh_.csv')\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Cooling Load (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/cooling_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,False)\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_load_model_b'+str(i)+'.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/cooling_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27452a-1127-41fc-a893-6c5d95c34309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.) DHW Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['DHW Heating (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/dhw_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_load_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/dhw_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a83cc-268d-4cb1-9877-775741ed0c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Equipment Electric Power (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['Equipment Electric Power (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2834e4-4804-489c-a3d6-af83d8d552e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neighbour Level: Carbon Intensity (kgCO2e/kWh) ; Solar Generation (W/kW)\n",
    "\n",
    "# 1.) Carbon Intensity (kgCO2e/kWh)\n",
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_list_clear[0].reset_index(drop=True),\n",
    "                  b_list_clear[1].reset_index(drop=True),\n",
    "                  b_list_clear[2].reset_index(drop=True)])\n",
    "    \n",
    "# Generate the x,y\n",
    "X = comb\n",
    "y = comb['kg_CO2/kWh']\n",
    "\n",
    "# Generate the test,train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "    xgb.save_model('my_models/models/Carbon_Intensity_Power_model'+str(i)+'.json')\n",
    "if model_type == 'lgb':\n",
    "    df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_hyper.pkl')\n",
    "    #lgb.booster_.save_model('my_models/models/Carbon_Intensity_Power_model_hyper.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97252705-78b9-47eb-9f8c-9d43ea70974a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Solar Generation (W/kW)\n",
    "sg = []\n",
    "i = 1\n",
    "\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Solar_Generation__W_kW_.csv')\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Solar Generation (W/kW)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/solar_generation_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/solar_generation_model_b'+str(i)+'_hyper.txt')\n",
    "        \n",
    "    sg.append(df)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f803d1-2147-441d-b81e-e6ba3d3eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0602038-da7f-431b-953b-1bb651df694d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a9782-0f28-4740-9d24-b77843561a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8db2cc-8054-4ea2-8220-43de2b430118",
   "metadata": {},
   "source": [
    "### FastAI Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d1e86d-7f6e-4785-b153-8e2076cd67ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timeseries_fastai.imports import *\n",
    "from timeseries_fastai.core import *\n",
    "from timeseries_fastai.data import *\n",
    "from timeseries_fastai.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccaa2e8a-9daa-49f7-9d8b-09c75569eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: /home/philaupk/work/CityLearn_Competition/Adiac\n",
      "Error loading files: /home/philaupk/work/CityLearn_Competition/Adiac\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m----> 2\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m load_df_ucr(PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdiac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m x_cols \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      4\u001b[0m dls \u001b[38;5;241m=\u001b[39m TSDataLoaders\u001b[38;5;241m.\u001b[39mfrom_dfs(df_train, df_test, x_cols\u001b[38;5;241m=\u001b[39mx_cols, label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "PATH = Path.cwd().parent\n",
    "df_train, df_test = load_df_ucr(PATH, 'Adiac')\n",
    "x_cols = df_train.columns[0:-2].to_list()\n",
    "dls = TSDataLoaders.from_dfs(df_train, df_test, x_cols=x_cols, label_col='target', bs=16)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc490-672a-43ce-b598-361aa5c0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = create_inception(1, len(dls.vocab))\n",
    "learn = Learner(dls, inception, metrics=[accuracy])\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dce875-c3b2-4d0b-8b88-c7a87fec0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919da4-085e-44d0-b2f9-1b6f3d1bf51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5842d6-363b-443a-ad1c-cc973ad2b05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397b1b9-30db-4028-ba4b-dea174caa9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a0d31-ec58-4b17-acdc-d2dc49df840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e06583-710d-4df3-9965-ec642b22c929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e28d1-5254-4e21-b7c4-7fb38d71a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe233854-bf7d-4a80-bfed-81810000b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73419dd6-584b-4e11-8484-0d6ff286ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af48f-cc40-4dec-b919-0d7a9a270b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74af4548-880e-487b-a639-d613ba14caa1",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba062f91-4daa-4f65-ad4a-b028f0f7030e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "\n",
    "# Save the important features into files\n",
    "b = 1\n",
    "for data in b_list_clear:\n",
    "    feature_selection(data,'Cooling Load (kWh)')\n",
    "    feature_selection(data,'DHW Heating (kWh)')\n",
    "    feature_selection(data,'Equipment Electric Power (kWh)')\n",
    "    feature_selection(data,'kg_CO2/kWh')\n",
    "    feature_selection(data,'Solar Generation (W/kW)')\n",
    "    b = b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a165a-d411-4cc4-9cc1-74e999435b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b74d9ad-c656-4b1a-be5e-edfaf2842d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_selection(data,obs_feature):\n",
    "    # Split the dataset into features and target\n",
    "    X = data\n",
    "    y = data[obs_feature]\n",
    "    \n",
    "    # Apply Information Gain\n",
    "    ig = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create a dictionary of feature importance scores\n",
    "    feature_scores = {}\n",
    "    i = 0\n",
    "    for (columnName, columnData) in data.items():\n",
    "        feature_scores[columnName] = ig[i]\n",
    "        i = i + 1\n",
    "    # Sort the features by importance score in descending order\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    f_l = []\n",
    "    s_l = []\n",
    "    a_l = []\n",
    "    a_l_s = []\n",
    "    # Print the feature importance scores and the sorted features\n",
    "    for feature, score in sorted_features:\n",
    "        a_l.append(feature)\n",
    "        a_l_s.append(score)\n",
    "        if score > 0.10:\n",
    "            # save the features\n",
    "            f_l.append(feature)\n",
    "            s_l.append(score)\n",
    "            \n",
    "    dic = {'feature': f_l, 'score': s_l}\n",
    "    dic_a = {'feature': a_l, 'score': a_l_s}\n",
    "    df2 = pd.DataFrame(dic_a)\n",
    "    df = pd.DataFrame(dic)\n",
    "    obs_feature = obs_feature.replace(\" \", \"_\")\n",
    "    obs_feature = obs_feature.replace(\")\", \"_\")\n",
    "    obs_feature = obs_feature.replace(\"(\", \"_\")\n",
    "    obs_feature = obs_feature.replace(\"/\", \"_\")\n",
    "    df.to_csv('data/features/feature_importance_'+str(obs_feature)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e102-9041-4e76-8998-35445f86f858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8f249-46ad-40a5-a2c1-d9224ff76963",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071c164-b5b6-4eae-910f-081322985fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5489a18-4f56-45ac-b34d-2cf9bf6bb33f",
   "metadata": {},
   "source": [
    "## Simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672dd57-9e48-4af8-8863-a778593fd022",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from my_models.user_model import SubmissionModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05333283-0a9d-4ca3-ae1c-6ce1378e18a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a test env\n",
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0049ca9f-53b0-417c-9f3b-13293825d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_citylearn_env(config):\n",
    "    env = CityLearnEnv(config.SCHEMA)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = env.time_steps,\n",
    "        buildings_metadata = env.get_metadata()['buildings'],\n",
    "        num_buildings = len(env.buildings),\n",
    "        building_names = [b.name for b in env.buildings],\n",
    "        b0_pv_capacity = env.buildings[0].pv.nominal_power,\n",
    "    )\n",
    "\n",
    "    # Turn off actions for all buildings and do not simulate power outage (forecasting only).\n",
    "    for b in env.buildings:\n",
    "        b.ignore_dynamics = True\n",
    "        b.simulate_power_outage = False\n",
    "\n",
    "    return env, env_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fe70e10-5cce-4035-8bd9-7486201d83b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = './data/'\n",
    "    SCHEMA = os.path.join(data_dir, 'schemas/warm_up/schema.json')\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adf5221e-57fb-44ee-85b0-1fa6605e63b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env, env_data = create_citylearn_env(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15054c39-c5e2-477f-93fa-0a22f69b6242",
   "metadata": {},
   "source": [
    "## Generation of the Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1783afd-efc0-4205-aa31-3bda2673da08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "\n",
    "b_1_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point'])\n",
    "\n",
    "b_2_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point'])\n",
    "\n",
    "b_3_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point'])\n",
    "\n",
    "b_dataframe_list = [b_1_dataframe,b_2_dataframe,b_3_dataframe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0db48ddf-2417-4ca8-9663-70c05a33e7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Datasets for the different buildings:\n",
    "# Here I only need to simulate the ones, which are not present in the dataset:\n",
    "import pandas as pd\n",
    "\n",
    "for idx, b in enumerate(env.buildings):\n",
    "    indoor_dry_bulb_temperature           = b.energy_simulation.indoor_dry_bulb_temperature[env.time_step:env.time_step+720]\n",
    "    non_shiftable_load                    = b.energy_simulation.non_shiftable_load[env.time_step:env.time_step+720]\n",
    "    solar_generation                      = b.energy_simulation.solar_generation[env.time_step:env.time_step+720]\n",
    "    dhw_storage_soc                       = b.dhw_storage.soc[env.time_step:env.time_step+720]\n",
    "    electrical_storage_soc                = b.electrical_storage.soc[env.time_step:env.time_step+720]\n",
    "    cooling_demand                        = b.energy_simulation.cooling_demand[env.time_step:env.time_step+720]\n",
    "    dhw_demand                            = b.energy_simulation.dhw_demand[env.time_step:env.time_step+720]\n",
    "    indoor_dry_bulb_temperature_set_point = b.energy_simulation.indoor_dry_bulb_temperature_set_point[env.time_step:env.time_step+720]\n",
    "    \n",
    "    # After the generation of the different features I will add the global features (which are independend from the houses!)\n",
    "    day_type         = env.buildings[0].energy_simulation.day_type[env.time_step:env.time_step+720]\n",
    "    hour             = env.buildings[0].energy_simulation.hour[env.time_step:env.time_step+720]\n",
    "    carbon_intensity = env.buildings[0].carbon_intensity.carbon_intensity[env.time_step:env.time_step+720]\n",
    "\n",
    "    # Loading the local features\n",
    "    filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "    pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "    weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "    electricity_pricing                = pricing['Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_6h   = pricing['6h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_12h  = pricing['12h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_24h  = pricing['24h Prediction Electricity Pricing [$/kWh]']\n",
    "\n",
    "    outdoor_dry_bulb_temperature                = weather['Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_6h   = weather['6h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_12h  = weather['12h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_24h  = weather['24h Outdoor Drybulb Temperature (C)']\n",
    "\n",
    "    diffuse_solar_irradiance                    = weather['Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_6h       = weather['6h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_12h      = weather['12h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_24h      = weather['24h Diffuse Solar Radiation (W/m2)']\n",
    "\n",
    "    direct_solar_irradiance                     = weather['Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_6h        = weather['6h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_12h       = weather['12h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_24h       = weather['24h Direct Solar Radiation (W/m2)']\n",
    "    \n",
    "    # Generate the Dataframe for the training\n",
    "    b_dataframe_list[idx]['day_type']                                   = day_type\n",
    "    b_dataframe_list[idx]['hour']                                       = hour\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature']               = outdoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_6h']  = outdoor_dry_bulb_temperature_predicted_6h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_12h'] = outdoor_dry_bulb_temperature_predicted_12h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_24h'] = outdoor_dry_bulb_temperature_predicted_24h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance']                   = diffuse_solar_irradiance\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_6h']      = diffuse_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_12h']     = diffuse_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_24h']     = diffuse_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance']                    = direct_solar_irradiance\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_6h']       = direct_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_12h']      = direct_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_24h']      = direct_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['carbon_intensity']                           = carbon_intensity\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature']                = indoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['non_shiftable_load']                         = non_shiftable_load\n",
    "    b_dataframe_list[idx]['solar_generation']                           = solar_generation\n",
    "    b_dataframe_list[idx]['dhw_storage_soc']                            = dhw_storage_soc\n",
    "    b_dataframe_list[idx]['electrical_storage_soc']                     = electrical_storage_soc\n",
    "    b_dataframe_list[idx]['electricity_pricing']                        = electricity_pricing\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_6h']           = electricity_pricing_predicted_6h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_12h']          = electricity_pricing_predicted_12h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_24h']          = electricity_pricing_predicted_24h\n",
    "    b_dataframe_list[idx]['cooling_demand']                             = cooling_demand\n",
    "    b_dataframe_list[idx]['dhw_demand']                                 = dhw_demand\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature_set_point']      = indoor_dry_bulb_temperature_set_point\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627e12f6-233f-45ff-9d86-fc99b2349b13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ae84e00c-1958-4f58-9c60-8de58a0e39e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the Predictors (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b41fd673-11e2-4f20-a660-fb36934ccd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'lgb'\n",
    "hyperparameter = 'False'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0382c-bd19-474a-b753-fa3e54dbeb9f",
   "metadata": {},
   "source": [
    "## Building Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a8265-0e7c-4c65-836c-6bb7a55701e1",
   "metadata": {},
   "source": [
    "### 1.) Cooling Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "45da7752-a409-4bf3-a5ed-fc0d82380079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['cooling_demand']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        xgb.save_model('my_models/models/cooling_load_model_b'+str(i)+'_new.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_load_model_b'+str(i)+'_new.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5d417-bec7-49b8-8f1a-2b30b199bbf1",
   "metadata": {},
   "source": [
    "### 2.) DHW Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e2291829-e34d-491d-a21f-9f6b8c981d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['dhw_demand']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        xgb.save_model('my_models/models/dhw_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_load_model_b'+str(i)+'_new.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f10a61-a65d-4a70-ad5f-01f02f0a2049",
   "metadata": {},
   "source": [
    "### 3.) Equipment Electric Power (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a4ecb764-a3e2-4266-a1ae-1da596ce021f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['non_shiftable_load']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        xgb.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_new.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5143b8-6eb1-424a-975f-434b42934d7c",
   "metadata": {},
   "source": [
    "# Neighbourhood Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6668b0-ba09-47d6-84f6-a4b392d12377",
   "metadata": {},
   "source": [
    "### 1.) Carbon Intensity (kgCO2e/kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "836e4946-9e37-4a24-83a7-9ea2b756110e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_dataframe_list[0].reset_index(drop=True),\n",
    "                  b_dataframe_list[1].reset_index(drop=True),\n",
    "                  b_dataframe_list[2].reset_index(drop=True)])\n",
    "    \n",
    "# Generate the x,y\n",
    "X = comb\n",
    "y = comb['carbon_intensity']\n",
    "\n",
    "# Generate the test,train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "    xgb.save_model('my_models/models/Carbon_Intensity_Power_model'+str(i)+'.json')\n",
    "if model_type == 'lgb':\n",
    "    df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_new.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99ab8e-9d57-4554-96b5-6f69cc0041f3",
   "metadata": {},
   "source": [
    "### 2.) Solar Generation (W/kW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2d128e16-9ebc-4318-864e-53f440826011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['solar_generation']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        xgb.save_model('my_models/models/solar_generation_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,hyperparameter)\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_new.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ab787-e32b-46d3-85ae-62dac941cd32",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2dbe62f7-aa7c-4b50-88d1-7911ef439a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM Models\n",
    "\n",
    "def LightGBM_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_mean  = grid_search_mean.predict(X_test)\n",
    "    \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred_mean\n",
    "            })\n",
    "     \n",
    "        return df, grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        'verbose':-1,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred\n",
    "            })\n",
    "     \n",
    "        return df, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1069a8-60aa-44ec-9c7f-dbd6588ecb5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0110207f-f746-4ebb-93b5-e62e1e6b7a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96430fdc-557d-4e7f-9995-3c6ad418da3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024ea8fa-812f-4f1e-b0c0-ae8886e8c379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b38e0e-c673-41fe-8a97-b1890cc25c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6c123-ac24-4957-b317-74a0d5ec6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ce45e-3ec4-4765-a8da-5568a4e5aabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f4244-379d-4021-bd9a-dd69ce80ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ba147-6d10-4b20-8cb5-56cb16f6cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560235de-5577-4919-bdf6-1021ef6f79e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b85efd-8c1a-43bb-82a3-9d1ca6e195fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc2b52-6236-4670-89da-86023cbed3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cb36f-9613-48eb-90be-cffe73c682b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0fd6a-fc08-4de4-9682-9cc373d5a018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fa69f-e93f-427d-bee1-d415a68da321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725c757-8501-4b1e-b9cc-b9e71372a9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23a7dadc-c47c-4303-9efb-9f029854f3e1",
   "metadata": {},
   "source": [
    "# Testing the Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "2953445d-1ebc-48ba-8d0c-c5423315ed9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import GroupKFold\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import joblib\n",
    "from difflib import SequenceMatcher\n",
    "\n",
    "\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_pinball_loss\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "\n",
    "from my_models.base_predictor_model import BasePredictorModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0a531-5522-4c3a-a99f-fb61b9d50d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
