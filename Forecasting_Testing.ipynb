{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaaa4c5-871d-4a4d-bab0-4b18ac8f4f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the Datasets\n",
    "filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "# Building information\n",
    "b_1 = pd.read_csv(filepath + 'Building_1.csv')\n",
    "b_2 = pd.read_csv(filepath + 'Building_2.csv')\n",
    "b_3 = pd.read_csv(filepath + 'Building_3.csv')\n",
    "\n",
    "# Other information\n",
    "carbon_int = pd.read_csv(filepath + 'carbon_intensity.csv')\n",
    "pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "# Building level combine the dfs\n",
    "comb_b_1 = pd.concat([b_1.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_2 = pd.concat([b_2.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_3 = pd.concat([b_3.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Make a list of the buildings\n",
    "b_list = [comb_b_1,comb_b_2,comb_b_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375f433-049f-4bef-bd38-7f04176885c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataframes contain inf\n",
    "\n",
    "# Building 1\n",
    "d = np.isfinite(comb_b_1) \n",
    "\n",
    "# Building 2\n",
    "d = np.isfinite(comb_b_2) \n",
    "\n",
    "\n",
    "# Building 3\n",
    "d = np.isfinite(comb_b_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ddbdb-0110-437c-ac53-65d2eddc65de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the titles\n",
    "b_list_clear = []\n",
    "\n",
    "for b in b_list:\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    b.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in b.columns.values]\n",
    "    b_list_clear.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7414601-9b7a-4173-b2d9-e0ffc395c892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c530e-34c0-4a9e-ac13-f4f78e2c18af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost Models\n",
    "\n",
    "def XGBoost_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50,\n",
    "           verbose=False)\n",
    "     \n",
    "    y_pred  = reg.predict(X_test)\n",
    "    \n",
    "    # Generate the df\n",
    "    df = pd.DataFrame(\n",
    "        {'Actual Value': y_test,\n",
    "        'Predicted Value': y_pred\n",
    "        })\n",
    "\n",
    "    return df, reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84c794-ae07-4b51-9b8c-5c6722394b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM Models\n",
    "\n",
    "# Generating the LightGBM\n",
    "\n",
    "def LightGBM_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_mean  = grid_search_mean.predict(X_test)\n",
    "    \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred_mean\n",
    "            })\n",
    "     \n",
    "        return df, grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred\n",
    "            })\n",
    "     \n",
    "        return df, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207434d-97f7-4cd8-bda9-238301ce8514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e4788-f351-4756-a93f-7829aaebe1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.) Cooling Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Cooling_Load__kWh_.csv')\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Cooling Load (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/cooling_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,False)\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_load_model_b'+str(i)+'.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/cooling_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27452a-1127-41fc-a893-6c5d95c34309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.) DHW Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['DHW Heating (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/dhw_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_load_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/dhw_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a83cc-268d-4cb1-9877-775741ed0c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Equipment Electric Power (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['Equipment Electric Power (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2834e4-4804-489c-a3d6-af83d8d552e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neighbour Level: Carbon Intensity (kgCO2e/kWh) ; Solar Generation (W/kW)\n",
    "\n",
    "# 1.) Carbon Intensity (kgCO2e/kWh)\n",
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_list_clear[0].reset_index(drop=True),\n",
    "                  b_list_clear[1].reset_index(drop=True),\n",
    "                  b_list_clear[2].reset_index(drop=True)])\n",
    "    \n",
    "# Generate the x,y\n",
    "X = comb\n",
    "y = comb['kg_CO2/kWh']\n",
    "\n",
    "# Generate the test,train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "    xgb.save_model('my_models/models/Carbon_Intensity_Power_model'+str(i)+'.json')\n",
    "if model_type == 'lgb':\n",
    "    df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_hyper.pkl')\n",
    "    #lgb.booster_.save_model('my_models/models/Carbon_Intensity_Power_model_hyper.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97252705-78b9-47eb-9f8c-9d43ea70974a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Solar Generation (W/kW)\n",
    "sg = []\n",
    "i = 1\n",
    "\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Solar_Generation__W_kW_.csv')\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Solar Generation (W/kW)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/solar_generation_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/solar_generation_model_b'+str(i)+'_hyper.txt')\n",
    "        \n",
    "    sg.append(df)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f803d1-2147-441d-b81e-e6ba3d3eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0602038-da7f-431b-953b-1bb651df694d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a9782-0f28-4740-9d24-b77843561a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8db2cc-8054-4ea2-8220-43de2b430118",
   "metadata": {},
   "source": [
    "### FastAI Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1e86d-7f6e-4785-b153-8e2076cd67ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timeseries_fastai.imports import *\n",
    "from timeseries_fastai.core import *\n",
    "from timeseries_fastai.data import *\n",
    "from timeseries_fastai.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa2e8a-9daa-49f7-9d8b-09c75569eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = Path.cwd().parent\n",
    "df_train, df_test = load_df_ucr(PATH, 'Adiac')\n",
    "x_cols = df_train.columns[0:-2].to_list()\n",
    "dls = TSDataLoaders.from_dfs(df_train, df_test, x_cols=x_cols, label_col='target', bs=16)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc490-672a-43ce-b598-361aa5c0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = create_inception(1, len(dls.vocab))\n",
    "learn = Learner(dls, inception, metrics=[accuracy])\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dce875-c3b2-4d0b-8b88-c7a87fec0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919da4-085e-44d0-b2f9-1b6f3d1bf51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5842d6-363b-443a-ad1c-cc973ad2b05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397b1b9-30db-4028-ba4b-dea174caa9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a0d31-ec58-4b17-acdc-d2dc49df840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e06583-710d-4df3-9965-ec642b22c929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e28d1-5254-4e21-b7c4-7fb38d71a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe233854-bf7d-4a80-bfed-81810000b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73419dd6-584b-4e11-8484-0d6ff286ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af48f-cc40-4dec-b919-0d7a9a270b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74af4548-880e-487b-a639-d613ba14caa1",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba062f91-4daa-4f65-ad4a-b028f0f7030e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a165a-d411-4cc4-9cc1-74e999435b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74d9ad-c656-4b1a-be5e-edfaf2842d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e102-9041-4e76-8998-35445f86f858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a114b7b5-58cd-4a68-b82c-766a76667c46",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4071c164-b5b6-4eae-910f-081322985fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/p37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-23 22:29:35.905046: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 22:29:35.905313: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 22:29:35.905336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install category_encoders\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from my_models.user_model import SubmissionModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5489a18-4f56-45ac-b34d-2cf9bf6bb33f",
   "metadata": {},
   "source": [
    "## Simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05333283-0a9d-4ca3-ae1c-6ce1378e18a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a test env\n",
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0049ca9f-53b0-417c-9f3b-13293825d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_citylearn_env(config):\n",
    "    env = CityLearnEnv(config.SCHEMA)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = 720,\n",
    "        buildings_metadata = env.get_metadata()['buildings'],\n",
    "        num_buildings = len(env.buildings),\n",
    "        building_names = [b.name for b in env.buildings],\n",
    "        b0_pv_capacity = env.buildings[0].pv.nominal_power,\n",
    "    )\n",
    "\n",
    "    # Turn off actions for all buildings and do not simulate power outage (forecasting only).\n",
    "    for b in env.buildings:\n",
    "        b.ignore_dynamics = True\n",
    "        b.simulate_power_outage = False\n",
    "\n",
    "    return env, env_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fe70e10-5cce-4035-8bd9-7486201d83b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = './data/'\n",
    "    SCHEMA = os.path.join(data_dir, 'schemas/warm_up/schema.json')\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf5221e-57fb-44ee-85b0-1fa6605e63b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env, env_data = create_citylearn_env(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15054c39-c5e2-477f-93fa-0a22f69b6242",
   "metadata": {},
   "source": [
    "## Generation of the Features\n",
    "\n",
    "\n",
    "TODO: Add the other features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1783afd-efc0-4205-aa31-3bda2673da08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "\n",
    "b_1_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_2_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_3_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_dataframe_list = [b_1_dataframe,b_2_dataframe,b_3_dataframe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c42120-ce5a-46d1-af63-a279e2425823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67788136], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, b in enumerate(env.buildings):\n",
    "    \n",
    "    con = b.net_electricity_consumption\n",
    "    print(str(len(con)))\n",
    "    \n",
    "env.buildings[0].net_electricity_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0db48ddf-2417-4ca8-9663-70c05a33e7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Datasets for the different buildings:\n",
    "# Here I only need to simulate the ones, which are not present in the dataset:\n",
    "\n",
    "for idx, b in enumerate(env.buildings):\n",
    "    indoor_dry_bulb_temperature           = b.energy_simulation.indoor_dry_bulb_temperature\n",
    "    non_shiftable_load                    = b.energy_simulation.non_shiftable_load\n",
    "    solar_generation                      = b.energy_simulation.solar_generation\n",
    "    dhw_storage_soc                       = b.dhw_storage.soc\n",
    "    electrical_storage_soc                = b.electrical_storage.soc\n",
    "    cooling_demand                        = b.energy_simulation.cooling_demand\n",
    "    dhw_demand                            = b.energy_simulation.dhw_demand\n",
    "    indoor_dry_bulb_temperature_set_point = b.energy_simulation.indoor_dry_bulb_temperature_set_point\n",
    "    occupant_count                        = b.occupant_count.repeat(720)\n",
    "    net_electricity_consumption           = b.net_electricity_consumption.repeat(720)\n",
    "    \n",
    "    # After the generation of the different features I will add the global features (which are independend from the houses!)\n",
    "    day_type         = env.buildings[0].energy_simulation.day_type\n",
    "    hour             = env.buildings[0].energy_simulation.hour\n",
    "    carbon_intensity = env.buildings[0].carbon_intensity.carbon_intensity\n",
    "\n",
    "    # Loading the local features\n",
    "    filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "    pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "    weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "    electricity_pricing                = pricing['Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_6h   = pricing['6h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_12h  = pricing['12h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_24h  = pricing['24h Prediction Electricity Pricing [$/kWh]']\n",
    "\n",
    "    outdoor_dry_bulb_temperature                = weather['Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_6h   = weather['6h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_12h  = weather['12h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_24h  = weather['24h Outdoor Drybulb Temperature (C)']\n",
    "\n",
    "    diffuse_solar_irradiance                    = weather['Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_6h       = weather['6h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_12h      = weather['12h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_24h      = weather['24h Diffuse Solar Radiation (W/m2)']\n",
    "\n",
    "    direct_solar_irradiance                     = weather['Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_6h        = weather['6h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_12h       = weather['12h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_24h       = weather['24h Direct Solar Radiation (W/m2)']\n",
    "    \n",
    "    # Generate the Dataframe for the training\n",
    "    b_dataframe_list[idx]['day_type']                                   = day_type\n",
    "    b_dataframe_list[idx]['hour']                                       = hour\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature']               = outdoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_6h']  = outdoor_dry_bulb_temperature_predicted_6h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_12h'] = outdoor_dry_bulb_temperature_predicted_12h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_24h'] = outdoor_dry_bulb_temperature_predicted_24h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance']                   = diffuse_solar_irradiance\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_6h']      = diffuse_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_12h']     = diffuse_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_24h']     = diffuse_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance']                    = direct_solar_irradiance\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_6h']       = direct_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_12h']      = direct_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_24h']      = direct_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['carbon_intensity']                           = carbon_intensity\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature']                = indoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['non_shiftable_load']                         = non_shiftable_load\n",
    "    b_dataframe_list[idx]['solar_generation']                           = solar_generation\n",
    "    b_dataframe_list[idx]['dhw_storage_soc']                            = dhw_storage_soc\n",
    "    b_dataframe_list[idx]['electrical_storage_soc']                     = electrical_storage_soc\n",
    "    b_dataframe_list[idx]['electricity_pricing']                        = electricity_pricing\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_6h']           = electricity_pricing_predicted_6h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_12h']          = electricity_pricing_predicted_12h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_24h']          = electricity_pricing_predicted_24h\n",
    "    b_dataframe_list[idx]['cooling_demand']                             = cooling_demand\n",
    "    b_dataframe_list[idx]['dhw_demand']                                 = dhw_demand\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature_set_point']      = indoor_dry_bulb_temperature_set_point\n",
    "    b_dataframe_list[idx]['occupant_count']                             = occupant_count\n",
    "    b_dataframe_list[idx]['net_electricity_consumption']                = net_electricity_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36edbc-8963-4cf9-853e-c087c493193c",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402aa4b-066a-4024-806a-f07878d5f764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the important features into files\n",
    "b = 1\n",
    "for data in b_dataframe_list:\n",
    "    feature_selection(data,'cooling_demand')\n",
    "    feature_selection(data,'dhw_demand')\n",
    "    feature_selection(data,'non_shiftable_load')\n",
    "    feature_selection(data,'carbon_intensity')\n",
    "    feature_selection(data,'solar_generation')\n",
    "    b = b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc97c1a-68e1-4d74-a6e1-301ff68e91a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_selection(data,obs_feature):\n",
    "    # Split the dataset into features and target\n",
    "    X = data\n",
    "    y = data[obs_feature]\n",
    "    \n",
    "    # Apply Information Gain\n",
    "    ig = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create a dictionary of feature importance scores\n",
    "    feature_scores = {}\n",
    "    i = 0\n",
    "    for (columnName, columnData) in data.items():\n",
    "        feature_scores[columnName] = ig[i]\n",
    "        i = i + 1\n",
    "    # Sort the features by importance score in descending order\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    f_l = []\n",
    "    s_l = []\n",
    "    a_l = []\n",
    "    a_l_s = []\n",
    "    # Print the feature importance scores and the sorted features\n",
    "    for feature, score in sorted_features:\n",
    "        a_l.append(feature)\n",
    "        a_l_s.append(score)\n",
    "        if score > 0.10:\n",
    "            # save the features\n",
    "            f_l.append(feature)\n",
    "            s_l.append(score)\n",
    "            \n",
    "    dic = {'feature': f_l, 'score': s_l}\n",
    "    dic_a = {'feature': a_l, 'score': a_l_s}\n",
    "    df2 = pd.DataFrame(dic_a)\n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv('data/features/feature_importance_'+str(obs_feature)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84e00c-1958-4f58-9c60-8de58a0e39e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the Predictors (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b41fd673-11e2-4f20-a660-fb36934ccd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'fusion'\n",
    "hyperparameter = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0382c-bd19-474a-b753-fa3e54dbeb9f",
   "metadata": {},
   "source": [
    "## Building Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a8265-0e7c-4c65-836c-6bb7a55701e1",
   "metadata": {},
   "source": [
    "### 1.) Cooling Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da7752-a409-4bf3-a5ed-fc0d82380079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    print(\"Building Model!\")\n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'cooling_demand')\n",
    "        joblib.dump(xgb, 'my_models/models/cooling_demand_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'cooling_demand')\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_demand_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'cooling_demand')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'cooling_demand')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/cooling_demand_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/cooling_demand_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'cooling_demand',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/cooling_demand_model_b'+str(i)+'.pkl')\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5d417-bec7-49b8-8f1a-2b30b199bbf1",
   "metadata": {},
   "source": [
    "### 2.) DHW Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2291829-e34d-491d-a21f-9f6b8c981d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'dhw_demand')\n",
    "        joblib.dump(xgb, 'my_models/models/dhw_demand_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'dhw_demand')\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_demand_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'dhw_demand')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'dhw_demand')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/dhw_demand_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/dhw_demand_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'dhw_demand',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/dhw_demand_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f10a61-a65d-4a70-ad5f-01f02f0a2049",
   "metadata": {},
   "source": [
    "### 3.) Equipment Electric Power (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4ecb764-a3e2-4266-a1ae-1da596ce021f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        joblib.dump(xgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_new_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_new_2_hyper.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        #lstm_model = LSTM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/Equipment_Electric_Power_model_b'+str(i)+'_2.pkl')\n",
    "        #joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/Equipment_Electric_Power_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'non_shiftable_load',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/Equipment_Electric_Power_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5143b8-6eb1-424a-975f-434b42934d7c",
   "metadata": {},
   "source": [
    "# Neighbourhood Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6668b0-ba09-47d6-84f6-a4b392d12377",
   "metadata": {},
   "source": [
    "### 1.) Carbon Intensity (kgCO2e/kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e4946-9e37-4a24-83a7-9ea2b756110e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 01:03:28.571594: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-10-24 01:03:28.572786: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-10-24 01:03:28.573287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (6b1cc6700774): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "54/54 [==============================] - 8s 48ms/step - loss: 0.0503 - val_loss: 0.0060\n",
      "Epoch 2/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 0.0034 - val_loss: 0.0026\n",
      "Epoch 3/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 4/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 0.0017 - val_loss: 0.0015\n",
      "Epoch 5/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0014 - val_loss: 0.0013\n",
      "Epoch 6/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 0.0013 - val_loss: 0.0012\n",
      "Epoch 7/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 0.0012 - val_loss: 0.0012\n",
      "Epoch 8/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 0.0011 - val_loss: 0.0011\n",
      "Epoch 9/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0010 - val_loss: 0.0012\n",
      "Epoch 10/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 0.0010 - val_loss: 0.0011\n",
      "Epoch 11/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 9.5283e-04 - val_loss: 0.0010\n",
      "Epoch 12/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 9.3852e-04 - val_loss: 0.0010\n",
      "Epoch 13/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 9.3549e-04 - val_loss: 0.0010\n",
      "Epoch 14/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 8.9761e-04 - val_loss: 9.3936e-04\n",
      "Epoch 15/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 8.6184e-04 - val_loss: 9.3608e-04\n",
      "Epoch 16/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 8.5620e-04 - val_loss: 9.1951e-04\n",
      "Epoch 17/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 8.4989e-04 - val_loss: 9.9380e-04\n",
      "Epoch 18/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.6659e-04 - val_loss: 9.8114e-04\n",
      "Epoch 19/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 8.5244e-04 - val_loss: 8.6962e-04\n",
      "Epoch 20/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 8.2830e-04 - val_loss: 9.4020e-04\n",
      "Epoch 21/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 8.0386e-04 - val_loss: 9.1139e-04\n",
      "Epoch 22/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 8.6180e-04 - val_loss: 8.7312e-04\n",
      "Epoch 23/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.2745e-04 - val_loss: 9.2665e-04\n",
      "Epoch 24/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 8.1300e-04 - val_loss: 8.5307e-04\n",
      "Epoch 25/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 8.0596e-04 - val_loss: 8.7990e-04\n",
      "Epoch 26/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.7961e-04 - val_loss: 9.1168e-04\n",
      "Epoch 27/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.9812e-04 - val_loss: 9.1981e-04\n",
      "Epoch 28/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 7.8685e-04 - val_loss: 7.9940e-04\n",
      "Epoch 29/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.6284e-04 - val_loss: 8.4939e-04\n",
      "Epoch 30/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 8.0429e-04 - val_loss: 9.0174e-04\n",
      "Epoch 31/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.9490e-04 - val_loss: 8.5332e-04\n",
      "Epoch 32/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 8.0568e-04 - val_loss: 9.3762e-04\n",
      "Epoch 33/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.1980e-04 - val_loss: 8.8735e-04\n",
      "Epoch 34/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 8.2463e-04 - val_loss: 8.4054e-04\n",
      "Epoch 35/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 7.9800e-04 - val_loss: 8.7806e-04\n",
      "Epoch 36/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.7435e-04 - val_loss: 8.0337e-04\n",
      "Epoch 37/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.5152e-04 - val_loss: 8.5173e-04\n",
      "Epoch 38/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.5010e-04 - val_loss: 7.8773e-04\n",
      "Epoch 39/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 8.0958e-04 - val_loss: 8.5675e-04\n",
      "Epoch 40/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.7997e-04 - val_loss: 8.7912e-04\n",
      "Epoch 41/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.3799e-04 - val_loss: 8.8278e-04\n",
      "Epoch 42/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 7.3427e-04 - val_loss: 8.2571e-04\n",
      "Epoch 43/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.7804e-04 - val_loss: 8.2410e-04\n",
      "Epoch 44/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.1595e-04 - val_loss: 8.5394e-04\n",
      "Epoch 45/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.5990e-04 - val_loss: 8.4677e-04\n",
      "Epoch 46/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.3008e-04 - val_loss: 8.2089e-04\n",
      "Epoch 47/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.3470e-04 - val_loss: 8.0262e-04\n",
      "Epoch 48/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 7.5282e-04 - val_loss: 8.1451e-04\n",
      "Epoch 49/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 7.5560e-04 - val_loss: 7.6924e-04\n",
      "Epoch 50/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.0110e-04 - val_loss: 8.3054e-04\n",
      "Epoch 51/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.8741e-04 - val_loss: 7.6168e-04\n",
      "Epoch 52/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.6082e-04 - val_loss: 7.7377e-04\n",
      "Epoch 53/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.1561e-04 - val_loss: 8.1304e-04\n",
      "Epoch 54/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.0569e-04 - val_loss: 7.6594e-04\n",
      "Epoch 55/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.0549e-04 - val_loss: 8.1444e-04\n",
      "Epoch 56/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.4779e-04 - val_loss: 8.4970e-04\n",
      "Epoch 57/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 7.1710e-04 - val_loss: 7.8976e-04\n",
      "Epoch 58/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.9134e-04 - val_loss: 7.5998e-04\n",
      "Epoch 59/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.0178e-04 - val_loss: 7.5917e-04\n",
      "Epoch 60/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.5816e-04 - val_loss: 8.1778e-04\n",
      "Epoch 61/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.2805e-04 - val_loss: 8.6091e-04\n",
      "Epoch 62/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.7035e-04 - val_loss: 8.2986e-04\n",
      "Epoch 63/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 7.3237e-04 - val_loss: 8.4280e-04\n",
      "Epoch 64/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 7.3836e-04 - val_loss: 8.5066e-04\n",
      "Epoch 65/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.4333e-04 - val_loss: 8.1018e-04\n",
      "Epoch 66/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.1431e-04 - val_loss: 8.6817e-04\n",
      "Epoch 67/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.0647e-04 - val_loss: 8.3435e-04\n",
      "Epoch 68/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.9322e-04 - val_loss: 7.8552e-04\n",
      "Epoch 69/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.9488e-04 - val_loss: 8.1569e-04\n",
      "Epoch 70/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.8242e-04 - val_loss: 8.8606e-04\n",
      "Epoch 71/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 6.8746e-04 - val_loss: 8.1774e-04\n",
      "Epoch 72/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.0245e-04 - val_loss: 8.5783e-04\n",
      "Epoch 73/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.2822e-04 - val_loss: 8.9854e-04\n",
      "Epoch 74/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 7.2849e-04 - val_loss: 7.8501e-04\n",
      "Epoch 75/1000\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 7.1081e-04 - val_loss: 8.0641e-04\n",
      "Epoch 76/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.6615e-04 - val_loss: 7.5487e-04\n",
      "Epoch 77/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.4516e-04 - val_loss: 7.9394e-04\n",
      "Epoch 78/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 6.7135e-04 - val_loss: 7.3023e-04\n",
      "Epoch 79/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.5705e-04 - val_loss: 6.9661e-04\n",
      "Epoch 80/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.4436e-04 - val_loss: 8.0607e-04\n",
      "Epoch 81/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.0677e-04 - val_loss: 7.4468e-04\n",
      "Epoch 82/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.5736e-04 - val_loss: 7.2706e-04\n",
      "Epoch 83/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.4852e-04 - val_loss: 7.8097e-04\n",
      "Epoch 84/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.3021e-04 - val_loss: 7.9341e-04\n",
      "Epoch 85/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 6.6250e-04 - val_loss: 8.0042e-04\n",
      "Epoch 86/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.6466e-04 - val_loss: 7.1549e-04\n",
      "Epoch 87/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.3610e-04 - val_loss: 7.7644e-04\n",
      "Epoch 88/1000\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 6.2953e-04 - val_loss: 7.1356e-04\n",
      "Epoch 89/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.1946e-04 - val_loss: 6.7058e-04\n",
      "Epoch 90/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.5208e-04 - val_loss: 7.9250e-04\n",
      "Epoch 91/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3101e-04 - val_loss: 6.9944e-04\n",
      "Epoch 92/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.8761e-04 - val_loss: 6.9254e-04\n",
      "Epoch 93/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 6.2925e-04 - val_loss: 7.1807e-04\n",
      "Epoch 94/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.6517e-04 - val_loss: 7.0024e-04\n",
      "Epoch 95/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7535e-04 - val_loss: 7.0973e-04\n",
      "Epoch 96/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.6874e-04 - val_loss: 7.0047e-04\n",
      "Epoch 97/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.4384e-04 - val_loss: 6.7746e-04\n",
      "Epoch 98/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.0287e-04 - val_loss: 6.5760e-04\n",
      "Epoch 99/1000\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 6.0585e-04 - val_loss: 6.7133e-04\n",
      "Epoch 100/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.3400e-04 - val_loss: 8.4168e-04\n",
      "Epoch 101/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7592e-04 - val_loss: 7.3543e-04\n",
      "Epoch 102/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.8764e-04 - val_loss: 7.8395e-04\n",
      "Epoch 103/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.8896e-04 - val_loss: 8.8560e-04\n",
      "Epoch 104/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.6556e-04 - val_loss: 8.5828e-04\n",
      "Epoch 105/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7329e-04 - val_loss: 7.4765e-04\n",
      "Epoch 106/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.6340e-04 - val_loss: 7.0439e-04\n",
      "Epoch 107/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 6.6115e-04 - val_loss: 7.5266e-04\n",
      "Epoch 108/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.2621e-04 - val_loss: 6.9049e-04\n",
      "Epoch 109/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.4427e-04 - val_loss: 7.4696e-04\n",
      "Epoch 110/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3934e-04 - val_loss: 6.8746e-04\n",
      "Epoch 111/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.4262e-04 - val_loss: 6.9235e-04\n",
      "Epoch 112/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3482e-04 - val_loss: 6.8141e-04\n",
      "Epoch 113/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.6489e-04 - val_loss: 7.3326e-04\n",
      "Epoch 114/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.7123e-04 - val_loss: 7.6275e-04\n",
      "Epoch 115/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.4168e-04 - val_loss: 8.4322e-04\n",
      "Epoch 116/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.6656e-04 - val_loss: 7.7138e-04\n",
      "Epoch 117/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.3702e-04 - val_loss: 7.0824e-04\n",
      "Epoch 118/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.4577e-04 - val_loss: 7.1342e-04\n",
      "Epoch 119/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2020e-04 - val_loss: 7.3755e-04\n",
      "Epoch 120/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.5703e-04 - val_loss: 7.5696e-04\n",
      "Epoch 121/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 6.1542e-04 - val_loss: 9.0670e-04\n",
      "Epoch 122/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.1214e-04 - val_loss: 7.8468e-04\n",
      "Epoch 123/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 7.0690e-04 - val_loss: 7.6891e-04\n",
      "Epoch 124/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.6798e-04 - val_loss: 7.3260e-04\n",
      "Epoch 125/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7305e-04 - val_loss: 7.6457e-04\n",
      "Epoch 126/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7802e-04 - val_loss: 8.0394e-04\n",
      "Epoch 127/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.8152e-04 - val_loss: 8.0597e-04\n",
      "Epoch 128/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.4573e-04 - val_loss: 7.2274e-04\n",
      "Epoch 129/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 6.4514e-04 - val_loss: 7.5288e-04\n",
      "Epoch 130/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7491e-04 - val_loss: 7.9359e-04\n",
      "Epoch 131/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.2291e-04 - val_loss: 9.4119e-04\n",
      "Epoch 132/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.8607e-04 - val_loss: 8.6893e-04\n",
      "Epoch 133/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.8452e-04 - val_loss: 7.4538e-04\n",
      "Epoch 134/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.9711e-04 - val_loss: 8.5871e-04\n",
      "Epoch 135/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 7.1448e-04 - val_loss: 8.9628e-04\n",
      "Epoch 136/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 6.9600e-04 - val_loss: 9.5749e-04\n",
      "Epoch 137/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7976e-04 - val_loss: 8.3406e-04\n",
      "Epoch 138/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.7205e-04 - val_loss: 7.2330e-04\n",
      "Epoch 139/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7215e-04 - val_loss: 7.8178e-04\n",
      "Epoch 140/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.7888e-04 - val_loss: 7.5553e-04\n",
      "Epoch 141/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.6073e-04 - val_loss: 8.5012e-04\n",
      "Epoch 142/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 6.8859e-04 - val_loss: 7.5660e-04\n",
      "Epoch 143/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 6.6712e-04 - val_loss: 8.2861e-04\n",
      "Epoch 144/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 7.4237e-04 - val_loss: 8.8754e-04\n",
      "Epoch 145/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.1495e-04 - val_loss: 7.8500e-04\n",
      "Epoch 146/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 7.3758e-04 - val_loss: 8.0851e-04\n",
      "Epoch 147/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.9095e-04 - val_loss: 7.9969e-04\n",
      "Epoch 148/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.7963e-04 - val_loss: 7.7482e-04\n",
      "Epoch 149/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.6417e-04 - val_loss: 7.5812e-04\n",
      "Epoch 150/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.2588e-04 - val_loss: 7.4601e-04\n",
      "Epoch 151/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.7511e-04 - val_loss: 7.8555e-04\n",
      "Epoch 152/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.7160e-04 - val_loss: 7.5369e-04\n",
      "Epoch 153/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.8485e-04 - val_loss: 7.4604e-04\n",
      "Epoch 154/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.8865e-04 - val_loss: 8.5488e-04\n",
      "Epoch 155/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.0499e-04 - val_loss: 7.6339e-04\n",
      "Epoch 156/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.3550e-04 - val_loss: 8.0557e-04\n",
      "Epoch 157/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.7385e-04 - val_loss: 7.5768e-04\n",
      "Epoch 158/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.2626e-04 - val_loss: 7.0354e-04\n",
      "Epoch 159/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.9508e-04 - val_loss: 7.7033e-04\n",
      "Epoch 160/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.2991e-04 - val_loss: 7.4967e-04\n",
      "Epoch 161/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.3344e-04 - val_loss: 7.8599e-04\n",
      "Epoch 162/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2951e-04 - val_loss: 7.7423e-04\n",
      "Epoch 163/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.2552e-04 - val_loss: 7.1771e-04\n",
      "Epoch 164/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.2563e-04 - val_loss: 7.8054e-04\n",
      "Epoch 165/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.2467e-04 - val_loss: 7.0433e-04\n",
      "Epoch 166/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.5755e-04 - val_loss: 7.9281e-04\n",
      "Epoch 167/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.5234e-04 - val_loss: 8.9433e-04\n",
      "Epoch 168/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 7.1723e-04 - val_loss: 8.2084e-04\n",
      "Epoch 169/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.2543e-04 - val_loss: 7.3940e-04\n",
      "Epoch 170/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 5.9386e-04 - val_loss: 7.4081e-04\n",
      "Epoch 171/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.2121e-04 - val_loss: 7.3271e-04\n",
      "Epoch 172/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.1124e-04 - val_loss: 7.3577e-04\n",
      "Epoch 173/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.9682e-04 - val_loss: 8.4873e-04\n",
      "Epoch 174/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.2706e-04 - val_loss: 6.9873e-04\n",
      "Epoch 175/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.8295e-04 - val_loss: 7.0127e-04\n",
      "Epoch 176/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5840e-04 - val_loss: 6.7776e-04\n",
      "Epoch 177/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.7110e-04 - val_loss: 7.3102e-04\n",
      "Epoch 178/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.0900e-04 - val_loss: 6.8927e-04\n",
      "Epoch 179/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.0530e-04 - val_loss: 7.4929e-04\n",
      "Epoch 180/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.9984e-04 - val_loss: 6.9268e-04\n",
      "Epoch 181/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.1236e-04 - val_loss: 6.8135e-04\n",
      "Epoch 182/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.9229e-04 - val_loss: 6.7530e-04\n",
      "Epoch 183/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.8701e-04 - val_loss: 7.0894e-04\n",
      "Epoch 184/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 6.2345e-04 - val_loss: 7.1763e-04\n",
      "Epoch 185/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.2513e-04 - val_loss: 7.3929e-04\n",
      "Epoch 186/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.0134e-04 - val_loss: 6.7359e-04\n",
      "Epoch 187/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5181e-04 - val_loss: 6.7043e-04\n",
      "Epoch 188/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 5.7470e-04 - val_loss: 6.5076e-04\n",
      "Epoch 189/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 5.7894e-04 - val_loss: 6.4497e-04\n",
      "Epoch 190/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.5381e-04 - val_loss: 6.0600e-04\n",
      "Epoch 191/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 5.5383e-04 - val_loss: 7.0683e-04\n",
      "Epoch 192/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.0061e-04 - val_loss: 6.5144e-04\n",
      "Epoch 193/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.6238e-04 - val_loss: 6.7856e-04\n",
      "Epoch 194/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.2041e-04 - val_loss: 6.5484e-04\n",
      "Epoch 195/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.4085e-04 - val_loss: 7.8555e-04\n",
      "Epoch 196/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3408e-04 - val_loss: 7.4379e-04\n",
      "Epoch 197/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 6.1998e-04 - val_loss: 7.6900e-04\n",
      "Epoch 198/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.9606e-04 - val_loss: 6.5690e-04\n",
      "Epoch 199/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.8012e-04 - val_loss: 7.1528e-04\n",
      "Epoch 200/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.0974e-04 - val_loss: 8.0889e-04\n",
      "Epoch 201/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.8080e-04 - val_loss: 7.9647e-04\n",
      "Epoch 202/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3919e-04 - val_loss: 7.1876e-04\n",
      "Epoch 203/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7315e-04 - val_loss: 6.9708e-04\n",
      "Epoch 204/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 5.7459e-04 - val_loss: 7.4937e-04\n",
      "Epoch 205/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.7886e-04 - val_loss: 6.7307e-04\n",
      "Epoch 206/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.7805e-04 - val_loss: 6.8427e-04\n",
      "Epoch 207/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.7271e-04 - val_loss: 6.7120e-04\n",
      "Epoch 208/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5549e-04 - val_loss: 6.7233e-04\n",
      "Epoch 209/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5221e-04 - val_loss: 6.7201e-04\n",
      "Epoch 210/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7990e-04 - val_loss: 6.7530e-04\n",
      "Epoch 211/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.6971e-04 - val_loss: 6.7809e-04\n",
      "Epoch 212/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 5.9374e-04 - val_loss: 7.1338e-04\n",
      "Epoch 213/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.8277e-04 - val_loss: 7.3574e-04\n",
      "Epoch 214/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7780e-04 - val_loss: 6.9889e-04\n",
      "Epoch 215/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.5164e-04 - val_loss: 7.2468e-04\n",
      "Epoch 216/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.3761e-04 - val_loss: 7.2370e-04\n",
      "Epoch 217/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.2751e-04 - val_loss: 8.3928e-04\n",
      "Epoch 218/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 6.3985e-04 - val_loss: 6.9965e-04\n",
      "Epoch 219/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 5.9869e-04 - val_loss: 7.5324e-04\n",
      "Epoch 220/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 6.0622e-04 - val_loss: 7.7358e-04\n",
      "Epoch 221/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.9985e-04 - val_loss: 7.0835e-04\n",
      "Epoch 222/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.5472e-04 - val_loss: 6.7761e-04\n",
      "Epoch 223/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.5169e-04 - val_loss: 6.4313e-04\n",
      "Epoch 224/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7234e-04 - val_loss: 7.0585e-04\n",
      "Epoch 225/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 6.0855e-04 - val_loss: 6.9319e-04\n",
      "Epoch 226/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 5.9218e-04 - val_loss: 7.3401e-04\n",
      "Epoch 227/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.9106e-04 - val_loss: 7.1782e-04\n",
      "Epoch 228/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.1248e-04 - val_loss: 6.8133e-04\n",
      "Epoch 229/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2968e-04 - val_loss: 6.8419e-04\n",
      "Epoch 230/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2121e-04 - val_loss: 7.5354e-04\n",
      "Epoch 231/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.9661e-04 - val_loss: 7.1378e-04\n",
      "Epoch 232/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 6.0094e-04 - val_loss: 7.8261e-04\n",
      "Epoch 233/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 5.8914e-04 - val_loss: 6.5396e-04\n",
      "Epoch 234/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.5667e-04 - val_loss: 6.0453e-04\n",
      "Epoch 235/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.2461e-04 - val_loss: 6.7342e-04\n",
      "Epoch 236/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.4587e-04 - val_loss: 6.9446e-04\n",
      "Epoch 237/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5607e-04 - val_loss: 6.8522e-04\n",
      "Epoch 238/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.6557e-04 - val_loss: 6.4727e-04\n",
      "Epoch 239/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 5.6472e-04 - val_loss: 7.5795e-04\n",
      "Epoch 240/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 5.9014e-04 - val_loss: 6.2709e-04\n",
      "Epoch 241/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5903e-04 - val_loss: 6.4422e-04\n",
      "Epoch 242/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.4524e-04 - val_loss: 6.2488e-04\n",
      "Epoch 243/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.1779e-04 - val_loss: 6.5490e-04\n",
      "Epoch 244/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2914e-04 - val_loss: 6.1149e-04\n",
      "Epoch 245/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2544e-04 - val_loss: 6.2388e-04\n",
      "Epoch 246/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.1516e-04 - val_loss: 6.1881e-04\n",
      "Epoch 247/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2110e-04 - val_loss: 6.6663e-04\n",
      "Epoch 248/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9568e-04 - val_loss: 5.9760e-04\n",
      "Epoch 249/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.0667e-04 - val_loss: 5.6375e-04\n",
      "Epoch 250/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8108e-04 - val_loss: 5.7579e-04\n",
      "Epoch 251/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.6943e-04 - val_loss: 5.8187e-04\n",
      "Epoch 252/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9079e-04 - val_loss: 7.0402e-04\n",
      "Epoch 253/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.9938e-04 - val_loss: 5.8672e-04\n",
      "Epoch 254/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9615e-04 - val_loss: 7.0804e-04\n",
      "Epoch 255/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2733e-04 - val_loss: 6.5922e-04\n",
      "Epoch 256/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.3005e-04 - val_loss: 8.6451e-04\n",
      "Epoch 257/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.8099e-04 - val_loss: 6.5318e-04\n",
      "Epoch 258/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.4404e-04 - val_loss: 6.1582e-04\n",
      "Epoch 259/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.9984e-04 - val_loss: 6.3518e-04\n",
      "Epoch 260/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 5.1163e-04 - val_loss: 6.3802e-04\n",
      "Epoch 261/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.1822e-04 - val_loss: 6.2684e-04\n",
      "Epoch 262/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.4255e-04 - val_loss: 6.6024e-04\n",
      "Epoch 263/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.0976e-04 - val_loss: 5.8759e-04\n",
      "Epoch 264/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8947e-04 - val_loss: 6.0101e-04\n",
      "Epoch 265/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7793e-04 - val_loss: 6.0190e-04\n",
      "Epoch 266/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.0852e-04 - val_loss: 6.6193e-04\n",
      "Epoch 267/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.4076e-04 - val_loss: 6.4235e-04\n",
      "Epoch 268/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.2647e-04 - val_loss: 6.0968e-04\n",
      "Epoch 269/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.2930e-04 - val_loss: 7.2029e-04\n",
      "Epoch 270/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.3837e-04 - val_loss: 5.8769e-04\n",
      "Epoch 271/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.8276e-04 - val_loss: 5.5976e-04\n",
      "Epoch 272/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.9645e-04 - val_loss: 6.2150e-04\n",
      "Epoch 273/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.9922e-04 - val_loss: 5.8149e-04\n",
      "Epoch 274/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 4.7258e-04 - val_loss: 6.0323e-04\n",
      "Epoch 275/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.7661e-04 - val_loss: 5.9717e-04\n",
      "Epoch 276/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.0019e-04 - val_loss: 6.4607e-04\n",
      "Epoch 277/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.1629e-04 - val_loss: 6.0419e-04\n",
      "Epoch 278/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.7619e-04 - val_loss: 8.1431e-04\n",
      "Epoch 279/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2184e-04 - val_loss: 7.8498e-04\n",
      "Epoch 280/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 6.2924e-04 - val_loss: 7.1431e-04\n",
      "Epoch 281/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 5.9293e-04 - val_loss: 7.1208e-04\n",
      "Epoch 282/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.1150e-04 - val_loss: 6.2300e-04\n",
      "Epoch 283/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.5339e-04 - val_loss: 6.7626e-04\n",
      "Epoch 284/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.3173e-04 - val_loss: 6.1425e-04\n",
      "Epoch 285/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.3439e-04 - val_loss: 7.6774e-04\n",
      "Epoch 286/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 6.1112e-04 - val_loss: 6.9519e-04\n",
      "Epoch 287/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 6.0501e-04 - val_loss: 7.0986e-04\n",
      "Epoch 288/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 5.4373e-04 - val_loss: 6.9344e-04\n",
      "Epoch 289/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.3951e-04 - val_loss: 5.9875e-04\n",
      "Epoch 290/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.2790e-04 - val_loss: 6.3984e-04\n",
      "Epoch 291/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2989e-04 - val_loss: 6.1148e-04\n",
      "Epoch 292/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.4061e-04 - val_loss: 6.0878e-04\n",
      "Epoch 293/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.4736e-04 - val_loss: 7.2443e-04\n",
      "Epoch 294/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.2795e-04 - val_loss: 6.1857e-04\n",
      "Epoch 295/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.3099e-04 - val_loss: 5.9464e-04\n",
      "Epoch 296/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.4642e-04 - val_loss: 6.5441e-04\n",
      "Epoch 297/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.0668e-04 - val_loss: 6.1547e-04\n",
      "Epoch 298/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8662e-04 - val_loss: 6.1231e-04\n",
      "Epoch 299/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.6498e-04 - val_loss: 6.5853e-04\n",
      "Epoch 300/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2442e-04 - val_loss: 6.1599e-04\n",
      "Epoch 301/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.4114e-04 - val_loss: 6.9044e-04\n",
      "Epoch 302/1000\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 5.8194e-04 - val_loss: 7.0344e-04\n",
      "Epoch 303/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.5115e-04 - val_loss: 6.0729e-04\n",
      "Epoch 304/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.0384e-04 - val_loss: 5.9089e-04\n",
      "Epoch 305/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.7031e-04 - val_loss: 5.6388e-04\n",
      "Epoch 306/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.7906e-04 - val_loss: 6.1988e-04\n",
      "Epoch 307/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.1490e-04 - val_loss: 6.1600e-04\n",
      "Epoch 308/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.1814e-04 - val_loss: 5.9102e-04\n",
      "Epoch 309/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 4.6572e-04 - val_loss: 5.6307e-04\n",
      "Epoch 310/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.5026e-04 - val_loss: 5.7603e-04\n",
      "Epoch 311/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.6440e-04 - val_loss: 6.5923e-04\n",
      "Epoch 312/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9537e-04 - val_loss: 6.2483e-04\n",
      "Epoch 313/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9237e-04 - val_loss: 6.0165e-04\n",
      "Epoch 314/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.8620e-04 - val_loss: 6.6554e-04\n",
      "Epoch 315/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9715e-04 - val_loss: 5.9130e-04\n",
      "Epoch 316/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 5.2851e-04 - val_loss: 6.3742e-04\n",
      "Epoch 317/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.2799e-04 - val_loss: 6.3130e-04\n",
      "Epoch 318/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.9125e-04 - val_loss: 5.9162e-04\n",
      "Epoch 319/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9783e-04 - val_loss: 6.0490e-04\n",
      "Epoch 320/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3892e-04 - val_loss: 5.9968e-04\n",
      "Epoch 321/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.6781e-04 - val_loss: 5.8164e-04\n",
      "Epoch 322/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.9150e-04 - val_loss: 5.8829e-04\n",
      "Epoch 323/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 5.1112e-04 - val_loss: 5.6474e-04\n",
      "Epoch 324/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.0102e-04 - val_loss: 5.8141e-04\n",
      "Epoch 325/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.0831e-04 - val_loss: 6.1184e-04\n",
      "Epoch 326/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8375e-04 - val_loss: 5.7428e-04\n",
      "Epoch 327/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 5.1385e-04 - val_loss: 6.4423e-04\n",
      "Epoch 328/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9277e-04 - val_loss: 6.3857e-04\n",
      "Epoch 329/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.5744e-04 - val_loss: 5.8724e-04\n",
      "Epoch 330/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.8023e-04 - val_loss: 5.6706e-04\n",
      "Epoch 331/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.5280e-04 - val_loss: 5.2004e-04\n",
      "Epoch 332/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.2492e-04 - val_loss: 6.1054e-04\n",
      "Epoch 333/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 4.8810e-04 - val_loss: 7.1464e-04\n",
      "Epoch 334/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 5.1132e-04 - val_loss: 5.8261e-04\n",
      "Epoch 335/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.9837e-04 - val_loss: 5.8606e-04\n",
      "Epoch 336/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.5978e-04 - val_loss: 5.1670e-04\n",
      "Epoch 337/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 4.7907e-04 - val_loss: 5.9355e-04\n",
      "Epoch 338/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4421e-04 - val_loss: 5.1767e-04\n",
      "Epoch 339/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.5441e-04 - val_loss: 5.5265e-04\n",
      "Epoch 340/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.6131e-04 - val_loss: 5.7617e-04\n",
      "Epoch 341/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2550e-04 - val_loss: 4.9327e-04\n",
      "Epoch 342/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.2561e-04 - val_loss: 5.0476e-04\n",
      "Epoch 343/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1833e-04 - val_loss: 5.2998e-04\n",
      "Epoch 344/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.8778e-04 - val_loss: 6.2329e-04\n",
      "Epoch 345/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8743e-04 - val_loss: 5.7136e-04\n",
      "Epoch 346/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.7537e-04 - val_loss: 5.7466e-04\n",
      "Epoch 347/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.1851e-04 - val_loss: 6.3733e-04\n",
      "Epoch 348/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9576e-04 - val_loss: 6.1474e-04\n",
      "Epoch 349/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.3697e-04 - val_loss: 6.0534e-04\n",
      "Epoch 350/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 5.2027e-04 - val_loss: 5.9532e-04\n",
      "Epoch 351/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 4.7622e-04 - val_loss: 5.8605e-04\n",
      "Epoch 352/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 5.1612e-04 - val_loss: 5.9299e-04\n",
      "Epoch 353/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.5401e-04 - val_loss: 5.0914e-04\n",
      "Epoch 354/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.8092e-04 - val_loss: 5.7548e-04\n",
      "Epoch 355/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.7100e-04 - val_loss: 5.6810e-04\n",
      "Epoch 356/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9582e-04 - val_loss: 5.1795e-04\n",
      "Epoch 357/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.6747e-04 - val_loss: 5.2132e-04\n",
      "Epoch 358/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.5889e-04 - val_loss: 5.0341e-04\n",
      "Epoch 359/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3803e-04 - val_loss: 4.7845e-04\n",
      "Epoch 360/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.6241e-04 - val_loss: 5.2119e-04\n",
      "Epoch 361/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.5720e-04 - val_loss: 5.7205e-04\n",
      "Epoch 362/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.5043e-04 - val_loss: 5.1605e-04\n",
      "Epoch 363/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.7189e-04 - val_loss: 5.7996e-04\n",
      "Epoch 364/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9398e-04 - val_loss: 5.3586e-04\n",
      "Epoch 365/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.1015e-04 - val_loss: 5.2990e-04\n",
      "Epoch 366/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9604e-04 - val_loss: 6.2066e-04\n",
      "Epoch 367/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9045e-04 - val_loss: 5.4753e-04\n",
      "Epoch 368/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.4255e-04 - val_loss: 4.9870e-04\n",
      "Epoch 369/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.6537e-04 - val_loss: 5.1880e-04\n",
      "Epoch 370/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.4396e-04 - val_loss: 5.0728e-04\n",
      "Epoch 371/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.1873e-04 - val_loss: 5.2957e-04\n",
      "Epoch 372/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 4.3672e-04 - val_loss: 5.4512e-04\n",
      "Epoch 373/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.4473e-04 - val_loss: 5.1854e-04\n",
      "Epoch 374/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.4849e-04 - val_loss: 5.4989e-04\n",
      "Epoch 375/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4183e-04 - val_loss: 5.9615e-04\n",
      "Epoch 376/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.7100e-04 - val_loss: 5.4785e-04\n",
      "Epoch 377/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.4852e-04 - val_loss: 5.1667e-04\n",
      "Epoch 378/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2789e-04 - val_loss: 5.2323e-04\n",
      "Epoch 379/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 4.5822e-04 - val_loss: 5.5542e-04\n",
      "Epoch 380/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.5297e-04 - val_loss: 5.2904e-04\n",
      "Epoch 381/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3476e-04 - val_loss: 4.9866e-04\n",
      "Epoch 382/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.4903e-04 - val_loss: 4.9611e-04\n",
      "Epoch 383/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.2014e-04 - val_loss: 5.1558e-04\n",
      "Epoch 384/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.0464e-04 - val_loss: 4.9127e-04\n",
      "Epoch 385/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9297e-04 - val_loss: 5.3604e-04\n",
      "Epoch 386/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 4.5261e-04 - val_loss: 5.1876e-04\n",
      "Epoch 387/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.2081e-04 - val_loss: 4.9505e-04\n",
      "Epoch 388/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3541e-04 - val_loss: 5.0626e-04\n",
      "Epoch 389/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.4442e-04 - val_loss: 4.5545e-04\n",
      "Epoch 390/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9915e-04 - val_loss: 4.7433e-04\n",
      "Epoch 391/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.2442e-04 - val_loss: 5.0129e-04\n",
      "Epoch 392/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1951e-04 - val_loss: 5.0297e-04\n",
      "Epoch 393/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.4043e-04 - val_loss: 5.1521e-04\n",
      "Epoch 394/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.1617e-04 - val_loss: 4.9312e-04\n",
      "Epoch 395/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.2696e-04 - val_loss: 4.7209e-04\n",
      "Epoch 396/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1401e-04 - val_loss: 4.7920e-04\n",
      "Epoch 397/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0472e-04 - val_loss: 4.4997e-04\n",
      "Epoch 398/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9789e-04 - val_loss: 4.6492e-04\n",
      "Epoch 399/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3247e-04 - val_loss: 5.4535e-04\n",
      "Epoch 400/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 4.7017e-04 - val_loss: 5.0042e-04\n",
      "Epoch 401/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2524e-04 - val_loss: 5.3777e-04\n",
      "Epoch 402/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.5620e-04 - val_loss: 5.3421e-04\n",
      "Epoch 403/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.3942e-04 - val_loss: 6.0661e-04\n",
      "Epoch 404/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.6497e-04 - val_loss: 5.7084e-04\n",
      "Epoch 405/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3558e-04 - val_loss: 5.4440e-04\n",
      "Epoch 406/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.2261e-04 - val_loss: 4.8593e-04\n",
      "Epoch 407/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.1886e-04 - val_loss: 5.2446e-04\n",
      "Epoch 408/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.2379e-04 - val_loss: 4.6455e-04\n",
      "Epoch 409/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3281e-04 - val_loss: 4.5877e-04\n",
      "Epoch 410/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.4431e-04 - val_loss: 4.9651e-04\n",
      "Epoch 411/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.5477e-04 - val_loss: 5.5168e-04\n",
      "Epoch 412/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4562e-04 - val_loss: 5.6798e-04\n",
      "Epoch 413/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3093e-04 - val_loss: 4.5568e-04\n",
      "Epoch 414/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 4.4764e-04 - val_loss: 5.2428e-04\n",
      "Epoch 415/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1472e-04 - val_loss: 4.7971e-04\n",
      "Epoch 416/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7107e-04 - val_loss: 4.2402e-04\n",
      "Epoch 417/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6726e-04 - val_loss: 5.0182e-04\n",
      "Epoch 418/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.1496e-04 - val_loss: 4.6541e-04\n",
      "Epoch 419/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2065e-04 - val_loss: 4.5348e-04\n",
      "Epoch 420/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9991e-04 - val_loss: 4.5364e-04\n",
      "Epoch 421/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.0459e-04 - val_loss: 4.4485e-04\n",
      "Epoch 422/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9431e-04 - val_loss: 4.8977e-04\n",
      "Epoch 423/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.8739e-04 - val_loss: 4.3696e-04\n",
      "Epoch 424/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6858e-04 - val_loss: 4.9834e-04\n",
      "Epoch 425/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8375e-04 - val_loss: 4.4195e-04\n",
      "Epoch 426/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.2668e-04 - val_loss: 5.3374e-04\n",
      "Epoch 427/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9148e-04 - val_loss: 4.7798e-04\n",
      "Epoch 428/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 4.0068e-04 - val_loss: 4.4991e-04\n",
      "Epoch 429/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8422e-04 - val_loss: 4.0627e-04\n",
      "Epoch 430/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1511e-04 - val_loss: 4.7626e-04\n",
      "Epoch 431/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4402e-04 - val_loss: 6.0798e-04\n",
      "Epoch 432/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.7568e-04 - val_loss: 5.2371e-04\n",
      "Epoch 433/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.3286e-04 - val_loss: 4.8384e-04\n",
      "Epoch 434/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.3771e-04 - val_loss: 4.9521e-04\n",
      "Epoch 435/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.9170e-04 - val_loss: 4.5233e-04\n",
      "Epoch 436/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.0562e-04 - val_loss: 4.9221e-04\n",
      "Epoch 437/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9578e-04 - val_loss: 4.7034e-04\n",
      "Epoch 438/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7972e-04 - val_loss: 4.6186e-04\n",
      "Epoch 439/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.1304e-04 - val_loss: 4.7094e-04\n",
      "Epoch 440/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.6124e-04 - val_loss: 4.6723e-04\n",
      "Epoch 441/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.8640e-04 - val_loss: 4.8339e-04\n",
      "Epoch 442/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 4.3320e-04 - val_loss: 5.3665e-04\n",
      "Epoch 443/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.6669e-04 - val_loss: 4.8679e-04\n",
      "Epoch 444/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.5779e-04 - val_loss: 5.3535e-04\n",
      "Epoch 445/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 4.4863e-04 - val_loss: 4.9168e-04\n",
      "Epoch 446/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.5935e-04 - val_loss: 5.0644e-04\n",
      "Epoch 447/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4319e-04 - val_loss: 5.4513e-04\n",
      "Epoch 448/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.9149e-04 - val_loss: 6.0378e-04\n",
      "Epoch 449/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 5.3616e-04 - val_loss: 6.1765e-04\n",
      "Epoch 450/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.7500e-04 - val_loss: 5.4772e-04\n",
      "Epoch 451/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.6101e-04 - val_loss: 5.1655e-04\n",
      "Epoch 452/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.3372e-04 - val_loss: 4.5197e-04\n",
      "Epoch 453/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.0640e-04 - val_loss: 4.6139e-04\n",
      "Epoch 454/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.1970e-04 - val_loss: 5.3858e-04\n",
      "Epoch 455/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.1219e-04 - val_loss: 5.0673e-04\n",
      "Epoch 456/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.1840e-04 - val_loss: 5.0246e-04\n",
      "Epoch 457/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.4032e-04 - val_loss: 4.7370e-04\n",
      "Epoch 458/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.9359e-04 - val_loss: 4.0186e-04\n",
      "Epoch 459/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7961e-04 - val_loss: 4.7390e-04\n",
      "Epoch 460/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.1369e-04 - val_loss: 4.6370e-04\n",
      "Epoch 461/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.1447e-04 - val_loss: 5.0889e-04\n",
      "Epoch 462/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.8405e-04 - val_loss: 5.1205e-04\n",
      "Epoch 463/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.2586e-04 - val_loss: 4.6384e-04\n",
      "Epoch 464/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.5650e-04 - val_loss: 4.9353e-04\n",
      "Epoch 465/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9469e-04 - val_loss: 4.0638e-04\n",
      "Epoch 466/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7296e-04 - val_loss: 4.0986e-04\n",
      "Epoch 467/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5401e-04 - val_loss: 4.4520e-04\n",
      "Epoch 468/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6637e-04 - val_loss: 3.9319e-04\n",
      "Epoch 469/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7075e-04 - val_loss: 4.3848e-04\n",
      "Epoch 470/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.8623e-04 - val_loss: 4.1364e-04\n",
      "Epoch 471/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 4.1271e-04 - val_loss: 3.9811e-04\n",
      "Epoch 472/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8008e-04 - val_loss: 4.0181e-04\n",
      "Epoch 473/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.0244e-04 - val_loss: 4.5160e-04\n",
      "Epoch 474/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0575e-04 - val_loss: 3.9753e-04\n",
      "Epoch 475/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.6376e-04 - val_loss: 4.3176e-04\n",
      "Epoch 476/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8705e-04 - val_loss: 4.8480e-04\n",
      "Epoch 477/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.5855e-04 - val_loss: 4.8431e-04\n",
      "Epoch 478/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 4.0693e-04 - val_loss: 4.4747e-04\n",
      "Epoch 479/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1968e-04 - val_loss: 5.4930e-04\n",
      "Epoch 480/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.1975e-04 - val_loss: 4.2862e-04\n",
      "Epoch 481/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6418e-04 - val_loss: 4.4826e-04\n",
      "Epoch 482/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.8343e-04 - val_loss: 4.2999e-04\n",
      "Epoch 483/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.1038e-04 - val_loss: 4.9863e-04\n",
      "Epoch 484/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.9554e-04 - val_loss: 5.2121e-04\n",
      "Epoch 485/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.5963e-04 - val_loss: 4.9674e-04\n",
      "Epoch 486/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1377e-04 - val_loss: 4.4873e-04\n",
      "Epoch 487/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9117e-04 - val_loss: 4.4068e-04\n",
      "Epoch 488/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.8444e-04 - val_loss: 3.8807e-04\n",
      "Epoch 489/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.8394e-04 - val_loss: 4.2198e-04\n",
      "Epoch 490/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6781e-04 - val_loss: 4.1391e-04\n",
      "Epoch 491/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.8485e-04 - val_loss: 4.4447e-04\n",
      "Epoch 492/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.7486e-04 - val_loss: 4.5051e-04\n",
      "Epoch 493/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8533e-04 - val_loss: 4.1939e-04\n",
      "Epoch 494/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.0397e-04 - val_loss: 4.6945e-04\n",
      "Epoch 495/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6214e-04 - val_loss: 4.0007e-04\n",
      "Epoch 496/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4692e-04 - val_loss: 3.8335e-04\n",
      "Epoch 497/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.5767e-04 - val_loss: 4.6023e-04\n",
      "Epoch 498/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.5052e-04 - val_loss: 3.9195e-04\n",
      "Epoch 499/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.3417e-04 - val_loss: 3.8693e-04\n",
      "Epoch 500/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7137e-04 - val_loss: 4.0601e-04\n",
      "Epoch 501/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4971e-04 - val_loss: 3.9629e-04\n",
      "Epoch 502/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.6682e-04 - val_loss: 4.1567e-04\n",
      "Epoch 503/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6043e-04 - val_loss: 4.2312e-04\n",
      "Epoch 504/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8386e-04 - val_loss: 4.2882e-04\n",
      "Epoch 505/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.5665e-04 - val_loss: 3.7852e-04\n",
      "Epoch 506/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.7298e-04 - val_loss: 3.9924e-04\n",
      "Epoch 507/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4842e-04 - val_loss: 3.7792e-04\n",
      "Epoch 508/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0361e-04 - val_loss: 4.9598e-04\n",
      "Epoch 509/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0286e-04 - val_loss: 4.5300e-04\n",
      "Epoch 510/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7244e-04 - val_loss: 4.6064e-04\n",
      "Epoch 511/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4482e-04 - val_loss: 3.9402e-04\n",
      "Epoch 512/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4231e-04 - val_loss: 3.8645e-04\n",
      "Epoch 513/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.7184e-04 - val_loss: 4.2757e-04\n",
      "Epoch 514/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5009e-04 - val_loss: 4.2313e-04\n",
      "Epoch 515/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6587e-04 - val_loss: 3.5337e-04\n",
      "Epoch 516/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4697e-04 - val_loss: 3.7859e-04\n",
      "Epoch 517/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.7589e-04 - val_loss: 4.8174e-04\n",
      "Epoch 518/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1081e-04 - val_loss: 4.1415e-04\n",
      "Epoch 519/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.8489e-04 - val_loss: 4.4986e-04\n",
      "Epoch 520/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 4.0679e-04 - val_loss: 4.5105e-04\n",
      "Epoch 521/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9482e-04 - val_loss: 4.0181e-04\n",
      "Epoch 522/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7596e-04 - val_loss: 4.6543e-04\n",
      "Epoch 523/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.9026e-04 - val_loss: 4.0210e-04\n",
      "Epoch 524/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9320e-04 - val_loss: 4.3445e-04\n",
      "Epoch 525/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.0366e-04 - val_loss: 3.8863e-04\n",
      "Epoch 526/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.4378e-04 - val_loss: 4.3495e-04\n",
      "Epoch 527/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.8822e-04 - val_loss: 4.5708e-04\n",
      "Epoch 528/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6076e-04 - val_loss: 4.0616e-04\n",
      "Epoch 529/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5883e-04 - val_loss: 4.2186e-04\n",
      "Epoch 530/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4906e-04 - val_loss: 4.4724e-04\n",
      "Epoch 531/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.4449e-04 - val_loss: 3.8175e-04\n",
      "Epoch 532/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4238e-04 - val_loss: 3.5445e-04\n",
      "Epoch 533/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.1768e-04 - val_loss: 3.9040e-04\n",
      "Epoch 534/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2064e-04 - val_loss: 3.8154e-04\n",
      "Epoch 535/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.3333e-04 - val_loss: 5.7262e-04\n",
      "Epoch 536/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.7690e-04 - val_loss: 5.3215e-04\n",
      "Epoch 537/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.4940e-04 - val_loss: 4.6341e-04\n",
      "Epoch 538/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.5899e-04 - val_loss: 5.1283e-04\n",
      "Epoch 539/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7733e-04 - val_loss: 3.8112e-04\n",
      "Epoch 540/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 3.7609e-04 - val_loss: 3.8918e-04\n",
      "Epoch 541/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.1207e-04 - val_loss: 4.8260e-04\n",
      "Epoch 542/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.7815e-04 - val_loss: 3.5625e-04\n",
      "Epoch 543/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4456e-04 - val_loss: 3.7901e-04\n",
      "Epoch 544/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4909e-04 - val_loss: 4.0800e-04\n",
      "Epoch 545/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2220e-04 - val_loss: 3.7384e-04\n",
      "Epoch 546/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.3731e-04 - val_loss: 3.2091e-04\n",
      "Epoch 547/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.1364e-04 - val_loss: 3.7028e-04\n",
      "Epoch 548/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6560e-04 - val_loss: 4.4960e-04\n",
      "Epoch 549/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9873e-04 - val_loss: 4.2112e-04\n",
      "Epoch 550/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6681e-04 - val_loss: 3.8914e-04\n",
      "Epoch 551/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1639e-04 - val_loss: 4.7669e-04\n",
      "Epoch 552/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5837e-04 - val_loss: 3.4693e-04\n",
      "Epoch 553/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.3605e-04 - val_loss: 4.0584e-04\n",
      "Epoch 554/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5207e-04 - val_loss: 3.6809e-04\n",
      "Epoch 555/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2704e-04 - val_loss: 3.6857e-04\n",
      "Epoch 556/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.1881e-04 - val_loss: 3.6827e-04\n",
      "Epoch 557/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.1435e-04 - val_loss: 3.7210e-04\n",
      "Epoch 558/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2824e-04 - val_loss: 3.4434e-04\n",
      "Epoch 559/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3139e-04 - val_loss: 3.8792e-04\n",
      "Epoch 560/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.5509e-04 - val_loss: 4.2405e-04\n",
      "Epoch 561/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.8631e-04 - val_loss: 4.5500e-04\n",
      "Epoch 562/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5875e-04 - val_loss: 4.9269e-04\n",
      "Epoch 563/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.6683e-04 - val_loss: 4.5026e-04\n",
      "Epoch 564/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6667e-04 - val_loss: 5.5261e-04\n",
      "Epoch 565/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5390e-04 - val_loss: 4.1341e-04\n",
      "Epoch 566/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4853e-04 - val_loss: 3.9714e-04\n",
      "Epoch 567/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3603e-04 - val_loss: 3.9854e-04\n",
      "Epoch 568/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.5412e-04 - val_loss: 4.1964e-04\n",
      "Epoch 569/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4240e-04 - val_loss: 4.1754e-04\n",
      "Epoch 570/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.4839e-04 - val_loss: 4.7649e-04\n",
      "Epoch 571/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.6179e-04 - val_loss: 4.1484e-04\n",
      "Epoch 572/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5990e-04 - val_loss: 4.3973e-04\n",
      "Epoch 573/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5529e-04 - val_loss: 4.0624e-04\n",
      "Epoch 574/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6172e-04 - val_loss: 4.7040e-04\n",
      "Epoch 575/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 4.0309e-04 - val_loss: 4.2951e-04\n",
      "Epoch 576/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7042e-04 - val_loss: 5.5424e-04\n",
      "Epoch 577/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7939e-04 - val_loss: 5.4042e-04\n",
      "Epoch 578/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3304e-04 - val_loss: 5.2817e-04\n",
      "Epoch 579/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1847e-04 - val_loss: 4.0634e-04\n",
      "Epoch 580/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7231e-04 - val_loss: 3.9466e-04\n",
      "Epoch 581/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.4415e-04 - val_loss: 3.8909e-04\n",
      "Epoch 582/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.8293e-04 - val_loss: 4.8471e-04\n",
      "Epoch 583/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7140e-04 - val_loss: 4.0149e-04\n",
      "Epoch 584/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3985e-04 - val_loss: 3.9727e-04\n",
      "Epoch 585/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3057e-04 - val_loss: 3.9355e-04\n",
      "Epoch 586/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6671e-04 - val_loss: 3.9486e-04\n",
      "Epoch 587/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4762e-04 - val_loss: 4.7837e-04\n",
      "Epoch 588/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.9922e-04 - val_loss: 5.7140e-04\n",
      "Epoch 589/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.2499e-04 - val_loss: 4.1597e-04\n",
      "Epoch 590/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.7600e-04 - val_loss: 3.8202e-04\n",
      "Epoch 591/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3202e-04 - val_loss: 3.9444e-04\n",
      "Epoch 592/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3114e-04 - val_loss: 3.7206e-04\n",
      "Epoch 593/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0929e-04 - val_loss: 3.8873e-04\n",
      "Epoch 594/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.2167e-04 - val_loss: 4.1458e-04\n",
      "Epoch 595/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.1888e-04 - val_loss: 3.4996e-04\n",
      "Epoch 596/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.1278e-04 - val_loss: 4.1328e-04\n",
      "Epoch 597/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0917e-04 - val_loss: 3.9450e-04\n",
      "Epoch 598/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 3.0355e-04 - val_loss: 3.6959e-04\n",
      "Epoch 599/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0998e-04 - val_loss: 3.8078e-04\n",
      "Epoch 600/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3675e-04 - val_loss: 3.9531e-04\n",
      "Epoch 601/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4495e-04 - val_loss: 3.8702e-04\n",
      "Epoch 602/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.2607e-04 - val_loss: 3.4441e-04\n",
      "Epoch 603/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.1396e-04 - val_loss: 3.6148e-04\n",
      "Epoch 604/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3411e-04 - val_loss: 4.2893e-04\n",
      "Epoch 605/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2052e-04 - val_loss: 3.8499e-04\n",
      "Epoch 606/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5748e-04 - val_loss: 3.7592e-04\n",
      "Epoch 607/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2726e-04 - val_loss: 4.1242e-04\n",
      "Epoch 608/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.5359e-04 - val_loss: 4.0208e-04\n",
      "Epoch 609/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4337e-04 - val_loss: 4.2235e-04\n",
      "Epoch 610/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.6107e-04 - val_loss: 3.6345e-04\n",
      "Epoch 611/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4077e-04 - val_loss: 4.1438e-04\n",
      "Epoch 612/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 3.0950e-04 - val_loss: 3.7205e-04\n",
      "Epoch 613/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1124e-04 - val_loss: 3.9427e-04\n",
      "Epoch 614/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3782e-04 - val_loss: 3.6968e-04\n",
      "Epoch 615/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.1494e-04 - val_loss: 3.1981e-04\n",
      "Epoch 616/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8796e-04 - val_loss: 3.1953e-04\n",
      "Epoch 617/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.2871e-04 - val_loss: 3.7709e-04\n",
      "Epoch 618/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.3323e-04 - val_loss: 4.3666e-04\n",
      "Epoch 619/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5513e-04 - val_loss: 4.6374e-04\n",
      "Epoch 620/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5719e-04 - val_loss: 4.1085e-04\n",
      "Epoch 621/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.1171e-04 - val_loss: 5.1866e-04\n",
      "Epoch 622/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.2023e-04 - val_loss: 4.0563e-04\n",
      "Epoch 623/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.2787e-04 - val_loss: 3.8596e-04\n",
      "Epoch 624/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.4075e-04 - val_loss: 4.3217e-04\n",
      "Epoch 625/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5501e-04 - val_loss: 3.8811e-04\n",
      "Epoch 626/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3369e-04 - val_loss: 3.8089e-04\n",
      "Epoch 627/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.1135e-04 - val_loss: 3.9833e-04\n",
      "Epoch 628/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3669e-04 - val_loss: 3.9305e-04\n",
      "Epoch 629/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.4478e-04 - val_loss: 4.1875e-04\n",
      "Epoch 630/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7445e-04 - val_loss: 4.3447e-04\n",
      "Epoch 631/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.6822e-04 - val_loss: 4.1646e-04\n",
      "Epoch 632/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4782e-04 - val_loss: 3.9546e-04\n",
      "Epoch 633/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4258e-04 - val_loss: 4.0635e-04\n",
      "Epoch 634/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5318e-04 - val_loss: 4.5694e-04\n",
      "Epoch 635/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3870e-04 - val_loss: 4.9170e-04\n",
      "Epoch 636/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.9358e-04 - val_loss: 4.9100e-04\n",
      "Epoch 637/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.0912e-04 - val_loss: 4.8764e-04\n",
      "Epoch 638/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.5076e-04 - val_loss: 4.6082e-04\n",
      "Epoch 639/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6407e-04 - val_loss: 4.6034e-04\n",
      "Epoch 640/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.7259e-04 - val_loss: 4.7400e-04\n",
      "Epoch 641/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6794e-04 - val_loss: 4.7033e-04\n",
      "Epoch 642/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7450e-04 - val_loss: 4.7385e-04\n",
      "Epoch 643/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7708e-04 - val_loss: 5.0716e-04\n",
      "Epoch 644/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.6936e-04 - val_loss: 5.6060e-04\n",
      "Epoch 645/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 4.7563e-04 - val_loss: 4.3238e-04\n",
      "Epoch 646/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.8825e-04 - val_loss: 4.2306e-04\n",
      "Epoch 647/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7492e-04 - val_loss: 4.4866e-04\n",
      "Epoch 648/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7446e-04 - val_loss: 3.9902e-04\n",
      "Epoch 649/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5984e-04 - val_loss: 4.6379e-04\n",
      "Epoch 650/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.6630e-04 - val_loss: 4.3663e-04\n",
      "Epoch 651/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5352e-04 - val_loss: 3.7113e-04\n",
      "Epoch 652/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.5494e-04 - val_loss: 4.4623e-04\n",
      "Epoch 653/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4791e-04 - val_loss: 3.9842e-04\n",
      "Epoch 654/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2311e-04 - val_loss: 4.1173e-04\n",
      "Epoch 655/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5591e-04 - val_loss: 4.1489e-04\n",
      "Epoch 656/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4311e-04 - val_loss: 3.6025e-04\n",
      "Epoch 657/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5132e-04 - val_loss: 4.0204e-04\n",
      "Epoch 658/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4289e-04 - val_loss: 3.9107e-04\n",
      "Epoch 659/1000\n",
      "54/54 [==============================] - 1s 26ms/step - loss: 3.4761e-04 - val_loss: 3.9121e-04\n",
      "Epoch 660/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2637e-04 - val_loss: 3.9185e-04\n",
      "Epoch 661/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2374e-04 - val_loss: 3.4803e-04\n",
      "Epoch 662/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1458e-04 - val_loss: 3.4285e-04\n",
      "Epoch 663/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0363e-04 - val_loss: 3.4619e-04\n",
      "Epoch 664/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3796e-04 - val_loss: 3.5304e-04\n",
      "Epoch 665/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1448e-04 - val_loss: 3.3526e-04\n",
      "Epoch 666/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.1078e-04 - val_loss: 3.4623e-04\n",
      "Epoch 667/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.2764e-04 - val_loss: 3.7541e-04\n",
      "Epoch 668/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0339e-04 - val_loss: 3.3212e-04\n",
      "Epoch 669/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9602e-04 - val_loss: 3.7342e-04\n",
      "Epoch 670/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2139e-04 - val_loss: 3.9294e-04\n",
      "Epoch 671/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3010e-04 - val_loss: 3.6778e-04\n",
      "Epoch 672/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1128e-04 - val_loss: 3.7557e-04\n",
      "Epoch 673/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.8682e-04 - val_loss: 4.3763e-04\n",
      "Epoch 674/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.5851e-04 - val_loss: 3.9085e-04\n",
      "Epoch 675/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.1953e-04 - val_loss: 3.3776e-04\n",
      "Epoch 676/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6252e-04 - val_loss: 3.5212e-04\n",
      "Epoch 677/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.2220e-04 - val_loss: 3.8217e-04\n",
      "Epoch 678/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0277e-04 - val_loss: 3.2852e-04\n",
      "Epoch 679/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.0098e-04 - val_loss: 4.0882e-04\n",
      "Epoch 680/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.8794e-04 - val_loss: 3.1481e-04\n",
      "Epoch 681/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.8891e-04 - val_loss: 3.7366e-04\n",
      "Epoch 682/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1735e-04 - val_loss: 3.2290e-04\n",
      "Epoch 683/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7407e-04 - val_loss: 3.3834e-04\n",
      "Epoch 684/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9302e-04 - val_loss: 3.6608e-04\n",
      "Epoch 685/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3216e-04 - val_loss: 3.5792e-04\n",
      "Epoch 686/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.4795e-04 - val_loss: 5.1894e-04\n",
      "Epoch 687/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.9443e-04 - val_loss: 4.7813e-04\n",
      "Epoch 688/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6682e-04 - val_loss: 3.6362e-04\n",
      "Epoch 689/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3318e-04 - val_loss: 4.5211e-04\n",
      "Epoch 690/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.9747e-04 - val_loss: 4.6762e-04\n",
      "Epoch 691/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.8776e-04 - val_loss: 4.3614e-04\n",
      "Epoch 692/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7864e-04 - val_loss: 4.3274e-04\n",
      "Epoch 693/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.8477e-04 - val_loss: 4.4024e-04\n",
      "Epoch 694/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.2152e-04 - val_loss: 5.8464e-04\n",
      "Epoch 695/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9614e-04 - val_loss: 4.5328e-04\n",
      "Epoch 696/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.5798e-04 - val_loss: 4.5517e-04\n",
      "Epoch 697/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5345e-04 - val_loss: 4.3821e-04\n",
      "Epoch 698/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.6117e-04 - val_loss: 4.7923e-04\n",
      "Epoch 699/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9404e-04 - val_loss: 5.0012e-04\n",
      "Epoch 700/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.2607e-04 - val_loss: 5.0644e-04\n",
      "Epoch 701/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.9122e-04 - val_loss: 4.6092e-04\n",
      "Epoch 702/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6429e-04 - val_loss: 3.9983e-04\n",
      "Epoch 703/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4021e-04 - val_loss: 3.7849e-04\n",
      "Epoch 704/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3969e-04 - val_loss: 3.9707e-04\n",
      "Epoch 705/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3871e-04 - val_loss: 4.2643e-04\n",
      "Epoch 706/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4229e-04 - val_loss: 4.4402e-04\n",
      "Epoch 707/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.7597e-04 - val_loss: 4.4003e-04\n",
      "Epoch 708/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.7310e-04 - val_loss: 3.9503e-04\n",
      "Epoch 709/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3908e-04 - val_loss: 3.7000e-04\n",
      "Epoch 710/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2352e-04 - val_loss: 4.0655e-04\n",
      "Epoch 711/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2907e-04 - val_loss: 4.2001e-04\n",
      "Epoch 712/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6536e-04 - val_loss: 4.0201e-04\n",
      "Epoch 713/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5527e-04 - val_loss: 4.2065e-04\n",
      "Epoch 714/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.5243e-04 - val_loss: 4.3675e-04\n",
      "Epoch 715/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.6093e-04 - val_loss: 4.5888e-04\n",
      "Epoch 716/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.6861e-04 - val_loss: 4.2634e-04\n",
      "Epoch 717/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.4538e-04 - val_loss: 4.0765e-04\n",
      "Epoch 718/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4382e-04 - val_loss: 4.3943e-04\n",
      "Epoch 719/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.3229e-04 - val_loss: 3.8021e-04\n",
      "Epoch 720/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.6538e-04 - val_loss: 5.0190e-04\n",
      "Epoch 721/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.8544e-04 - val_loss: 5.1804e-04\n",
      "Epoch 722/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.0357e-04 - val_loss: 4.6059e-04\n",
      "Epoch 723/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7012e-04 - val_loss: 4.7265e-04\n",
      "Epoch 724/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6210e-04 - val_loss: 5.2859e-04\n",
      "Epoch 725/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8684e-04 - val_loss: 4.4933e-04\n",
      "Epoch 726/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.7291e-04 - val_loss: 4.4027e-04\n",
      "Epoch 727/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.9110e-04 - val_loss: 4.5124e-04\n",
      "Epoch 728/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.5241e-04 - val_loss: 4.3161e-04\n",
      "Epoch 729/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.4912e-04 - val_loss: 4.5376e-04\n",
      "Epoch 730/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5341e-04 - val_loss: 4.0549e-04\n",
      "Epoch 731/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4224e-04 - val_loss: 4.0446e-04\n",
      "Epoch 732/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5645e-04 - val_loss: 4.6416e-04\n",
      "Epoch 733/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4964e-04 - val_loss: 4.0433e-04\n",
      "Epoch 734/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1694e-04 - val_loss: 4.1825e-04\n",
      "Epoch 735/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.2381e-04 - val_loss: 4.2785e-04\n",
      "Epoch 736/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.3589e-04 - val_loss: 4.1068e-04\n",
      "Epoch 737/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.2432e-04 - val_loss: 4.2737e-04\n",
      "Epoch 738/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4207e-04 - val_loss: 5.1300e-04\n",
      "Epoch 739/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3445e-04 - val_loss: 4.1277e-04\n",
      "Epoch 740/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2224e-04 - val_loss: 3.7398e-04\n",
      "Epoch 741/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3232e-04 - val_loss: 4.6723e-04\n",
      "Epoch 742/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.5229e-04 - val_loss: 4.9880e-04\n",
      "Epoch 743/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.0314e-04 - val_loss: 4.9746e-04\n",
      "Epoch 744/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 4.1708e-04 - val_loss: 5.8518e-04\n",
      "Epoch 745/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.4084e-04 - val_loss: 5.3370e-04\n",
      "Epoch 746/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.3594e-04 - val_loss: 5.7084e-04\n",
      "Epoch 747/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.1966e-04 - val_loss: 5.5506e-04\n",
      "Epoch 748/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 4.2797e-04 - val_loss: 5.6122e-04\n",
      "Epoch 749/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 4.6986e-04 - val_loss: 5.5005e-04\n",
      "Epoch 750/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 4.0876e-04 - val_loss: 4.8552e-04\n",
      "Epoch 751/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8762e-04 - val_loss: 4.7581e-04\n",
      "Epoch 752/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8752e-04 - val_loss: 4.5335e-04\n",
      "Epoch 753/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7314e-04 - val_loss: 4.9850e-04\n",
      "Epoch 754/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9974e-04 - val_loss: 5.0810e-04\n",
      "Epoch 755/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.1850e-04 - val_loss: 4.5029e-04\n",
      "Epoch 756/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.8190e-04 - val_loss: 4.3580e-04\n",
      "Epoch 757/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.6765e-04 - val_loss: 4.7997e-04\n",
      "Epoch 758/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.8751e-04 - val_loss: 4.5676e-04\n",
      "Epoch 759/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.7692e-04 - val_loss: 4.3742e-04\n",
      "Epoch 760/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.2186e-04 - val_loss: 5.2662e-04\n",
      "Epoch 761/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.3667e-04 - val_loss: 4.6563e-04\n",
      "Epoch 762/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 4.0723e-04 - val_loss: 4.4081e-04\n",
      "Epoch 763/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.8771e-04 - val_loss: 4.4179e-04\n",
      "Epoch 764/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.7286e-04 - val_loss: 4.4281e-04\n",
      "Epoch 765/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8499e-04 - val_loss: 4.6800e-04\n",
      "Epoch 766/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9597e-04 - val_loss: 4.6732e-04\n",
      "Epoch 767/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.9645e-04 - val_loss: 4.7719e-04\n",
      "Epoch 768/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 4.0299e-04 - val_loss: 5.1611e-04\n",
      "Epoch 769/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.8072e-04 - val_loss: 4.6565e-04\n",
      "Epoch 770/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 3.5077e-04 - val_loss: 4.1170e-04\n",
      "Epoch 771/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3382e-04 - val_loss: 4.0736e-04\n",
      "Epoch 772/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.3858e-04 - val_loss: 4.1494e-04\n",
      "Epoch 773/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.2782e-04 - val_loss: 4.0623e-04\n",
      "Epoch 774/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0152e-04 - val_loss: 3.8839e-04\n",
      "Epoch 775/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0472e-04 - val_loss: 4.4098e-04\n",
      "Epoch 776/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.2639e-04 - val_loss: 4.5632e-04\n",
      "Epoch 777/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.4226e-04 - val_loss: 4.0394e-04\n",
      "Epoch 778/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5323e-04 - val_loss: 4.2278e-04\n",
      "Epoch 779/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3247e-04 - val_loss: 3.8197e-04\n",
      "Epoch 780/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2908e-04 - val_loss: 4.2795e-04\n",
      "Epoch 781/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0925e-04 - val_loss: 4.7163e-04\n",
      "Epoch 782/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0751e-04 - val_loss: 3.6631e-04\n",
      "Epoch 783/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.2430e-04 - val_loss: 3.8870e-04\n",
      "Epoch 784/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.3616e-04 - val_loss: 4.0653e-04\n",
      "Epoch 785/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2473e-04 - val_loss: 3.9454e-04\n",
      "Epoch 786/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.2218e-04 - val_loss: 3.8442e-04\n",
      "Epoch 787/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.2840e-04 - val_loss: 3.6434e-04\n",
      "Epoch 788/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.2929e-04 - val_loss: 4.1865e-04\n",
      "Epoch 789/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 4.0869e-04 - val_loss: 4.5506e-04\n",
      "Epoch 790/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.9517e-04 - val_loss: 4.4470e-04\n",
      "Epoch 791/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.5099e-04 - val_loss: 4.1668e-04\n",
      "Epoch 792/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9993e-04 - val_loss: 3.6670e-04\n",
      "Epoch 793/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7470e-04 - val_loss: 3.5022e-04\n",
      "Epoch 794/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8124e-04 - val_loss: 3.7655e-04\n",
      "Epoch 795/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9382e-04 - val_loss: 3.4410e-04\n",
      "Epoch 796/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8305e-04 - val_loss: 3.2916e-04\n",
      "Epoch 797/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 2.7657e-04 - val_loss: 3.7498e-04\n",
      "Epoch 798/1000\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 2.7233e-04 - val_loss: 3.4120e-04\n",
      "Epoch 799/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7475e-04 - val_loss: 3.5027e-04\n",
      "Epoch 800/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9834e-04 - val_loss: 3.4592e-04\n",
      "Epoch 801/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9726e-04 - val_loss: 3.5560e-04\n",
      "Epoch 802/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9044e-04 - val_loss: 3.1558e-04\n",
      "Epoch 803/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.8156e-04 - val_loss: 4.1130e-04\n",
      "Epoch 804/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.9094e-04 - val_loss: 3.3879e-04\n",
      "Epoch 805/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.1157e-04 - val_loss: 3.8798e-04\n",
      "Epoch 806/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0038e-04 - val_loss: 3.8966e-04\n",
      "Epoch 807/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0332e-04 - val_loss: 3.5927e-04\n",
      "Epoch 808/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9415e-04 - val_loss: 3.5081e-04\n",
      "Epoch 809/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1360e-04 - val_loss: 4.0097e-04\n",
      "Epoch 810/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.8895e-04 - val_loss: 3.6925e-04\n",
      "Epoch 811/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.9134e-04 - val_loss: 3.5293e-04\n",
      "Epoch 812/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.2997e-04 - val_loss: 4.0596e-04\n",
      "Epoch 813/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.2770e-04 - val_loss: 3.7395e-04\n",
      "Epoch 814/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9721e-04 - val_loss: 3.5675e-04\n",
      "Epoch 815/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1617e-04 - val_loss: 3.5697e-04\n",
      "Epoch 816/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9648e-04 - val_loss: 3.8126e-04\n",
      "Epoch 817/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.9073e-04 - val_loss: 3.2732e-04\n",
      "Epoch 818/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7165e-04 - val_loss: 3.3471e-04\n",
      "Epoch 819/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 2.8570e-04 - val_loss: 3.5412e-04\n",
      "Epoch 820/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.8817e-04 - val_loss: 3.6096e-04\n",
      "Epoch 821/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0886e-04 - val_loss: 3.5491e-04\n",
      "Epoch 822/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0964e-04 - val_loss: 3.9113e-04\n",
      "Epoch 823/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.7978e-04 - val_loss: 3.5046e-04\n",
      "Epoch 824/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9839e-04 - val_loss: 3.3937e-04\n",
      "Epoch 825/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.7892e-04 - val_loss: 3.3932e-04\n",
      "Epoch 826/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.7552e-04 - val_loss: 3.7052e-04\n",
      "Epoch 827/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0261e-04 - val_loss: 3.7041e-04\n",
      "Epoch 828/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9556e-04 - val_loss: 3.4423e-04\n",
      "Epoch 829/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8271e-04 - val_loss: 3.4565e-04\n",
      "Epoch 830/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8638e-04 - val_loss: 3.5376e-04\n",
      "Epoch 831/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8480e-04 - val_loss: 3.0819e-04\n",
      "Epoch 832/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9993e-04 - val_loss: 3.2730e-04\n",
      "Epoch 833/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 2.7917e-04 - val_loss: 3.6461e-04\n",
      "Epoch 834/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9335e-04 - val_loss: 3.4892e-04\n",
      "Epoch 835/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1065e-04 - val_loss: 3.6249e-04\n",
      "Epoch 836/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 3.0683e-04 - val_loss: 3.5026e-04\n",
      "Epoch 837/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 2.9432e-04 - val_loss: 3.3777e-04\n",
      "Epoch 838/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.8232e-04 - val_loss: 3.6284e-04\n",
      "Epoch 839/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.2783e-04 - val_loss: 3.4599e-04\n",
      "Epoch 840/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.8322e-04 - val_loss: 3.4965e-04\n",
      "Epoch 841/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0125e-04 - val_loss: 3.4891e-04\n",
      "Epoch 842/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.9177e-04 - val_loss: 3.7895e-04\n",
      "Epoch 843/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0681e-04 - val_loss: 3.3145e-04\n",
      "Epoch 844/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8900e-04 - val_loss: 3.7384e-04\n",
      "Epoch 845/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.3710e-04 - val_loss: 4.3112e-04\n",
      "Epoch 846/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3588e-04 - val_loss: 4.4758e-04\n",
      "Epoch 847/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.3694e-04 - val_loss: 4.5850e-04\n",
      "Epoch 848/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.1600e-04 - val_loss: 3.8762e-04\n",
      "Epoch 849/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.5211e-04 - val_loss: 3.9349e-04\n",
      "Epoch 850/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1572e-04 - val_loss: 3.5906e-04\n",
      "Epoch 851/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8092e-04 - val_loss: 3.4740e-04\n",
      "Epoch 852/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7814e-04 - val_loss: 3.6853e-04\n",
      "Epoch 853/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7689e-04 - val_loss: 3.3230e-04\n",
      "Epoch 854/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 2.8095e-04 - val_loss: 3.4509e-04\n",
      "Epoch 855/1000\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 2.6849e-04 - val_loss: 3.2587e-04\n",
      "Epoch 856/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.9688e-04 - val_loss: 3.5538e-04\n",
      "Epoch 857/1000\n",
      "54/54 [==============================] - 1s 12ms/step - loss: 3.0456e-04 - val_loss: 4.0951e-04\n",
      "Epoch 858/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0190e-04 - val_loss: 3.4044e-04\n",
      "Epoch 859/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6356e-04 - val_loss: 3.2078e-04\n",
      "Epoch 860/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7055e-04 - val_loss: 3.2923e-04\n",
      "Epoch 861/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 2.6769e-04 - val_loss: 3.2289e-04\n",
      "Epoch 862/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.6762e-04 - val_loss: 3.6366e-04\n",
      "Epoch 863/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6578e-04 - val_loss: 3.5471e-04\n",
      "Epoch 864/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7557e-04 - val_loss: 3.3525e-04\n",
      "Epoch 865/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.1034e-04 - val_loss: 3.4077e-04\n",
      "Epoch 866/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0793e-04 - val_loss: 3.9192e-04\n",
      "Epoch 867/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.9243e-04 - val_loss: 3.4547e-04\n",
      "Epoch 868/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.7031e-04 - val_loss: 3.6099e-04\n",
      "Epoch 869/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.6544e-04 - val_loss: 3.2660e-04\n",
      "Epoch 870/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0285e-04 - val_loss: 3.4274e-04\n",
      "Epoch 871/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0550e-04 - val_loss: 3.4642e-04\n",
      "Epoch 872/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0969e-04 - val_loss: 3.6336e-04\n",
      "Epoch 873/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9600e-04 - val_loss: 3.4976e-04\n",
      "Epoch 874/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 2.8616e-04 - val_loss: 3.5215e-04\n",
      "Epoch 875/1000\n",
      "54/54 [==============================] - 1s 23ms/step - loss: 3.1035e-04 - val_loss: 3.8007e-04\n",
      "Epoch 876/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0063e-04 - val_loss: 3.5525e-04\n",
      "Epoch 877/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8680e-04 - val_loss: 3.5037e-04\n",
      "Epoch 878/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0586e-04 - val_loss: 3.5481e-04\n",
      "Epoch 879/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8870e-04 - val_loss: 3.3104e-04\n",
      "Epoch 880/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9303e-04 - val_loss: 3.4125e-04\n",
      "Epoch 881/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 2.9705e-04 - val_loss: 3.5683e-04\n",
      "Epoch 882/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.0000e-04 - val_loss: 3.5553e-04\n",
      "Epoch 883/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2552e-04 - val_loss: 3.8379e-04\n",
      "Epoch 884/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9886e-04 - val_loss: 3.7497e-04\n",
      "Epoch 885/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5735e-04 - val_loss: 4.2935e-04\n",
      "Epoch 886/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1755e-04 - val_loss: 3.4069e-04\n",
      "Epoch 887/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.3382e-04 - val_loss: 4.5848e-04\n",
      "Epoch 888/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0421e-04 - val_loss: 3.6153e-04\n",
      "Epoch 889/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.8583e-04 - val_loss: 3.5836e-04\n",
      "Epoch 890/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9265e-04 - val_loss: 3.7574e-04\n",
      "Epoch 891/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9338e-04 - val_loss: 3.7667e-04\n",
      "Epoch 892/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7000e-04 - val_loss: 3.3652e-04\n",
      "Epoch 893/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7746e-04 - val_loss: 3.2676e-04\n",
      "Epoch 894/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.6810e-04 - val_loss: 3.3053e-04\n",
      "Epoch 895/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8484e-04 - val_loss: 3.4716e-04\n",
      "Epoch 896/1000\n",
      "54/54 [==============================] - 1s 22ms/step - loss: 2.7804e-04 - val_loss: 3.6330e-04\n",
      "Epoch 897/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1160e-04 - val_loss: 3.8371e-04\n",
      "Epoch 898/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8971e-04 - val_loss: 3.6862e-04\n",
      "Epoch 899/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.7233e-04 - val_loss: 3.2136e-04\n",
      "Epoch 900/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.5717e-04 - val_loss: 2.9748e-04\n",
      "Epoch 901/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6733e-04 - val_loss: 3.5339e-04\n",
      "Epoch 902/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7888e-04 - val_loss: 3.8350e-04\n",
      "Epoch 903/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.8478e-04 - val_loss: 3.2450e-04\n",
      "Epoch 904/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.6750e-04 - val_loss: 3.1167e-04\n",
      "Epoch 905/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6633e-04 - val_loss: 3.3082e-04\n",
      "Epoch 906/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.8143e-04 - val_loss: 3.2764e-04\n",
      "Epoch 907/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.8229e-04 - val_loss: 3.4668e-04\n",
      "Epoch 908/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7508e-04 - val_loss: 3.5454e-04\n",
      "Epoch 909/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0258e-04 - val_loss: 3.9627e-04\n",
      "Epoch 910/1000\n",
      "54/54 [==============================] - 1s 24ms/step - loss: 3.1347e-04 - val_loss: 3.5604e-04\n",
      "Epoch 911/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8441e-04 - val_loss: 3.4512e-04\n",
      "Epoch 912/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.7833e-04 - val_loss: 3.6099e-04\n",
      "Epoch 913/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7591e-04 - val_loss: 3.4879e-04\n",
      "Epoch 914/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.5875e-04 - val_loss: 2.9947e-04\n",
      "Epoch 915/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6669e-04 - val_loss: 3.2625e-04\n",
      "Epoch 916/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.6955e-04 - val_loss: 3.3578e-04\n",
      "Epoch 917/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.6711e-04 - val_loss: 3.2870e-04\n",
      "Epoch 918/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6276e-04 - val_loss: 3.1539e-04\n",
      "Epoch 919/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7137e-04 - val_loss: 3.1715e-04\n",
      "Epoch 920/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7298e-04 - val_loss: 3.3922e-04\n",
      "Epoch 921/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.1774e-04 - val_loss: 3.7569e-04\n",
      "Epoch 922/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9127e-04 - val_loss: 3.2864e-04\n",
      "Epoch 923/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2048e-04 - val_loss: 3.8436e-04\n",
      "Epoch 924/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 3.1849e-04 - val_loss: 3.7934e-04\n",
      "Epoch 925/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1511e-04 - val_loss: 3.9909e-04\n",
      "Epoch 926/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0957e-04 - val_loss: 3.4452e-04\n",
      "Epoch 927/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2365e-04 - val_loss: 3.8884e-04\n",
      "Epoch 928/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.2358e-04 - val_loss: 3.9948e-04\n",
      "Epoch 929/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4434e-04 - val_loss: 4.5561e-04\n",
      "Epoch 930/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1435e-04 - val_loss: 4.5921e-04\n",
      "Epoch 931/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.4116e-04 - val_loss: 3.7242e-04\n",
      "Epoch 932/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2242e-04 - val_loss: 3.7416e-04\n",
      "Epoch 933/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0325e-04 - val_loss: 3.7663e-04\n",
      "Epoch 934/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.1229e-04 - val_loss: 3.9230e-04\n",
      "Epoch 935/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.2653e-04 - val_loss: 3.6921e-04\n",
      "Epoch 936/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9108e-04 - val_loss: 3.9953e-04\n",
      "Epoch 937/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 3.0082e-04 - val_loss: 3.4895e-04\n",
      "Epoch 938/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 2.8580e-04 - val_loss: 3.4638e-04\n",
      "Epoch 939/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8246e-04 - val_loss: 3.1668e-04\n",
      "Epoch 940/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7651e-04 - val_loss: 3.3822e-04\n",
      "Epoch 941/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8906e-04 - val_loss: 3.3511e-04\n",
      "Epoch 942/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9967e-04 - val_loss: 3.2649e-04\n",
      "Epoch 943/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.0539e-04 - val_loss: 3.6522e-04\n",
      "Epoch 944/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.6181e-04 - val_loss: 3.9117e-04\n",
      "Epoch 945/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.0835e-04 - val_loss: 3.5489e-04\n",
      "Epoch 946/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.3765e-04 - val_loss: 3.9647e-04\n",
      "Epoch 947/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0413e-04 - val_loss: 3.3449e-04\n",
      "Epoch 948/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.0677e-04 - val_loss: 3.9741e-04\n",
      "Epoch 949/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0866e-04 - val_loss: 3.4721e-04\n",
      "Epoch 950/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9104e-04 - val_loss: 3.2069e-04\n",
      "Epoch 951/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.9109e-04 - val_loss: 3.0816e-04\n",
      "Epoch 952/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 2.6800e-04 - val_loss: 3.4524e-04\n",
      "Epoch 953/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8375e-04 - val_loss: 3.7229e-04\n",
      "Epoch 954/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9757e-04 - val_loss: 4.9133e-04\n",
      "Epoch 955/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.5694e-04 - val_loss: 4.1806e-04\n",
      "Epoch 956/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.4442e-04 - val_loss: 4.3705e-04\n",
      "Epoch 957/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.2698e-04 - val_loss: 3.4240e-04\n",
      "Epoch 958/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.1952e-04 - val_loss: 3.8398e-04\n",
      "Epoch 959/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.5262e-04 - val_loss: 4.0857e-04\n",
      "Epoch 960/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4044e-04 - val_loss: 4.3044e-04\n",
      "Epoch 961/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.3495e-04 - val_loss: 3.4430e-04\n",
      "Epoch 962/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.9367e-04 - val_loss: 3.4167e-04\n",
      "Epoch 963/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.7774e-04 - val_loss: 3.2808e-04\n",
      "Epoch 964/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.8636e-04 - val_loss: 3.1255e-04\n",
      "Epoch 965/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 2.6777e-04 - val_loss: 3.0088e-04\n",
      "Epoch 966/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8828e-04 - val_loss: 3.3834e-04\n",
      "Epoch 967/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.8854e-04 - val_loss: 4.0661e-04\n",
      "Epoch 968/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0013e-04 - val_loss: 3.4804e-04\n",
      "Epoch 969/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.9382e-04 - val_loss: 3.2713e-04\n",
      "Epoch 970/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0214e-04 - val_loss: 3.6799e-04\n",
      "Epoch 971/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 3.1038e-04 - val_loss: 3.3127e-04\n",
      "Epoch 972/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 3.0338e-04 - val_loss: 3.8576e-04\n",
      "Epoch 973/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.8919e-04 - val_loss: 3.7840e-04\n",
      "Epoch 974/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7428e-04 - val_loss: 3.3558e-04\n",
      "Epoch 975/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.5412e-04 - val_loss: 3.1617e-04\n",
      "Epoch 976/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.7397e-04 - val_loss: 3.5983e-04\n",
      "Epoch 977/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.6488e-04 - val_loss: 3.0320e-04\n",
      "Epoch 978/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.5650e-04 - val_loss: 3.1321e-04\n",
      "Epoch 979/1000\n",
      "54/54 [==============================] - 1s 18ms/step - loss: 2.7308e-04 - val_loss: 2.9517e-04\n",
      "Epoch 980/1000\n",
      "54/54 [==============================] - 1s 21ms/step - loss: 3.1074e-04 - val_loss: 4.0300e-04\n",
      "Epoch 981/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.4237e-04 - val_loss: 4.1825e-04\n",
      "Epoch 982/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 3.0726e-04 - val_loss: 3.4718e-04\n",
      "Epoch 983/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6831e-04 - val_loss: 3.0800e-04\n",
      "Epoch 984/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.6812e-04 - val_loss: 3.1732e-04\n",
      "Epoch 985/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.6395e-04 - val_loss: 3.2661e-04\n",
      "Epoch 986/1000\n",
      "54/54 [==============================] - 1s 20ms/step - loss: 2.8419e-04 - val_loss: 4.3054e-04\n",
      "Epoch 987/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 3.1608e-04 - val_loss: 4.4271e-04\n",
      "Epoch 988/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.7739e-04 - val_loss: 3.0806e-04\n",
      "Epoch 989/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.5937e-04 - val_loss: 3.4122e-04\n",
      "Epoch 990/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.8140e-04 - val_loss: 3.7535e-04\n",
      "Epoch 991/1000\n",
      "54/54 [==============================] - 1s 14ms/step - loss: 2.6523e-04 - val_loss: 3.5213e-04\n",
      "Epoch 992/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 3.0261e-04 - val_loss: 3.2600e-04\n",
      "Epoch 993/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.7623e-04 - val_loss: 3.2767e-04\n",
      "Epoch 994/1000\n",
      "54/54 [==============================] - 1s 19ms/step - loss: 2.5225e-04 - val_loss: 2.8580e-04\n",
      "Epoch 995/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.3781e-04 - val_loss: 2.8097e-04\n",
      "Epoch 996/1000\n",
      "54/54 [==============================] - 1s 16ms/step - loss: 2.4394e-04 - val_loss: 2.9954e-04\n",
      "Epoch 997/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.5215e-04 - val_loss: 3.1960e-04\n",
      "Epoch 998/1000\n",
      "54/54 [==============================] - 1s 17ms/step - loss: 2.6722e-04 - val_loss: 3.0070e-04\n",
      "Epoch 999/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.4782e-04 - val_loss: 3.4935e-04\n",
      "Epoch 1000/1000\n",
      "54/54 [==============================] - 1s 15ms/step - loss: 2.5018e-04 - val_loss: 3.1518e-04\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-10-24 01:18:08           64\n",
      "config.json                                    2023-10-24 01:18:08         2633\n",
      "variables.h5                                   2023-10-24 01:18:08       461544\n"
     ]
    }
   ],
   "source": [
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_dataframe_list[0].reset_index(drop=True),\n",
    "                  b_dataframe_list[1].reset_index(drop=True),\n",
    "                  b_dataframe_list[2].reset_index(drop=True)])\n",
    "    \n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    xgb = XGBoost_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    joblib.dump(xgb, 'my_models/models/Carbon_Intensity_Power_model_xgb.pkl')\n",
    "if model_type == 'lgb':\n",
    "    lgb = LightGBM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_lightgbm.pkl')\n",
    "if model_type == 'fusion':\n",
    "    lgb_model  = LightGBM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    lstm_model = LSTM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "        \n",
    "    joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/Carbon_Intensity_model_2.pkl')\n",
    "    joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/Carbon_Intensity_model_2.pkl')\n",
    "\n",
    "    #fusion_model = Fusion_Model(b,hyperparameter,'carbon_intensity',lstm_model,lgb_model)\n",
    "    #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/Carbon_Intensity_model'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99ab8e-9d57-4554-96b5-6f69cc0041f3",
   "metadata": {},
   "source": [
    "### 2.) Solar Generation (W/kW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d128e16-9ebc-4318-864e-53f440826011",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 7s 103ms/step - loss: 96814.4297 - val_loss: 108132.9688\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 96550.0312 - val_loss: 107741.0156\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 96058.8203 - val_loss: 107024.7188\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 95315.5391 - val_loss: 106081.4375\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 94409.9922 - val_loss: 105077.7812\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 93466.3438 - val_loss: 104164.4844\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 92736.6953 - val_loss: 103448.4844\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 92113.5312 - val_loss: 102886.1094\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 91626.8359 - val_loss: 102398.9453\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 91202.0312 - val_loss: 101973.3906\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 90811.8672 - val_loss: 101579.8359\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 90459.0469 - val_loss: 101205.3203\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 90118.1484 - val_loss: 100851.6875\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 89799.3828 - val_loss: 100498.2812\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 89475.6953 - val_loss: 100170.2812\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 89172.3438 - val_loss: 99844.0938\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88873.5156 - val_loss: 99521.8047\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88574.2344 - val_loss: 99212.0938\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 88288.4922 - val_loss: 98897.3594\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88003.5781 - val_loss: 98584.4844\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 87716.1406 - val_loss: 98283.4141\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 87436.7578 - val_loss: 97985.4062\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 87164.8438 - val_loss: 97682.0703\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86886.7188 - val_loss: 97389.2422\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 86618.9453 - val_loss: 97092.6875\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 86344.6406 - val_loss: 96807.5859\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86079.9531 - val_loss: 96520.3359\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85812.7422 - val_loss: 96237.8906\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85553.3906 - val_loss: 95949.7109\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 85290.9062 - val_loss: 95665.4688\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 85027.7188 - val_loss: 95389.2188\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 84774.6094 - val_loss: 95105.0312\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 84513.7812 - val_loss: 94830.4141\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 84259.7891 - val_loss: 94555.0859\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 84005.1406 - val_loss: 94282.7188\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 83759.3750 - val_loss: 94000.8906\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 83498.0547 - val_loss: 93740.0312\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 83253.5312 - val_loss: 93469.9844\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 83007.9141 - val_loss: 93197.4688\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 82754.5625 - val_loss: 92937.5781\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 82514.8047 - val_loss: 92666.4453\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 82268.5312 - val_loss: 92399.5781\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 82022.3516 - val_loss: 92138.2188\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 81779.3438 - val_loss: 91878.1562\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 81542.7578 - val_loss: 91610.0312\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 81298.2812 - val_loss: 91349.2891\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 81056.2734 - val_loss: 91093.7266\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 80819.0625 - val_loss: 90835.5547\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 80581.5938 - val_loss: 90577.3984\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 80346.0469 - val_loss: 90316.0938\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 80106.2188 - val_loss: 90057.5859\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 79868.2344 - val_loss: 89803.6875\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 79636.8594 - val_loss: 89542.2031\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 79400.2031 - val_loss: 89285.3125\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 79163.8438 - val_loss: 89036.2109\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 78931.3203 - val_loss: 88785.1484\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 78701.4844 - val_loss: 88529.9297\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 78467.5469 - val_loss: 88278.8359\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 78237.2500 - val_loss: 88023.0547\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78005.5078 - val_loss: 87770.7578\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 77772.9297 - val_loss: 87525.5859\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 77547.5234 - val_loss: 87275.0078\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 77319.9453 - val_loss: 87025.3594\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 77090.3438 - val_loss: 86781.8203\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 76865.3594 - val_loss: 86536.2031\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 76641.1328 - val_loss: 86287.4688\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 76413.5312 - val_loss: 86047.5156\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 76192.9688 - val_loss: 85800.4141\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 75970.1562 - val_loss: 85553.0859\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 75741.1172 - val_loss: 85320.4844\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 75525.3750 - val_loss: 85075.6562\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75302.0156 - val_loss: 84836.2031\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75080.8047 - val_loss: 84600.4141\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 74867.2422 - val_loss: 84351.7500\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 74641.2109 - val_loss: 84115.8203\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 74425.5391 - val_loss: 83877.1094\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 74207.6562 - val_loss: 83639.2812\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 73989.0391 - val_loss: 83406.0703\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 73772.2812 - val_loss: 83172.3438\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 73559.3516 - val_loss: 82934.3359\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 73344.2109 - val_loss: 82697.4141\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 73128.5469 - val_loss: 82463.1797\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72912.5234 - val_loss: 82235.2500\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72705.1484 - val_loss: 81995.5625\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 72487.8438 - val_loss: 81767.2656\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72278.0312 - val_loss: 81536.0312\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 72061.8047 - val_loss: 81314.0547\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71860.8594 - val_loss: 81075.9766\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71644.5391 - val_loss: 80852.3438\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 71438.7031 - val_loss: 80619.1328\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71228.3516 - val_loss: 80390.1641\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71020.1641 - val_loss: 80160.9453\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 70813.4766 - val_loss: 79930.7344\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 70603.3438 - val_loss: 79707.0156\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 70396.8750 - val_loss: 79484.0703\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 70192.7188 - val_loss: 79258.1094\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 69987.3438 - val_loss: 79032.3672\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 69781.4141 - val_loss: 78809.6406\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 69576.5938 - val_loss: 78588.2891\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 69374.7656 - val_loss: 78363.8516\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 69167.3359 - val_loss: 78149.2188\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 68971.7266 - val_loss: 77920.2656\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68764.4062 - val_loss: 77702.1797\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68565.3672 - val_loss: 77479.6328\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68364.9375 - val_loss: 77256.5547\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68158.7109 - val_loss: 77046.4062\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67968.9375 - val_loss: 76822.5234\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67767.9688 - val_loss: 76599.5938\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 67565.6484 - val_loss: 76385.6484\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 67366.1484 - val_loss: 76173.5000\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67170.8125 - val_loss: 75952.3359\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 66971.1562 - val_loss: 75737.1406\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 66769.8438 - val_loss: 75526.3281\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 66578.1641 - val_loss: 75302.5469\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 66374.6484 - val_loss: 75092.9531\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 66181.6406 - val_loss: 74876.5312\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 65984.9531 - val_loss: 74664.5000\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65792.6562 - val_loss: 74445.6797\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 65593.7500 - val_loss: 74235.7734\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 65400.9922 - val_loss: 74022.2031\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65204.8125 - val_loss: 73812.2969\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 65012.3906 - val_loss: 73603.1094\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 64821.2070 - val_loss: 73389.9062\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 64628.4219 - val_loss: 73178.8047\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 64437.4297 - val_loss: 72968.1562\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 64244.2852 - val_loss: 72761.4219\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 64056.0273 - val_loss: 72550.4453\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 63864.0078 - val_loss: 72342.5859\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 63674.1680 - val_loss: 72137.6875\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 63484.7344 - val_loss: 71933.3203\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 63296.0547 - val_loss: 71724.9688\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 63105.9727 - val_loss: 71520.2188\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 62920.5820 - val_loss: 71310.3438\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62730.7656 - val_loss: 71104.5312\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 62542.0977 - val_loss: 70902.5469\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 62356.4219 - val_loss: 70697.6016\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 62172.3594 - val_loss: 70488.6328\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61983.3125 - val_loss: 70286.1953\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 61794.6797 - val_loss: 70086.2188\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61614.5430 - val_loss: 69880.3047\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 61428.7773 - val_loss: 69676.7812\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 61243.8281 - val_loss: 69475.0391\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61064.4023 - val_loss: 69269.4688\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60878.1172 - val_loss: 69068.7812\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60697.6875 - val_loss: 68871.6328\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60516.2031 - val_loss: 68669.3750\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60328.8047 - val_loss: 68473.8438\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 60147.0898 - val_loss: 68275.0859\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 59966.9023 - val_loss: 68078.7500\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 59787.4844 - val_loss: 67879.0000\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 59607.7305 - val_loss: 67681.9141\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 59428.7656 - val_loss: 67479.5547\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 59248.8398 - val_loss: 67282.5078\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 59071.9375 - val_loss: 67088.9062\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 58893.2344 - val_loss: 66890.9141\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 58716.4922 - val_loss: 66696.8438\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 58537.5781 - val_loss: 66499.0781\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 58362.5547 - val_loss: 66300.5312\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58181.6016 - val_loss: 66114.3438\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58006.9141 - val_loss: 65921.0703\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57830.5352 - val_loss: 65726.7891\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57656.5273 - val_loss: 65528.1250\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57477.9844 - val_loss: 65342.9805\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57304.5156 - val_loss: 65150.3672\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 57129.8281 - val_loss: 64961.6094\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 56957.1016 - val_loss: 64771.8906\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 56786.5898 - val_loss: 64576.8828\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 56611.4883 - val_loss: 64387.5195\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 56442.7031 - val_loss: 64191.5273\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 56269.8398 - val_loss: 64005.8320\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 56096.6367 - val_loss: 63819.1953\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 55925.5352 - val_loss: 63629.6094\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55754.6953 - val_loss: 63440.0352\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 55582.0430 - val_loss: 63254.3398\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 55415.8672 - val_loss: 63061.3203\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 55242.6680 - val_loss: 62875.7969\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55074.1641 - val_loss: 62690.2344\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 54907.2188 - val_loss: 62501.0547\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 54734.5469 - val_loss: 62317.3477\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54568.8125 - val_loss: 62131.2773\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54402.6680 - val_loss: 61947.0352\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 54230.9258 - val_loss: 61767.2500\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 54069.2148 - val_loss: 61578.6719\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 53896.9531 - val_loss: 61396.7852\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 53733.2812 - val_loss: 61205.5781\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 53564.7031 - val_loss: 61035.1445\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53407.4219 - val_loss: 60840.8828\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 53238.5664 - val_loss: 60660.2422\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53074.8164 - val_loss: 60475.0977\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 52907.4727 - val_loss: 60298.4219\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52742.5820 - val_loss: 60115.6172\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 52583.0039 - val_loss: 59927.6797\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52418.6484 - val_loss: 59746.3047\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 52252.9102 - val_loss: 59579.5273\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 52091.1953 - val_loss: 59395.9453\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51928.3359 - val_loss: 59209.4531\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51762.6875 - val_loss: 59035.6602\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 51605.0820 - val_loss: 58852.2500\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51441.5469 - val_loss: 58672.2500\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51281.2422 - val_loss: 58496.6523\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 51126.6680 - val_loss: 58310.6250\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 50965.5703 - val_loss: 58144.7656\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 50802.7656 - val_loss: 57959.6797\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50643.6289 - val_loss: 57794.1250\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 50482.4219 - val_loss: 57603.7617\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50324.2656 - val_loss: 57447.2383\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50164.2266 - val_loss: 57248.9883\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 50009.3945 - val_loss: 57068.8008\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 49856.8594 - val_loss: 56888.4258\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49700.0898 - val_loss: 56717.4648\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49539.3750 - val_loss: 56550.5781\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 49402.3984 - val_loss: 56371.7539\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49227.6016 - val_loss: 56191.4023\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 49068.3594 - val_loss: 56024.2344\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 48916.9180 - val_loss: 55847.2422\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 48755.0039 - val_loss: 55697.9531\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 48601.2344 - val_loss: 55527.5781\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 48450.0547 - val_loss: 55342.2734\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 48294.8633 - val_loss: 55155.0391\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 48136.1875 - val_loss: 54994.8828\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 47994.8125 - val_loss: 54814.1016\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 47833.0078 - val_loss: 54647.3906\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47678.1641 - val_loss: 54475.9648\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 47528.1367 - val_loss: 54334.4531\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47386.2266 - val_loss: 54136.7031\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47226.6250 - val_loss: 53964.7109\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 47073.3594 - val_loss: 53807.5820\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46923.6289 - val_loss: 53632.6602\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46764.6914 - val_loss: 53474.2852\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 46645.9180 - val_loss: 53307.2031\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46493.5195 - val_loss: 53127.2266\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 46319.3672 - val_loss: 52999.4062\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 46177.6016 - val_loss: 52823.8555\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 46028.4297 - val_loss: 52666.8164\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 45873.1250 - val_loss: 52472.9297\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 45725.9727 - val_loss: 52307.2344\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 45575.7188 - val_loss: 52167.2344\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 45430.9102 - val_loss: 51986.6328\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 45280.5781 - val_loss: 51829.3867\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 45130.5469 - val_loss: 51664.2070\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 44988.1875 - val_loss: 51496.0703\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44836.6328 - val_loss: 51338.4453\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44691.6250 - val_loss: 51172.6602\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44545.1719 - val_loss: 51009.6641\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44401.4453 - val_loss: 50844.2500\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44255.1016 - val_loss: 50686.0859\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 44112.1953 - val_loss: 50524.2070\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 43964.4102 - val_loss: 50366.8867\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43822.4648 - val_loss: 50203.6680\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 43679.4531 - val_loss: 50037.7930\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 43533.8945 - val_loss: 49887.6953\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 43392.1133 - val_loss: 49715.9727\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 43250.7578 - val_loss: 49555.9297\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 43106.9844 - val_loss: 49404.7188\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 42964.9727 - val_loss: 49241.7070\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 42825.4219 - val_loss: 49079.5156\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42680.4219 - val_loss: 48932.4141\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 42543.7031 - val_loss: 48771.5430\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 42402.3164 - val_loss: 48636.8047\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 42263.5273 - val_loss: 48457.3203\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42121.2773 - val_loss: 48303.1055\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41984.5039 - val_loss: 48147.6172\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41843.6445 - val_loss: 47988.5547\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41704.7148 - val_loss: 47847.7578\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41566.4844 - val_loss: 47669.8789\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 41424.3398 - val_loss: 47533.9023\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 41286.7266 - val_loss: 47358.7578\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41169.3086 - val_loss: 47212.3320\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 41124.5625 - val_loss: 47056.9531\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40927.6406 - val_loss: 46916.9180\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40778.8789 - val_loss: 46805.1328\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 40631.5195 - val_loss: 46637.2500\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 40479.9062 - val_loss: 46446.8633\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40343.7305 - val_loss: 46325.1094\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40200.3516 - val_loss: 46180.9336\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 40068.1016 - val_loss: 46029.5703\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39932.8594 - val_loss: 45875.9805\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39795.6875 - val_loss: 45710.3477\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39660.5430 - val_loss: 45561.6055\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39527.4414 - val_loss: 45412.5195\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39393.8750 - val_loss: 45251.9023\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39261.2930 - val_loss: 45099.2070\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 39126.7305 - val_loss: 44966.1445\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 38996.3438 - val_loss: 44784.9141\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 38860.7109 - val_loss: 44667.7969\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 38729.8594 - val_loss: 44518.6797\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 38593.7227 - val_loss: 44373.0117\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 38469.5977 - val_loss: 44228.8594\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 38334.8281 - val_loss: 44082.1055\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 38207.2344 - val_loss: 43933.0547\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 38074.8398 - val_loss: 43788.8789\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37944.7109 - val_loss: 43639.3203\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37812.1094 - val_loss: 43493.8711\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 37682.9805 - val_loss: 43348.2969\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 37554.5078 - val_loss: 43200.9648\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 37422.8164 - val_loss: 43062.5156\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 37297.3594 - val_loss: 42915.4492\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 37169.9023 - val_loss: 42767.4727\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37043.4023 - val_loss: 42634.7773\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 36919.3281 - val_loss: 42476.0781\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 36783.7031 - val_loss: 42335.0703\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 36658.7578 - val_loss: 42191.8828\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 36536.7539 - val_loss: 42032.7070\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 36410.3359 - val_loss: 41903.5898\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 36281.4219 - val_loss: 41757.2500\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 36156.5156 - val_loss: 41593.6523\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 36029.6016 - val_loss: 41455.1914\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 35904.7695 - val_loss: 41343.5742\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 35780.1445 - val_loss: 41191.4180\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 35655.3203 - val_loss: 41058.2539\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 35530.8594 - val_loss: 40921.4922\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35407.5156 - val_loss: 40777.2188\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 35282.7344 - val_loss: 40645.5664\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 35161.1406 - val_loss: 40506.2656\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 35036.4219 - val_loss: 40368.3125\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 34914.6328 - val_loss: 40229.5273\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34796.5469 - val_loss: 40088.2695\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34673.3398 - val_loss: 39957.2383\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34550.8633 - val_loss: 39803.0938\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34431.1953 - val_loss: 39672.2695\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34309.6523 - val_loss: 39535.1211\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34189.7344 - val_loss: 39391.1758\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34069.1914 - val_loss: 39244.0820\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 33949.3086 - val_loss: 39104.1875\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 33833.9688 - val_loss: 38975.2734\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 33714.3320 - val_loss: 38844.7578\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 33597.7500 - val_loss: 38712.9570\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 33484.2383 - val_loss: 38623.0195\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 33374.3281 - val_loss: 38450.4453\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 33247.7773 - val_loss: 38320.2578\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 33188.9961 - val_loss: 38182.7500\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 33230.5273 - val_loss: 38046.3047\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 33010.7305 - val_loss: 38018.5156\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 32799.9922 - val_loss: 37803.2148\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 32743.8672 - val_loss: 37658.3203\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 32594.5898 - val_loss: 37559.9883\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32500.1289 - val_loss: 37404.6680\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32334.9863 - val_loss: 37261.9844\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32243.1973 - val_loss: 37256.9531\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32117.3887 - val_loss: 37040.9023\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 31998.3340 - val_loss: 36875.9062\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 31859.6953 - val_loss: 36761.7227\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 31752.4551 - val_loss: 36684.6289\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 31666.8086 - val_loss: 36514.0859\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 31526.5352 - val_loss: 36364.0703\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 31408.2500 - val_loss: 36238.7422\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 31309.3262 - val_loss: 36152.8984\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 31193.8477 - val_loss: 36056.0000\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 31086.3828 - val_loss: 35855.0352\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30971.7715 - val_loss: 35730.2344\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 30845.3926 - val_loss: 35647.3047\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30735.1641 - val_loss: 35479.1758\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 30647.4141 - val_loss: 35355.7070\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30514.9023 - val_loss: 35245.5469\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30407.3965 - val_loss: 35138.2031\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30295.9238 - val_loss: 35025.2773\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 30194.2109 - val_loss: 34886.4531\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30076.7402 - val_loss: 34757.7656\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29962.5352 - val_loss: 34639.3555\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 29867.5898 - val_loss: 34515.1406\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 29754.0527 - val_loss: 34389.9844\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 29640.1387 - val_loss: 34236.7422\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 29533.7051 - val_loss: 34103.5039\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29428.0586 - val_loss: 33985.6680\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 29320.1738 - val_loss: 33868.8359\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 29211.1250 - val_loss: 33757.1719\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 29108.6348 - val_loss: 33630.3477\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 29002.5098 - val_loss: 33526.7227\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 28895.8340 - val_loss: 33395.8281\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28794.5410 - val_loss: 33257.8242\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28685.9902 - val_loss: 33143.9570\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 28584.6406 - val_loss: 33025.5234\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28477.7715 - val_loss: 32912.5508\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28373.3828 - val_loss: 32798.2773\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28271.1328 - val_loss: 32684.9453\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28166.6934 - val_loss: 32573.6562\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 28066.6816 - val_loss: 32459.5723\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 27962.5273 - val_loss: 32350.4590\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 27854.6484 - val_loss: 32241.3711\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27750.9883 - val_loss: 32121.2500\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27651.7910 - val_loss: 32006.5391\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 27567.9336 - val_loss: 31864.5449\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27522.6367 - val_loss: 31775.6641\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 27372.5352 - val_loss: 31663.6289\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27258.5312 - val_loss: 31708.8359\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27142.8203 - val_loss: 31402.2188\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27081.8574 - val_loss: 31276.4102\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26947.5957 - val_loss: 31187.0176\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 26834.4258 - val_loss: 31069.2012\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 26744.6016 - val_loss: 30940.8672\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26636.0723 - val_loss: 30827.4160\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 26528.6445 - val_loss: 30729.7773\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26428.4922 - val_loss: 30601.7500\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 26330.3008 - val_loss: 30485.7266\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 26230.2812 - val_loss: 30346.8828\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26130.0195 - val_loss: 30240.3086\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26032.8047 - val_loss: 30137.9375\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25935.8574 - val_loss: 30031.9590\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 25834.8711 - val_loss: 29912.1875\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25741.2559 - val_loss: 29806.7402\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25641.7266 - val_loss: 29702.4199\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25544.9785 - val_loss: 29584.0078\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25435.6465 - val_loss: 29474.2852\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25338.0488 - val_loss: 29361.3203\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25255.5117 - val_loss: 29248.4453\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25146.1035 - val_loss: 29136.8301\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 25046.9785 - val_loss: 29028.1172\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 24942.8047 - val_loss: 28921.2637\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 24858.5820 - val_loss: 28815.8477\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 24765.1152 - val_loss: 28695.8926\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 24662.7227 - val_loss: 28597.4746\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 24563.5762 - val_loss: 28454.3613\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 24466.4492 - val_loss: 28359.6934\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24374.2578 - val_loss: 28247.6914\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24276.0293 - val_loss: 28142.3164\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24250.5371 - val_loss: 28111.8652\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24145.5449 - val_loss: 27973.0859\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24059.1816 - val_loss: 27869.6973\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23918.8691 - val_loss: 27712.2168\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 23815.2188 - val_loss: 27623.2266\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23716.9238 - val_loss: 27497.1895\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23641.8516 - val_loss: 27389.5273\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23544.8984 - val_loss: 27302.2090\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23450.3848 - val_loss: 27197.5137\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 23354.3262 - val_loss: 27101.8848\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 23282.6211 - val_loss: 26986.5547\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 23176.5703 - val_loss: 26877.6562\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23080.0293 - val_loss: 26786.7598\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 22986.4590 - val_loss: 26687.5176\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 22897.5664 - val_loss: 26585.6211\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 22801.5938 - val_loss: 26486.8770\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22722.6172 - val_loss: 26379.5859\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 22628.5625 - val_loss: 26275.3281\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 22540.6309 - val_loss: 26178.0137\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22446.3027 - val_loss: 26071.2637\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 22362.6289 - val_loss: 25970.3262\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 22265.8965 - val_loss: 25873.0957\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22172.6641 - val_loss: 25761.1328\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 22089.2461 - val_loss: 25658.3535\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 22026.2266 - val_loss: 25541.9785\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21933.2539 - val_loss: 25553.1172\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21842.1309 - val_loss: 25392.9512\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21744.6719 - val_loss: 25247.6465\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21655.1641 - val_loss: 25149.9824\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21572.3574 - val_loss: 25053.4902\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 21490.4551 - val_loss: 24963.0078\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 21391.0449 - val_loss: 24909.9707\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21312.6328 - val_loss: 24748.4297\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21221.2734 - val_loss: 24665.8984\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 21145.0996 - val_loss: 24561.5801\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21044.7539 - val_loss: 24469.0488\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20962.8125 - val_loss: 24363.0449\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 20883.7969 - val_loss: 24262.2930\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20797.9883 - val_loss: 24166.5625\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20706.5977 - val_loss: 24073.4102\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 20620.5293 - val_loss: 23974.8516\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20535.9668 - val_loss: 23877.7363\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20452.1641 - val_loss: 23779.1973\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20369.4277 - val_loss: 23674.4727\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20286.0977 - val_loss: 23624.8750\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20211.5488 - val_loss: 23491.8086\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20124.9863 - val_loss: 23387.9902\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20046.9043 - val_loss: 23313.8906\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 19965.6562 - val_loss: 23218.8047\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 19890.9785 - val_loss: 23116.7051\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 19794.0762 - val_loss: 23028.7656\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19718.0801 - val_loss: 22939.1484\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19633.9434 - val_loss: 22855.1172\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19596.9727 - val_loss: 22814.2578\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 19492.7402 - val_loss: 22657.8535\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 19408.2988 - val_loss: 22554.4551\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 19308.5703 - val_loss: 22480.1328\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19225.5449 - val_loss: 22386.2266\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19159.0977 - val_loss: 22286.4141\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19068.6855 - val_loss: 22264.8652\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 19043.5137 - val_loss: 22150.6680\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18932.9961 - val_loss: 22018.3047\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18872.7559 - val_loss: 21910.7793\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18761.5078 - val_loss: 21885.5742\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18720.7246 - val_loss: 21763.8340\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 18641.1797 - val_loss: 21660.8594\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 18596.0215 - val_loss: 21605.4141\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 18504.3809 - val_loss: 21515.1309\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18380.3965 - val_loss: 21397.3535\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18303.8867 - val_loss: 21310.5723\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18221.6230 - val_loss: 21207.8828\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 18145.1074 - val_loss: 21111.9609\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 18058.9453 - val_loss: 21016.2461\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 17982.8633 - val_loss: 20927.5234\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17911.8848 - val_loss: 20860.7891\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17829.2656 - val_loss: 20772.9844\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 17749.2109 - val_loss: 20655.5312\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17677.2012 - val_loss: 20594.4824\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 17619.1074 - val_loss: 20523.7754\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 17538.0039 - val_loss: 20449.5391\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 17449.5859 - val_loss: 20387.8926\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 17377.8340 - val_loss: 20289.4473\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 17300.9316 - val_loss: 20170.9570\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17229.9785 - val_loss: 20131.1523\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 17146.2480 - val_loss: 20051.4453\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 17071.8516 - val_loss: 19948.0527\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16997.0547 - val_loss: 19883.4102\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 16926.9160 - val_loss: 19739.0957\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 16858.2637 - val_loss: 19665.1484\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 16779.1504 - val_loss: 19580.2715\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 16719.4766 - val_loss: 19496.4316\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16653.0684 - val_loss: 19454.5938\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 16571.9941 - val_loss: 19317.8711\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16507.3750 - val_loss: 19237.3359\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16424.2129 - val_loss: 19201.1328\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16351.4170 - val_loss: 19072.2520\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16281.3906 - val_loss: 18974.6562\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16205.7793 - val_loss: 18908.4531\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16128.8213 - val_loss: 18861.3789\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16061.2227 - val_loss: 18758.7422\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15990.2256 - val_loss: 18665.3965\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15916.1318 - val_loss: 18626.1562\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 15840.6055 - val_loss: 18515.3359\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 15780.8145 - val_loss: 18435.9785\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 15705.3145 - val_loss: 18345.6465\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15626.7275 - val_loss: 18270.7305\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 15561.2725 - val_loss: 18148.6621\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15485.2012 - val_loss: 18083.3379\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15417.7480 - val_loss: 17967.6035\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15342.9395 - val_loss: 17956.7207\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15288.7832 - val_loss: 17841.6641\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 15200.2324 - val_loss: 17765.9844\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15132.1318 - val_loss: 17657.6621\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15065.1006 - val_loss: 17607.1289\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14999.0049 - val_loss: 17609.1543\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 14934.8555 - val_loss: 17481.2109\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14869.0312 - val_loss: 17393.9375\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 14795.1611 - val_loss: 17328.3965\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14725.1992 - val_loss: 17262.2012\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 14657.7305 - val_loss: 17112.3301\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 14592.4727 - val_loss: 17013.5098\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14541.2832 - val_loss: 16978.1699\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14463.4492 - val_loss: 16922.5898\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 14397.0156 - val_loss: 16836.0078\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14325.6719 - val_loss: 16757.7559\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14255.6143 - val_loss: 16673.4023\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14193.0850 - val_loss: 16584.4570\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 14125.6650 - val_loss: 16511.5527\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14056.8838 - val_loss: 16415.3281\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 13998.3564 - val_loss: 16324.1113\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13927.4492 - val_loss: 16268.5195\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13863.2383 - val_loss: 16197.9414\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13814.1475 - val_loss: 16147.4238\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13750.0215 - val_loss: 16020.6338\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13671.3662 - val_loss: 15955.6357\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 13611.4082 - val_loss: 15890.4531\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 13551.0439 - val_loss: 15805.3555\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 13483.7217 - val_loss: 15756.5420\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13423.4336 - val_loss: 15718.9395\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13358.3682 - val_loss: 15620.6602\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13298.0234 - val_loss: 15589.3955\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13232.1406 - val_loss: 15473.5430\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13179.9541 - val_loss: 15393.2236\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13117.0820 - val_loss: 15312.6943\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13049.6348 - val_loss: 15274.3975\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12989.3125 - val_loss: 15200.9238\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12927.4766 - val_loss: 15108.3643\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12865.4395 - val_loss: 15040.4961\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12804.4961 - val_loss: 14999.4170\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12739.9961 - val_loss: 14907.6211\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12679.7646 - val_loss: 14854.1895\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 12617.1055 - val_loss: 14753.4912\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 12568.6055 - val_loss: 14684.4756\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 12504.3555 - val_loss: 14662.3613\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 12447.9150 - val_loss: 14527.3711\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 12387.9336 - val_loss: 14472.8711\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 12358.1133 - val_loss: 14436.7588\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12305.5713 - val_loss: 14361.4287\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12219.2676 - val_loss: 14259.5049\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12154.1943 - val_loss: 14197.7393\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12102.0703 - val_loss: 14136.0977\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12076.1445 - val_loss: 14097.8369\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11992.1758 - val_loss: 13997.6699\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11926.3008 - val_loss: 14047.2607\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11893.6914 - val_loss: 13877.0459\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11868.9170 - val_loss: 13828.8086\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11805.7148 - val_loss: 13793.7969\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 11735.8477 - val_loss: 13687.5117\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 11642.8477 - val_loss: 13624.8750\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 11597.5996 - val_loss: 13561.5352\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11537.3174 - val_loss: 13495.6055\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11469.2910 - val_loss: 13418.9453\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 11407.2852 - val_loss: 13366.4219\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 11357.6143 - val_loss: 13334.7256\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11303.8574 - val_loss: 13255.9805\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11243.5723 - val_loss: 13161.6357\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 11184.5732 - val_loss: 13088.1445\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11125.2070 - val_loss: 13006.9824\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 11068.9258 - val_loss: 12962.5381\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11010.4189 - val_loss: 12893.8701\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10956.6387 - val_loss: 12855.4541\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10910.8174 - val_loss: 12787.8857\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 10850.3281 - val_loss: 12728.8809\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10796.6279 - val_loss: 12649.3643\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 10740.0693 - val_loss: 12596.9375\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 10687.5801 - val_loss: 12540.8525\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10633.4883 - val_loss: 12482.8193\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10585.4072 - val_loss: 12420.7412\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10530.7305 - val_loss: 12356.6143\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10483.3955 - val_loss: 12304.1387\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 10421.4961 - val_loss: 12209.7617\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 10372.2061 - val_loss: 12159.9756\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10314.9297 - val_loss: 12079.0439\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10261.8428 - val_loss: 12015.2773\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 10206.3945 - val_loss: 11958.6826\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10160.4824 - val_loss: 11908.2793\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10106.0742 - val_loss: 11852.6484\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10059.5117 - val_loss: 11781.5781\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10001.8828 - val_loss: 11736.9414\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9956.1104 - val_loss: 11674.0420\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 9903.0723 - val_loss: 11606.4619\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9848.8818 - val_loss: 11554.7129\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 9795.4199 - val_loss: 11488.3418\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9748.5586 - val_loss: 11432.5840\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9695.7373 - val_loss: 11385.9121\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9645.0430 - val_loss: 11325.3057\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9596.1221 - val_loss: 11239.8213\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 9551.2520 - val_loss: 11216.2773\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 9512.1787 - val_loss: 11135.1904\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 9453.3389 - val_loss: 11088.7451\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9408.0156 - val_loss: 11027.5713\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9355.3633 - val_loss: 10963.9707\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9305.8223 - val_loss: 10938.8633\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 9266.7832 - val_loss: 10861.0557\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 9208.2549 - val_loss: 10814.8242\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 9161.1836 - val_loss: 10741.6064\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 9108.6416 - val_loss: 10731.7373\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 9064.9512 - val_loss: 10609.0977\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9022.8242 - val_loss: 10592.4717\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8967.8867 - val_loss: 10504.6025\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8916.1553 - val_loss: 10482.4863\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 8887.2598 - val_loss: 10386.1250\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8836.9961 - val_loss: 10375.2100\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8794.1641 - val_loss: 10295.7451\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 8739.0303 - val_loss: 10261.9453\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 8694.0273 - val_loss: 10215.3145\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 8659.3438 - val_loss: 10107.3398\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8623.0117 - val_loss: 10054.1025\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 8604.4707 - val_loss: 10021.9492\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8568.0391 - val_loss: 10014.7578\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8491.0049 - val_loss: 9916.5225\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 8465.0293 - val_loss: 10000.1357\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 8424.5840 - val_loss: 9814.0508\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8372.7598 - val_loss: 9738.4062\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8307.0713 - val_loss: 9699.2979\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8267.8770 - val_loss: 9677.8008\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8254.2900 - val_loss: 9601.7256\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8223.0742 - val_loss: 9582.3232\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8168.9429 - val_loss: 9597.7139\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8103.6284 - val_loss: 9426.8975\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8042.8774 - val_loss: 9363.8643\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7996.4263 - val_loss: 9299.3369\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 7953.6074 - val_loss: 9257.0859\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 7901.8315 - val_loss: 9218.2676\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7862.9863 - val_loss: 9199.2529\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 7834.9053 - val_loss: 9231.0566\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7820.3066 - val_loss: 9194.6104\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7894.7065 - val_loss: 9091.7080\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7763.9419 - val_loss: 8999.1553\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7690.5000 - val_loss: 8983.4365\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7713.2891 - val_loss: 9072.4883\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7673.3770 - val_loss: 9003.4297\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7629.1440 - val_loss: 9030.9961\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7660.9399 - val_loss: 9266.1045\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7714.7476 - val_loss: 8853.0244\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7534.9165 - val_loss: 8918.1367\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7449.0000 - val_loss: 8664.1289\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7378.0479 - val_loss: 8581.0557\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7325.2344 - val_loss: 8542.5977\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 7272.6289 - val_loss: 8510.9707\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 7230.5435 - val_loss: 8479.4365\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 7190.0703 - val_loss: 8400.6914\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7146.7236 - val_loss: 8357.2773\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7109.6558 - val_loss: 8344.0195\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7065.7480 - val_loss: 8288.1113\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7038.8228 - val_loss: 8322.9443\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6998.9067 - val_loss: 8163.0762\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6963.2036 - val_loss: 8111.4634\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6907.9209 - val_loss: 8048.2847\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6894.2637 - val_loss: 7999.8975\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6832.5718 - val_loss: 8018.0693\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6793.0332 - val_loss: 7920.2310\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6751.9014 - val_loss: 7904.1025\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 6716.8145 - val_loss: 7863.6855\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6674.6768 - val_loss: 7801.9375\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6635.6802 - val_loss: 7766.3560\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 6594.5840 - val_loss: 7726.2847\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 6555.7007 - val_loss: 7701.2520\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 6534.2866 - val_loss: 7647.5449\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6489.4043 - val_loss: 7607.7090\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6455.5000 - val_loss: 7542.9941\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 6422.4038 - val_loss: 7518.9722\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 6391.7607 - val_loss: 7512.8862\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6335.2451 - val_loss: 7416.3037\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6303.7954 - val_loss: 7406.0234\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6299.8765 - val_loss: 7308.6475\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6248.6719 - val_loss: 7300.9297\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6208.0498 - val_loss: 7263.4043\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6171.5615 - val_loss: 7204.9141\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6139.3491 - val_loss: 7185.2671\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6114.1890 - val_loss: 7101.7510\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6084.9478 - val_loss: 7097.5381\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6032.8584 - val_loss: 7065.1855\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 6015.8657 - val_loss: 7029.9731\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 5975.4863 - val_loss: 6999.8281\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5931.6030 - val_loss: 7048.0356\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5894.8965 - val_loss: 6875.4512\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5851.9619 - val_loss: 6879.6279\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5829.0215 - val_loss: 6809.4097\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5786.2842 - val_loss: 6773.2935\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5752.5576 - val_loss: 6739.2778\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5720.5498 - val_loss: 6713.7480\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5701.6113 - val_loss: 6698.6885\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5672.4092 - val_loss: 6672.5625\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5621.5630 - val_loss: 6556.4873\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5603.1562 - val_loss: 6548.2041\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5554.0415 - val_loss: 6655.9146\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5531.6509 - val_loss: 6526.8901\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5521.8184 - val_loss: 6405.2637\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5486.2559 - val_loss: 6395.5503\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5430.0352 - val_loss: 6368.3237\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5392.0308 - val_loss: 6326.7559\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 5365.1899 - val_loss: 6289.9868\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 5322.8062 - val_loss: 6266.5112\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5291.7637 - val_loss: 6173.5186\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5272.6016 - val_loss: 6115.9307\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5232.5254 - val_loss: 6119.9199\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5198.5103 - val_loss: 6065.1943\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5164.4121 - val_loss: 6032.6567\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5120.6377 - val_loss: 6030.4204\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5100.6260 - val_loss: 6056.1650\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 5070.2637 - val_loss: 6050.3354\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5074.9170 - val_loss: 5962.8872\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5054.6968 - val_loss: 5894.8022\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4994.4941 - val_loss: 5836.8022\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4974.6094 - val_loss: 5863.1230\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4996.4668 - val_loss: 5723.4824\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4994.0669 - val_loss: 5777.6504\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4983.7217 - val_loss: 5802.5488\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 4884.9746 - val_loss: 5671.0381\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 4838.3955 - val_loss: 5660.1362\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4795.8481 - val_loss: 5594.8481\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4762.8867 - val_loss: 5546.3394\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4735.0947 - val_loss: 5562.1445\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4706.0332 - val_loss: 5469.7510\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4656.0835 - val_loss: 5427.8188\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4627.6226 - val_loss: 5425.1606\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4602.2104 - val_loss: 5346.5762\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4572.0737 - val_loss: 5333.8662\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4528.4907 - val_loss: 5314.1650\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 4503.1621 - val_loss: 5248.2949\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4482.8838 - val_loss: 5186.5879\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4444.8574 - val_loss: 5184.7612\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4410.2095 - val_loss: 5129.9707\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4392.7124 - val_loss: 5137.7070\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4364.7783 - val_loss: 5065.5093\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 4335.5059 - val_loss: 5047.1304\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 4315.1348 - val_loss: 5020.1099\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4289.5010 - val_loss: 4964.8159\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 4270.0469 - val_loss: 4977.8672\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4232.5288 - val_loss: 4946.6172\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4214.1777 - val_loss: 4916.7944\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4231.6987 - val_loss: 5029.5366\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4167.5127 - val_loss: 4865.7412\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4132.0581 - val_loss: 4825.5737\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4117.2988 - val_loss: 4798.7217\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 4078.6272 - val_loss: 4759.3203\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4057.8694 - val_loss: 4693.7266\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4032.9814 - val_loss: 4664.1504\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4000.5547 - val_loss: 4639.4175\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3975.2339 - val_loss: 4610.3535\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3953.9983 - val_loss: 4583.1895\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3922.4192 - val_loss: 4549.1733\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3903.0122 - val_loss: 4535.1963\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 3876.7334 - val_loss: 4501.1621\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3859.3098 - val_loss: 4460.9263\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3852.2349 - val_loss: 4503.6934\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3817.6133 - val_loss: 4484.3960\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3787.8706 - val_loss: 4369.4795\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3760.5117 - val_loss: 4380.1543\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3730.0894 - val_loss: 4317.8452\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 3710.1050 - val_loss: 4288.1948\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3668.6926 - val_loss: 4276.4429\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3646.7627 - val_loss: 4260.3789\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3640.8877 - val_loss: 4318.8833\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3651.8699 - val_loss: 4236.7339\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3604.1719 - val_loss: 4354.5063\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3594.1301 - val_loss: 4166.0234\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3543.4844 - val_loss: 4112.8325\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3518.5269 - val_loss: 4131.6919\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3480.7412 - val_loss: 4056.3767\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 3452.4033 - val_loss: 4029.7690\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 3420.7810 - val_loss: 3990.7332\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3407.2419 - val_loss: 3996.3577\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3403.2561 - val_loss: 3974.0208\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3367.6729 - val_loss: 3906.2266\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3357.1438 - val_loss: 3874.1545\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3299.5820 - val_loss: 3836.8018\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3281.4226 - val_loss: 3817.8311\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3272.4839 - val_loss: 3834.6970\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3247.2126 - val_loss: 3770.9822\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3231.1035 - val_loss: 3799.9067\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3229.7939 - val_loss: 3776.6223\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3186.1335 - val_loss: 3703.9185\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 3157.9529 - val_loss: 3736.9504\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3217.4719 - val_loss: 3773.2690\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3173.2666 - val_loss: 3698.0686\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3166.4209 - val_loss: 3710.6746\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 3143.0078 - val_loss: 3679.5012\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 3155.5203 - val_loss: 3833.7122\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 3145.2344 - val_loss: 3692.1138\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3099.2158 - val_loss: 3626.5854\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3089.9509 - val_loss: 3586.9287\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3071.4561 - val_loss: 3800.3604\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3117.1936 - val_loss: 3584.5591\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2976.8420 - val_loss: 3463.8276\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2940.6384 - val_loss: 3459.5366\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2914.2551 - val_loss: 3414.9436\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2878.0161 - val_loss: 3406.0425\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2850.1624 - val_loss: 3430.0781\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2865.9375 - val_loss: 3362.9924\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2858.5996 - val_loss: 3429.5598\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2811.6990 - val_loss: 3327.5474\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2837.0552 - val_loss: 3323.3459\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2771.9521 - val_loss: 3245.4065\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2779.9736 - val_loss: 3339.1914\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 2791.3289 - val_loss: 3222.9246\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 2699.1633 - val_loss: 3292.1377\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2681.2190 - val_loss: 3248.4011\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2664.6494 - val_loss: 3144.1804\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2719.6741 - val_loss: 3270.9102\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2822.3643 - val_loss: 3379.2000\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2751.3425 - val_loss: 3150.6211\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2625.9951 - val_loss: 3075.1367\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2611.7568 - val_loss: 3204.7549\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2607.6785 - val_loss: 3126.4827\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2583.4595 - val_loss: 3071.5117\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2548.7449 - val_loss: 3084.7700\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2542.9590 - val_loss: 3041.7842\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2498.0820 - val_loss: 3046.0596\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2497.2583 - val_loss: 2987.1829\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2490.5845 - val_loss: 2939.4722\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2464.8630 - val_loss: 2861.1143\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 2424.3081 - val_loss: 2902.9424\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 2409.2600 - val_loss: 2857.8950\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 2379.0332 - val_loss: 2795.2368\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2359.6221 - val_loss: 2818.8342\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2343.5242 - val_loss: 2768.1704\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2319.2500 - val_loss: 2718.3103\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2294.4558 - val_loss: 2738.7988\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2273.3174 - val_loss: 2719.6814\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2267.2371 - val_loss: 2745.3508\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2255.3369 - val_loss: 2690.4485\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2246.2722 - val_loss: 2606.0051\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2209.2017 - val_loss: 2586.2483\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2194.0444 - val_loss: 2609.1904\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2185.2012 - val_loss: 2592.8464\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2161.8752 - val_loss: 2593.5183\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2145.9575 - val_loss: 2561.9951\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2126.3699 - val_loss: 2574.0435\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2112.2678 - val_loss: 2549.8923\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 2086.9106 - val_loss: 2488.8594\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2073.0732 - val_loss: 2462.3503\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 2056.4854 - val_loss: 2442.9873\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2039.0645 - val_loss: 2394.7012\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2041.6300 - val_loss: 2394.6113\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2009.8108 - val_loss: 2424.6172\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1989.4401 - val_loss: 2422.1892\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1973.4757 - val_loss: 2384.9060\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1955.9126 - val_loss: 2383.9148\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1948.1348 - val_loss: 2335.2627\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1948.0812 - val_loss: 2272.0513\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1924.4551 - val_loss: 2326.1467\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1906.2045 - val_loss: 2273.6812\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1877.4397 - val_loss: 2286.4990\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1864.8262 - val_loss: 2262.0776\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1843.5189 - val_loss: 2309.3342\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1881.9584 - val_loss: 2211.7209\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1827.9752 - val_loss: 2223.7957\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 1825.4576 - val_loss: 2182.4607\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1821.4165 - val_loss: 2215.4915\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1823.8511 - val_loss: 2206.1511\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1857.5966 - val_loss: 2172.0930\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1784.3628 - val_loss: 2143.1335\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1859.5845 - val_loss: 2372.2239\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1887.5044 - val_loss: 2400.5095\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1880.2975 - val_loss: 2251.9353\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1796.9622 - val_loss: 2126.4465\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1738.1284 - val_loss: 2207.4019\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1710.7114 - val_loss: 2053.4136\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1698.8944 - val_loss: 2141.9353\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1672.5364 - val_loss: 2005.5599\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1651.5553 - val_loss: 2033.4069\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1649.8375 - val_loss: 2001.7274\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1633.7007 - val_loss: 2052.3528\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1741.6714 - val_loss: 1967.1582\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1627.3439 - val_loss: 1986.3334\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 1612.7311 - val_loss: 1903.0601\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1598.3763 - val_loss: 1931.4067\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1596.7543 - val_loss: 1958.5940\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1571.7505 - val_loss: 1983.6552\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1562.6213 - val_loss: 1929.4503\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1534.5660 - val_loss: 1915.7682\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1525.5679 - val_loss: 1834.9761\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1521.3430 - val_loss: 1845.0667\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1578.5620 - val_loss: 1909.1587\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1509.1237 - val_loss: 1822.9180\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1473.9514 - val_loss: 1790.9794\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1471.8765 - val_loss: 1769.3185\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1472.0594 - val_loss: 1739.9542\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1446.7855 - val_loss: 1784.6355\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1442.5497 - val_loss: 1738.2833\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1406.7036 - val_loss: 1806.0773\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1415.6256 - val_loss: 1695.5994\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1415.5344 - val_loss: 1706.3324\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1391.0353 - val_loss: 1822.6771\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1376.4979 - val_loss: 1770.5718\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1359.7229 - val_loss: 1768.0034\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1337.2527 - val_loss: 1696.5212\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1322.6219 - val_loss: 1619.7222\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1304.7611 - val_loss: 1616.7289\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1291.1802 - val_loss: 1629.7928\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1323.4674 - val_loss: 1603.1805\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1267.5526 - val_loss: 1579.7902\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1257.6256 - val_loss: 1582.8137\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1234.7566 - val_loss: 1583.1985\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1234.9543 - val_loss: 1525.2192\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1253.0835 - val_loss: 1544.7977\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1223.6976 - val_loss: 1554.4030\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1210.2966 - val_loss: 1558.0762\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1194.3722 - val_loss: 1550.3977\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1202.8290 - val_loss: 1539.7676\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 1180.9067 - val_loss: 1490.5137\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1187.2394 - val_loss: 1492.6049\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1176.4374 - val_loss: 1519.5614\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1144.8367 - val_loss: 1454.2656\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1139.9091 - val_loss: 1449.5117\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1137.8728 - val_loss: 1448.7600\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1111.9840 - val_loss: 1442.7001\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1103.0967 - val_loss: 1427.3553\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1113.2225 - val_loss: 1413.5908\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1087.8826 - val_loss: 1454.6537\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1083.1064 - val_loss: 1402.7216\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1066.4711 - val_loss: 1425.6077\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1048.0786 - val_loss: 1397.0702\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1044.9794 - val_loss: 1381.4321\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1021.4504 - val_loss: 1366.5680\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1016.7983 - val_loss: 1376.3689\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1008.7336 - val_loss: 1335.1704\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1000.7871 - val_loss: 1371.9191\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1006.1260 - val_loss: 1326.2838\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 982.7056 - val_loss: 1332.1892\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 986.7475 - val_loss: 1317.3984\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 976.2151 - val_loss: 1358.7701\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 970.4243 - val_loss: 1313.3109\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 958.5370 - val_loss: 1294.8610\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 950.9395 - val_loss: 1271.6471\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 947.5018 - val_loss: 1317.1383\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 941.9085 - val_loss: 1308.7626\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 941.8831 - val_loss: 1249.1951\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 942.8398 - val_loss: 1324.1185\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 941.8383 - val_loss: 1213.1697\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 905.1387 - val_loss: 1211.7520\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 906.7201 - val_loss: 1187.9984\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 933.1804 - val_loss: 1233.6046\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 917.6409 - val_loss: 1185.6195\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 898.3389 - val_loss: 1214.0293\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 860.8350 - val_loss: 1199.6449\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 867.1273 - val_loss: 1185.4419\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 855.6096 - val_loss: 1180.0042\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 846.3651 - val_loss: 1201.5022\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 856.9210 - val_loss: 1168.4075\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 833.0187 - val_loss: 1171.9790\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 841.3690 - val_loss: 1259.7041\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 854.5267 - val_loss: 1142.3000\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 843.6548 - val_loss: 1281.2611\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 864.5898 - val_loss: 1102.1033\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 838.8884 - val_loss: 1186.3094\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 819.6275 - val_loss: 1176.9185\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 832.2308 - val_loss: 1277.6821\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 815.4559 - val_loss: 1144.9150\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 803.0876 - val_loss: 1167.1987\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 771.8512 - val_loss: 1098.8445\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 788.9066 - val_loss: 1102.8209\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 776.4211 - val_loss: 1092.0566\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 762.8464 - val_loss: 1071.8019\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 757.2567 - val_loss: 1050.6964\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 751.0574 - val_loss: 1044.5665\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 736.1625 - val_loss: 1062.6329\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 743.9258 - val_loss: 1038.5553\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 767.8040 - val_loss: 995.3754\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 730.2615 - val_loss: 987.6477\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 738.9595 - val_loss: 1095.0120\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 710.7004 - val_loss: 1042.6610\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 690.4957 - val_loss: 1095.5875\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-10-24 01:59:18           64\n",
      "config.json                                    2023-10-24 01:59:18         2641\n",
      "variables.h5                                   2023-10-24 01:59:18       461544\n",
      "Done!\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 7s 121ms/step - loss: 96754.2188 - val_loss: 108039.6328\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 96430.4688 - val_loss: 107551.8047\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 95843.2500 - val_loss: 106773.6641\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 95002.5312 - val_loss: 105729.2812\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 94040.6484 - val_loss: 104785.3672\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 93253.6016 - val_loss: 104044.1641\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 92645.4297 - val_loss: 103470.1797\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 92156.6797 - val_loss: 102987.2812\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 91740.4453 - val_loss: 102547.6562\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 91347.1875 - val_loss: 102158.7578\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 90993.5000 - val_loss: 101787.6562\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 90660.7812 - val_loss: 101419.4062\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 90329.8516 - val_loss: 101075.4688\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 90009.5547 - val_loss: 100747.8438\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 89707.4688 - val_loss: 100416.2812\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 89406.1328 - val_loss: 100088.5156\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 89099.8203 - val_loss: 99782.5469\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88816.9531 - val_loss: 99463.5000\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88526.7656 - val_loss: 99154.9922\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 88237.3984 - val_loss: 98861.5547\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 87969.0078 - val_loss: 98549.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 87685.1406 - val_loss: 98253.8438\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 87411.9141 - val_loss: 97958.9062\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 87142.0078 - val_loss: 97663.3828\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 86869.4844 - val_loss: 97376.2422\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86604.1797 - val_loss: 97087.3359\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 86338.4688 - val_loss: 96800.4844\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86070.5938 - val_loss: 96521.1562\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 85813.4766 - val_loss: 96233.3203\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 85550.6250 - val_loss: 95951.7500\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 85290.2188 - val_loss: 95674.8359\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 85034.9766 - val_loss: 95395.6953\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 84777.2812 - val_loss: 95121.5312\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 84523.7656 - val_loss: 94847.0312\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 84273.2891 - val_loss: 94568.6953\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 84019.6484 - val_loss: 94295.9453\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 83768.7578 - val_loss: 94025.5938\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 83521.8125 - val_loss: 93753.1094\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 83273.6641 - val_loss: 93483.0547\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 83024.8516 - val_loss: 93218.5547\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 82778.1484 - val_loss: 92957.6641\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 82533.8984 - val_loss: 92697.8047\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 82294.1875 - val_loss: 92432.1719\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 82050.6094 - val_loss: 92169.9062\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 81805.5703 - val_loss: 91916.9922\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 81574.0234 - val_loss: 91647.1250\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 81328.2031 - val_loss: 91390.2656\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 81092.4688 - val_loss: 91129.8203\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 80855.2578 - val_loss: 90869.7734\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 80621.7812 - val_loss: 90607.1641\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 80379.9375 - val_loss: 90357.6406\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 80145.4922 - val_loss: 90108.0234\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 79913.9141 - val_loss: 89853.7734\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 79684.4375 - val_loss: 89593.7812\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 79446.2188 - val_loss: 89340.9531\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 79214.3438 - val_loss: 89090.5703\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78983.0156 - val_loss: 88838.5938\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78749.6875 - val_loss: 88587.5156\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78519.5312 - val_loss: 88337.5156\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78290.3438 - val_loss: 88085.5312\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 78056.7422 - val_loss: 87844.4375\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 77835.0000 - val_loss: 87590.5703\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 77607.1250 - val_loss: 87340.2656\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 77374.7812 - val_loss: 87101.0938\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 77154.2109 - val_loss: 86851.5156\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 76929.1953 - val_loss: 86603.6562\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 76698.1406 - val_loss: 86363.9141\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 76480.0312 - val_loss: 86116.0547\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 76253.8672 - val_loss: 85875.2188\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 76034.4609 - val_loss: 85629.0156\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 75807.1641 - val_loss: 85394.5000\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 75589.4453 - val_loss: 85153.9844\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75371.0312 - val_loss: 84909.7656\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 75151.7422 - val_loss: 84665.3750\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 74927.9531 - val_loss: 84430.3906\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 74713.5859 - val_loss: 84189.4609\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 74491.4375 - val_loss: 83958.2188\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 74277.8438 - val_loss: 83719.7109\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 74062.6641 - val_loss: 83480.0156\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 73846.2344 - val_loss: 83242.6484\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 73627.8828 - val_loss: 83012.0000\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 73414.3047 - val_loss: 82779.9062\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 73203.4297 - val_loss: 82548.0859\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 72987.9219 - val_loss: 82312.4688\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 72773.7891 - val_loss: 82084.6484\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 72562.7812 - val_loss: 81853.8047\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72352.4766 - val_loss: 81621.4688\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72140.5469 - val_loss: 81392.0156\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71933.5469 - val_loss: 81156.4453\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 71722.3594 - val_loss: 80925.0000\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 71506.4297 - val_loss: 80708.0000\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 71303.2812 - val_loss: 80480.1797\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 71098.2500 - val_loss: 80246.8516\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 70889.8203 - val_loss: 80017.1250\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 70680.3125 - val_loss: 79793.3984\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 70473.1875 - val_loss: 79572.3438\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 70270.7188 - val_loss: 79345.7578\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 70065.2266 - val_loss: 79121.0156\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 69860.4062 - val_loss: 78897.1016\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 69654.5312 - val_loss: 78678.5938\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 69452.8828 - val_loss: 78456.9297\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 69250.6094 - val_loss: 78234.0781\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 69048.3594 - val_loss: 78011.2500\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68843.5312 - val_loss: 77791.5391\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 68643.2812 - val_loss: 77573.5547\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 68442.5156 - val_loss: 77354.8516\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 68240.7578 - val_loss: 77134.9453\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 68039.3750 - val_loss: 76920.9297\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 67842.7188 - val_loss: 76702.9688\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 67646.6250 - val_loss: 76479.3438\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67445.1797 - val_loss: 76266.6250\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 67249.7734 - val_loss: 76047.4062\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67052.9531 - val_loss: 75825.5312\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 66850.3359 - val_loss: 75612.1562\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 66654.9922 - val_loss: 75397.3750\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 66455.9062 - val_loss: 75186.0000\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 66264.0234 - val_loss: 74968.3438\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 66068.0312 - val_loss: 74759.4297\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 65870.8906 - val_loss: 74539.0000\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 65678.0000 - val_loss: 74342.5078\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65485.2305 - val_loss: 74128.2734\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 65292.1250 - val_loss: 73909.7812\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 65095.0781 - val_loss: 73697.7734\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 64903.6094 - val_loss: 73488.4297\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 64710.3672 - val_loss: 73281.6250\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 64523.5195 - val_loss: 73066.2188\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 64328.0781 - val_loss: 72855.3984\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 64137.0195 - val_loss: 72648.7812\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 63948.6680 - val_loss: 72437.7969\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 63755.8828 - val_loss: 72233.2812\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 63570.0547 - val_loss: 72022.6562\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 63379.8125 - val_loss: 71815.1641\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 63194.1445 - val_loss: 71606.2109\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 62999.6875 - val_loss: 71408.7812\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 62818.3594 - val_loss: 71198.9531\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 62629.0078 - val_loss: 70993.2266\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 62440.6406 - val_loss: 70792.7812\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 62260.6172 - val_loss: 70579.8438\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62070.5898 - val_loss: 70378.1328\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61882.8320 - val_loss: 70182.4609\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61701.6875 - val_loss: 69978.2500\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 61518.7852 - val_loss: 69772.7188\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61333.0156 - val_loss: 69571.6094\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61150.9180 - val_loss: 69368.5000\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60964.9453 - val_loss: 69172.6719\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 60785.7930 - val_loss: 68970.7734\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 60604.1953 - val_loss: 68769.2344\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 60422.3281 - val_loss: 68568.6875\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60239.8320 - val_loss: 68372.0312\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 60059.3477 - val_loss: 68174.9062\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 59879.3477 - val_loss: 67976.9062\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 59702.3945 - val_loss: 67775.0312\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 59519.4023 - val_loss: 67581.0312\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 59342.5781 - val_loss: 67383.1016\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 59163.5273 - val_loss: 67187.1328\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 58985.4531 - val_loss: 66990.6250\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58806.9180 - val_loss: 66796.5156\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58632.1875 - val_loss: 66597.4453\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58451.9570 - val_loss: 66406.0938\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 58278.5352 - val_loss: 66209.8438\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 58099.1133 - val_loss: 66020.6250\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 57927.5898 - val_loss: 65827.8438\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 57754.8281 - val_loss: 65630.9219\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 57579.5820 - val_loss: 65434.2773\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57402.1211 - val_loss: 65244.2773\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57229.8789 - val_loss: 65056.5430\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57057.0352 - val_loss: 64860.7070\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 56879.8281 - val_loss: 64675.9570\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 56711.3672 - val_loss: 64482.0898\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 56539.1406 - val_loss: 64287.1680\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 56361.2695 - val_loss: 64102.7344\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 56194.7695 - val_loss: 63917.8203\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 56031.3945 - val_loss: 63731.1523\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55864.3984 - val_loss: 63541.8828\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55689.4414 - val_loss: 63356.9023\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55514.3125 - val_loss: 63175.0703\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 55346.5820 - val_loss: 62989.4023\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 55176.7344 - val_loss: 62800.8477\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 55010.4531 - val_loss: 62609.1523\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 54837.2812 - val_loss: 62425.1094\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 54669.1914 - val_loss: 62242.7344\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54503.3750 - val_loss: 62058.5781\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54333.5234 - val_loss: 61872.1172\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 54172.7422 - val_loss: 61685.4805\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 53999.7070 - val_loss: 61513.4180\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 53838.8281 - val_loss: 61328.9922\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 53672.7969 - val_loss: 61135.0703\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 53506.0195 - val_loss: 60960.1445\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53342.9609 - val_loss: 60759.7969\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53176.8281 - val_loss: 60586.3828\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 53006.2656 - val_loss: 60401.2969\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52850.3594 - val_loss: 60214.9805\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 52678.6328 - val_loss: 60044.5156\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 52516.4844 - val_loss: 59860.6328\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 52358.9297 - val_loss: 59702.0898\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52201.3086 - val_loss: 59504.4844\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52030.4922 - val_loss: 59318.7031\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 51871.0977 - val_loss: 59131.7578\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51702.1250 - val_loss: 58956.8203\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 51549.7148 - val_loss: 58769.6602\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 51382.3750 - val_loss: 58597.3672\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51220.8594 - val_loss: 58423.8750\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 51060.1445 - val_loss: 58247.1914\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 50896.4102 - val_loss: 58072.9023\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 50736.2695 - val_loss: 57917.2891\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50582.2539 - val_loss: 57714.8672\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 50420.0742 - val_loss: 57538.6914\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 50261.7773 - val_loss: 57353.4219\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 50101.4258 - val_loss: 57165.2969\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 49939.7500 - val_loss: 57006.0703\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49783.1094 - val_loss: 56828.8477\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 49624.6328 - val_loss: 56652.0273\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49471.5273 - val_loss: 56473.2148\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49312.5547 - val_loss: 56303.0273\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 49159.3242 - val_loss: 56125.9375\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 49001.0781 - val_loss: 55959.5273\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 48847.1719 - val_loss: 55782.7656\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 48693.6094 - val_loss: 55616.1680\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 48540.9922 - val_loss: 55430.7969\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 48377.3398 - val_loss: 55263.3867\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 48224.1172 - val_loss: 55093.4102\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 48069.0820 - val_loss: 54921.9062\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47921.3359 - val_loss: 54744.8398\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 47762.5586 - val_loss: 54580.7070\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 47611.8633 - val_loss: 54413.9258\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 47457.2852 - val_loss: 54238.3750\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 47310.5078 - val_loss: 54072.7656\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47163.2109 - val_loss: 53919.4297\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 47003.9180 - val_loss: 53764.6055\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46853.8281 - val_loss: 53591.7344\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 46703.7578 - val_loss: 53422.1914\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 46549.6328 - val_loss: 53252.7148\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 46400.7539 - val_loss: 53084.2344\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46249.3008 - val_loss: 52909.8633\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46100.1797 - val_loss: 52750.6602\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 45950.5234 - val_loss: 52591.1016\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 45805.3438 - val_loss: 52425.7148\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 45653.6641 - val_loss: 52250.7773\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 45505.3789 - val_loss: 52088.7578\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 45359.7148 - val_loss: 51926.2852\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 45211.4141 - val_loss: 51740.0156\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 45064.2188 - val_loss: 51573.0586\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44916.8867 - val_loss: 51403.8711\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44767.9727 - val_loss: 51242.5273\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44622.1523 - val_loss: 51084.5469\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44483.2812 - val_loss: 50928.3477\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 44330.8828 - val_loss: 50764.7656\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 44190.0742 - val_loss: 50594.3008\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 44043.9883 - val_loss: 50452.9492\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43900.2617 - val_loss: 50281.2070\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 43756.1758 - val_loss: 50112.1953\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43610.1719 - val_loss: 49954.0156\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 43470.8906 - val_loss: 49791.6836\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 43329.8242 - val_loss: 49635.5781\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43184.2070 - val_loss: 49472.8594\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 43040.1172 - val_loss: 49313.7930\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 42912.3594 - val_loss: 49156.1953\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 42756.9922 - val_loss: 49001.3633\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 42623.7461 - val_loss: 48841.1719\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42476.5234 - val_loss: 48673.7852\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42341.3281 - val_loss: 48514.6328\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 42202.4844 - val_loss: 48359.5078\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 42055.5352 - val_loss: 48209.9609\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41910.2812 - val_loss: 48056.8828\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41776.1992 - val_loss: 47898.9453\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 41638.4492 - val_loss: 47739.8555\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 41493.3555 - val_loss: 47592.4570\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41358.2500 - val_loss: 47429.5977\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41219.4453 - val_loss: 47278.3828\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 41078.8789 - val_loss: 47130.4297\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 40948.4727 - val_loss: 47011.0391\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 40808.8594 - val_loss: 46823.2695\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 40670.6289 - val_loss: 46661.0078\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 40534.2578 - val_loss: 46507.1328\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40397.0195 - val_loss: 46355.0820\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 40264.0039 - val_loss: 46204.4453\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 40125.0234 - val_loss: 46060.4688\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 39989.5156 - val_loss: 45900.4570\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39855.4102 - val_loss: 45749.4102\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39721.4219 - val_loss: 45598.5703\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39585.3047 - val_loss: 45456.4062\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39452.6719 - val_loss: 45299.8828\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39317.2070 - val_loss: 45156.8711\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39185.8281 - val_loss: 45000.1172\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39053.0430 - val_loss: 44847.5430\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 38919.1406 - val_loss: 44703.2109\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 38787.3516 - val_loss: 44553.5977\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 38655.7969 - val_loss: 44403.7617\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 38523.8320 - val_loss: 44257.8086\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 38391.7891 - val_loss: 44111.9297\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 38261.7148 - val_loss: 43965.5859\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 38134.5234 - val_loss: 43814.1602\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 38000.3906 - val_loss: 43670.4688\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37871.6406 - val_loss: 43524.3828\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 37741.4023 - val_loss: 43379.4102\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37613.4961 - val_loss: 43235.1406\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37486.1406 - val_loss: 43087.3203\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37357.0000 - val_loss: 42944.4844\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37230.3516 - val_loss: 42806.7344\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37103.7656 - val_loss: 42658.9453\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 36974.4453 - val_loss: 42514.7227\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 36847.7188 - val_loss: 42377.5938\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 36720.8047 - val_loss: 42243.9102\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 36595.1289 - val_loss: 42087.1602\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 36468.4766 - val_loss: 41943.9219\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 36343.0000 - val_loss: 41799.5898\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 36216.4805 - val_loss: 41653.4844\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 36092.2539 - val_loss: 41509.8633\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 35966.0781 - val_loss: 41370.5352\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35841.3438 - val_loss: 41232.4609\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35721.8359 - val_loss: 41088.7344\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 35593.6875 - val_loss: 40956.3750\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35470.0898 - val_loss: 40824.4844\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35345.9414 - val_loss: 40679.5469\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35226.5586 - val_loss: 40540.0234\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35105.8789 - val_loss: 40402.0703\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34983.7227 - val_loss: 40259.4219\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 34862.0703 - val_loss: 40146.9219\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 34740.0664 - val_loss: 39984.0273\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34616.0898 - val_loss: 39870.8945\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34496.3789 - val_loss: 39714.9180\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 34376.0156 - val_loss: 39576.3320\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34253.6523 - val_loss: 39441.9531\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 34136.2383 - val_loss: 39305.2578\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 34013.9023 - val_loss: 39175.1172\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 33897.3867 - val_loss: 39036.1875\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 33772.6680 - val_loss: 38909.4102\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 33657.7227 - val_loss: 38771.0430\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 33537.9023 - val_loss: 38632.3047\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 33419.0664 - val_loss: 38502.9453\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 33302.3555 - val_loss: 38363.3828\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 33184.4805 - val_loss: 38231.7188\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 33065.7656 - val_loss: 38105.5938\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 32949.2773 - val_loss: 37971.1211\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 32835.7305 - val_loss: 37845.6484\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 32715.5723 - val_loss: 37703.1797\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32600.8203 - val_loss: 37580.7344\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 32489.7461 - val_loss: 37444.0195\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32377.9688 - val_loss: 37319.9453\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32266.1016 - val_loss: 37182.1406\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32162.6699 - val_loss: 37143.9336\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 32054.9512 - val_loss: 36968.9648\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 31920.9160 - val_loss: 36836.0469\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 31815.6074 - val_loss: 36666.1406\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31716.0898 - val_loss: 36578.7188\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 31589.5176 - val_loss: 36454.6445\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 31481.8652 - val_loss: 36311.7930\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31352.5527 - val_loss: 36186.9844\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 31233.8164 - val_loss: 36055.0625\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 31120.7402 - val_loss: 35927.2383\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31008.6484 - val_loss: 35798.0273\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30898.0547 - val_loss: 35691.2695\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30793.7852 - val_loss: 35531.5156\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 30684.7949 - val_loss: 35407.4062\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 30566.7676 - val_loss: 35278.5234\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 30456.9688 - val_loss: 35156.4570\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30345.1289 - val_loss: 35032.9023\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30235.4141 - val_loss: 34899.7969\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30124.9824 - val_loss: 34773.6328\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 30012.1523 - val_loss: 34656.2695\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 29912.3477 - val_loss: 34528.4570\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29810.9336 - val_loss: 34409.6953\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 29700.4277 - val_loss: 34281.1328\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 29584.3965 - val_loss: 34159.6875\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 29471.9160 - val_loss: 34040.5234\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 29365.0000 - val_loss: 33917.1133\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 29258.5488 - val_loss: 33792.6992\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 29146.4551 - val_loss: 33676.5898\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 29043.1562 - val_loss: 33547.7734\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28932.6660 - val_loss: 33429.0469\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 28824.6621 - val_loss: 33309.6328\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28718.6172 - val_loss: 33188.9609\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28614.0391 - val_loss: 33068.3516\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 28506.7539 - val_loss: 32951.3555\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28404.5352 - val_loss: 32829.7930\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28297.7773 - val_loss: 32710.7285\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 28192.4180 - val_loss: 32594.0625\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 28090.0566 - val_loss: 32470.4688\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 27984.6133 - val_loss: 32358.1875\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 27879.8711 - val_loss: 32245.3164\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27777.8828 - val_loss: 32131.0703\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27676.3008 - val_loss: 32008.1426\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27572.3164 - val_loss: 31891.3672\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27467.5723 - val_loss: 31780.0723\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27368.3516 - val_loss: 31665.2090\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 27271.3926 - val_loss: 31546.4473\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 27163.8027 - val_loss: 31427.9863\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 27071.0703 - val_loss: 31315.4727\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26964.5059 - val_loss: 31205.3828\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26862.9082 - val_loss: 31085.3672\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26761.8516 - val_loss: 30975.1602\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26661.9199 - val_loss: 30860.9590\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26560.1973 - val_loss: 30745.2715\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 26466.7383 - val_loss: 30634.3535\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 26362.4355 - val_loss: 30524.2188\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 26260.9941 - val_loss: 30390.2148\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26153.1777 - val_loss: 30296.4785\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 26085.8535 - val_loss: 30188.9453\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25969.1641 - val_loss: 30063.7090\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25858.5020 - val_loss: 29937.5840\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 25761.7734 - val_loss: 29830.0449\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 25661.1152 - val_loss: 29744.6602\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25567.8711 - val_loss: 29620.2148\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25466.9629 - val_loss: 29535.9766\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25387.7207 - val_loss: 29383.2734\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25286.3516 - val_loss: 29276.8516\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25177.3301 - val_loss: 29156.8477\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25083.5527 - val_loss: 29072.6855\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24984.0703 - val_loss: 28965.5586\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24896.7676 - val_loss: 28826.9082\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24798.8477 - val_loss: 28715.1484\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 24701.0859 - val_loss: 28620.1699\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 24601.4766 - val_loss: 28486.0898\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 24499.0195 - val_loss: 28396.7168\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24402.0820 - val_loss: 28300.9375\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24313.6426 - val_loss: 28175.7227\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 24211.5801 - val_loss: 28084.1602\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 24119.7148 - val_loss: 27958.4590\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24021.3301 - val_loss: 27862.9922\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 23938.7637 - val_loss: 27748.8359\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23834.9160 - val_loss: 27630.9414\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23739.9863 - val_loss: 27533.9336\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23650.0352 - val_loss: 27438.8438\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 23563.8594 - val_loss: 27318.2461\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23466.5625 - val_loss: 27218.6875\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23370.6484 - val_loss: 27114.5410\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23279.9414 - val_loss: 27001.0352\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 23184.2129 - val_loss: 26902.3086\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 23093.9219 - val_loss: 26802.0898\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 23007.2539 - val_loss: 26699.2266\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 22914.1836 - val_loss: 26588.9395\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22825.3340 - val_loss: 26484.9766\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 22731.5703 - val_loss: 26378.6992\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 22652.1309 - val_loss: 26328.7266\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22570.1309 - val_loss: 26190.1914\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22494.3945 - val_loss: 26095.3301\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22381.7266 - val_loss: 25974.0801\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22297.9043 - val_loss: 25917.9414\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22208.4277 - val_loss: 25765.2246\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22117.6504 - val_loss: 25696.2578\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 22030.7559 - val_loss: 25594.2910\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21932.7598 - val_loss: 25459.6387\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21843.2109 - val_loss: 25379.1523\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 21759.2734 - val_loss: 25260.8633\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21666.7207 - val_loss: 25196.3887\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21580.8320 - val_loss: 25090.6211\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 21494.9355 - val_loss: 24990.6582\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 21406.0898 - val_loss: 24899.2988\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 21317.9336 - val_loss: 24792.2578\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 21231.4668 - val_loss: 24692.1328\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21144.4648 - val_loss: 24597.8281\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21060.1016 - val_loss: 24499.7773\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20973.5312 - val_loss: 24406.4609\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20887.1484 - val_loss: 24305.1035\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20808.7812 - val_loss: 24198.0859\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20721.0645 - val_loss: 24133.0566\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20646.3477 - val_loss: 24012.0098\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20559.5898 - val_loss: 23930.7441\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 20476.0645 - val_loss: 23811.3086\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 20391.7871 - val_loss: 23727.2793\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20312.5879 - val_loss: 23618.0430\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20226.8242 - val_loss: 23512.5664\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 20144.1191 - val_loss: 23407.7910\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20063.3574 - val_loss: 23343.0723\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 19981.2422 - val_loss: 23211.0449\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 19913.4824 - val_loss: 23203.2812\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 19829.3730 - val_loss: 23064.0234\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19746.5723 - val_loss: 22946.0137\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19654.3730 - val_loss: 22855.5527\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19569.9512 - val_loss: 22735.5898\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 19485.9805 - val_loss: 22668.3848\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 19397.1953 - val_loss: 22576.2031\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19319.6055 - val_loss: 22485.6934\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 19238.6719 - val_loss: 22364.0586\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 19155.5547 - val_loss: 22286.7109\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19073.9004 - val_loss: 22177.8984\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18999.6816 - val_loss: 22120.7891\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18918.1094 - val_loss: 22009.8457\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18838.8516 - val_loss: 21932.9062\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18787.7988 - val_loss: 21851.3438\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 18682.0898 - val_loss: 21761.1719\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18602.0000 - val_loss: 21658.8477\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 18520.9863 - val_loss: 21567.9023\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 18444.8535 - val_loss: 21478.3848\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18366.4707 - val_loss: 21397.5098\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18293.6543 - val_loss: 21309.0000\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 18209.9707 - val_loss: 21214.1523\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18131.7480 - val_loss: 21121.0391\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18070.2812 - val_loss: 21043.9551\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 17992.1152 - val_loss: 20934.7012\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17910.4258 - val_loss: 20832.2891\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17840.9941 - val_loss: 20787.8203\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17763.2676 - val_loss: 20646.0508\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 17684.8672 - val_loss: 20585.1875\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17613.2109 - val_loss: 20475.4258\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 17534.4453 - val_loss: 20398.8438\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17454.2598 - val_loss: 20318.7598\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17377.6465 - val_loss: 20228.0449\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 17308.5254 - val_loss: 20147.2754\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 17234.9668 - val_loss: 20046.4512\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 17164.0391 - val_loss: 20041.6387\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 17096.8281 - val_loss: 19879.2754\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 17019.0020 - val_loss: 19834.3027\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16939.7871 - val_loss: 19700.1934\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 16865.3457 - val_loss: 19644.5820\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 16777.4414 - val_loss: 19554.2363\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16707.8789 - val_loss: 19463.3867\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16629.3926 - val_loss: 19387.8301\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 16559.9336 - val_loss: 19312.4141\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 16482.6035 - val_loss: 19211.5859\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 16412.4590 - val_loss: 19126.9844\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 16337.2861 - val_loss: 19056.4980\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16266.3574 - val_loss: 18967.0156\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 16197.7539 - val_loss: 18886.5312\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 16124.4775 - val_loss: 18797.7363\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16052.7188 - val_loss: 18724.6699\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 15984.9463 - val_loss: 18657.4004\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 15914.0869 - val_loss: 18563.6738\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 15839.3525 - val_loss: 18474.9980\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 15765.9883 - val_loss: 18389.4043\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 15704.4287 - val_loss: 18313.4375\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15635.4668 - val_loss: 18218.7227\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15553.8701 - val_loss: 18143.7461\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15488.1074 - val_loss: 18060.4824\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15420.9414 - val_loss: 17979.6836\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15347.9961 - val_loss: 17895.0332\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 15281.0830 - val_loss: 17826.7598\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15214.5225 - val_loss: 17751.5293\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15151.5820 - val_loss: 17644.2852\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15078.8926 - val_loss: 17603.5234\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15015.7568 - val_loss: 17506.7734\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 14939.5830 - val_loss: 17418.7227\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14871.6387 - val_loss: 17330.1387\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 14799.0762 - val_loss: 17259.2168\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 14735.9307 - val_loss: 17177.3145\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 14667.5869 - val_loss: 17102.1348\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14597.8955 - val_loss: 17040.2500\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14526.8398 - val_loss: 16958.3926\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14461.8428 - val_loss: 16871.6074\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14399.1201 - val_loss: 16813.2598\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14334.8838 - val_loss: 16722.6875\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 14270.8525 - val_loss: 16643.6562\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14203.3027 - val_loss: 16568.6797\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 14141.6611 - val_loss: 16507.5977\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14075.0137 - val_loss: 16427.8926\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14010.5801 - val_loss: 16339.4170\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13936.9121 - val_loss: 16262.8330\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13877.1250 - val_loss: 16199.6562\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13808.1025 - val_loss: 16114.0352\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13754.5508 - val_loss: 16055.6250\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13688.5645 - val_loss: 15967.2500\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 13614.3398 - val_loss: 15906.7988\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 13555.7178 - val_loss: 15837.2568\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13496.0684 - val_loss: 15777.1680\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13465.6699 - val_loss: 15692.4688\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13376.6865 - val_loss: 15626.7100\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13317.8252 - val_loss: 15537.2363\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 13244.1133 - val_loss: 15479.8008\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13189.2490 - val_loss: 15376.3506\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13121.9814 - val_loss: 15343.8975\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13060.0195 - val_loss: 15249.6055\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12994.1328 - val_loss: 15178.6162\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12926.6270 - val_loss: 15120.0898\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 12870.4756 - val_loss: 15060.0830\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12812.4219 - val_loss: 14966.3477\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12754.3311 - val_loss: 14885.0400\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 12694.3438 - val_loss: 14818.8330\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 12627.2676 - val_loss: 14748.8818\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 12564.3115 - val_loss: 14676.4688\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 12504.1963 - val_loss: 14598.8164\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 12459.6650 - val_loss: 14529.3613\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 12387.9287 - val_loss: 14467.2871\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 12326.8350 - val_loss: 14403.1992\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12264.3115 - val_loss: 14325.0664\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12205.3691 - val_loss: 14276.0088\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12149.7910 - val_loss: 14180.4512\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12092.8584 - val_loss: 14126.5342\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12044.2461 - val_loss: 14062.2080\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11986.4131 - val_loss: 14016.1387\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11927.3408 - val_loss: 13935.8721\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11860.2402 - val_loss: 13868.9219\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11796.3164 - val_loss: 13778.7207\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 11733.4844 - val_loss: 13719.3760\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 11680.8623 - val_loss: 13643.6650\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11620.3916 - val_loss: 13590.9932\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11569.7471 - val_loss: 13531.4541\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 11542.1699 - val_loss: 13471.1006\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 11501.6084 - val_loss: 13412.2432\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 11472.6924 - val_loss: 13450.0938\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11454.1172 - val_loss: 13356.5762\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11399.3848 - val_loss: 13244.5742\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11316.9766 - val_loss: 13173.1045\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11302.3232 - val_loss: 13110.0352\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11209.0107 - val_loss: 13100.0664\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11117.1875 - val_loss: 12972.7852\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 11044.0244 - val_loss: 12894.0225\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11001.5557 - val_loss: 12865.4902\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11006.1191 - val_loss: 12805.9023\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 10914.9541 - val_loss: 12737.1367\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10852.5107 - val_loss: 12684.5020\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10787.8604 - val_loss: 12629.0801\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10726.7021 - val_loss: 12526.5674\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10663.5195 - val_loss: 12465.8789\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 10609.3203 - val_loss: 12413.6426\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 10555.0977 - val_loss: 12393.9580\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 10503.6299 - val_loss: 12291.3438\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10445.0693 - val_loss: 12214.9258\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10425.0273 - val_loss: 12235.0977\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10369.6523 - val_loss: 12165.7695\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10323.9922 - val_loss: 12097.1914\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10232.8916 - val_loss: 11966.3398\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10182.7549 - val_loss: 11909.1924\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 10146.7939 - val_loss: 11847.1113\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10097.0986 - val_loss: 11801.9727\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 10036.6367 - val_loss: 11737.4707\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9973.5664 - val_loss: 11671.1484\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9928.5459 - val_loss: 11611.8428\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9867.7451 - val_loss: 11550.5176\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9815.6133 - val_loss: 11476.3525\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9786.5352 - val_loss: 11451.4365\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 9717.3193 - val_loss: 11356.1982\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 9685.7266 - val_loss: 11272.3398\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 9621.0498 - val_loss: 11274.0088\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9567.2461 - val_loss: 11201.9023\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9524.2070 - val_loss: 11146.4658\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9472.3467 - val_loss: 11086.0938\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9412.7490 - val_loss: 11008.6416\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9361.9033 - val_loss: 10961.9688\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9313.1572 - val_loss: 10915.8340\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 9261.1523 - val_loss: 10858.4912\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9214.4326 - val_loss: 10778.9258\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 9166.8818 - val_loss: 10726.8887\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 9116.1387 - val_loss: 10679.3369\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 9070.3525 - val_loss: 10633.3926\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 9020.4141 - val_loss: 10573.0889\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8974.3203 - val_loss: 10518.9580\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 8924.4824 - val_loss: 10462.5381\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8883.7520 - val_loss: 10402.6133\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8837.1104 - val_loss: 10344.8643\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 8789.6162 - val_loss: 10295.1045\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 8742.1680 - val_loss: 10239.9629\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 8697.9492 - val_loss: 10206.5488\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 8659.8936 - val_loss: 10133.9492\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8611.9043 - val_loss: 10079.2803\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8564.7031 - val_loss: 10016.7539\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8512.4805 - val_loss: 9957.8955\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 8465.9150 - val_loss: 9897.9238\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 8429.6924 - val_loss: 9855.0039\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 8381.7041 - val_loss: 9811.4443\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 8339.5645 - val_loss: 9749.9902\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 8293.5078 - val_loss: 9698.5967\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8247.0000 - val_loss: 9634.2539\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 8199.5205 - val_loss: 9600.2969\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8157.2837 - val_loss: 9545.7305\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8115.6509 - val_loss: 9505.5078\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8076.5835 - val_loss: 9440.5381\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8037.9106 - val_loss: 9436.5605\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8057.4097 - val_loss: 9429.6602\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 7998.0000 - val_loss: 9338.9697\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 7934.1372 - val_loss: 9239.9570\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 7882.4946 - val_loss: 9190.5869\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7828.4507 - val_loss: 9157.3418\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7799.4912 - val_loss: 9100.1348\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7745.6963 - val_loss: 9041.5742\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7700.7197 - val_loss: 9013.0713\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7655.8628 - val_loss: 8951.3477\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7609.4653 - val_loss: 8903.8350\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7585.9663 - val_loss: 8856.8408\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 7542.1025 - val_loss: 8874.0586\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7519.3262 - val_loss: 8750.8350\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7450.1763 - val_loss: 8778.6699\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7405.0054 - val_loss: 8644.8320\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7366.1284 - val_loss: 8617.9912\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7322.1440 - val_loss: 8551.1055\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7276.9434 - val_loss: 8581.7217\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 7248.0581 - val_loss: 8444.2959\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 7211.4448 - val_loss: 8409.8242\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 7167.0811 - val_loss: 8366.9160\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7118.0332 - val_loss: 8334.8320\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7079.7134 - val_loss: 8295.6582\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7042.3442 - val_loss: 8225.6328\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6999.3472 - val_loss: 8245.8057\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6962.3809 - val_loss: 8168.2153\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6921.9263 - val_loss: 8110.9707\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6882.7910 - val_loss: 8064.2100\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6836.1094 - val_loss: 8048.6528\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6806.9092 - val_loss: 7950.1807\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6790.7739 - val_loss: 7990.8159\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6787.6523 - val_loss: 7925.6562\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6725.1699 - val_loss: 7907.8379\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6706.9082 - val_loss: 7913.0469\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6666.4453 - val_loss: 7745.2256\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6622.8174 - val_loss: 7686.4150\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 6624.8931 - val_loss: 7673.6851\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 6548.0684 - val_loss: 7617.4038\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6506.0352 - val_loss: 7572.6128\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6465.6699 - val_loss: 7518.1050\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6418.0640 - val_loss: 7481.1631\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6372.8511 - val_loss: 7498.8281\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 6358.2568 - val_loss: 7495.7354\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 6344.0278 - val_loss: 7362.9512\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6297.1040 - val_loss: 7355.5293\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6273.1191 - val_loss: 7301.4551\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6220.9390 - val_loss: 7302.9097\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6160.1582 - val_loss: 7250.8242\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6120.7354 - val_loss: 7140.8403\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 6088.6675 - val_loss: 7093.2075\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6059.2271 - val_loss: 7112.6172\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6032.1895 - val_loss: 7004.4756\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 5981.1479 - val_loss: 7011.6440\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 5940.5220 - val_loss: 6945.8896\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 5907.5762 - val_loss: 6898.3315\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5869.0088 - val_loss: 6858.8828\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5841.2588 - val_loss: 6844.2812\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 5804.6152 - val_loss: 6776.7490\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5778.8677 - val_loss: 6746.7183\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5742.2598 - val_loss: 6694.9453\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5699.5957 - val_loss: 6666.4268\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5664.3081 - val_loss: 6617.6973\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5627.9658 - val_loss: 6568.2900\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5600.3887 - val_loss: 6530.4688\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5561.2671 - val_loss: 6515.8452\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5529.5332 - val_loss: 6442.3237\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5496.9038 - val_loss: 6436.0044\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 5459.7788 - val_loss: 6420.1313\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 5433.4434 - val_loss: 6335.0449\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5398.2065 - val_loss: 6315.6753\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 5363.9673 - val_loss: 6281.6738\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 5329.7495 - val_loss: 6235.3472\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5296.5767 - val_loss: 6218.4160\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 5271.1577 - val_loss: 6148.2612\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5237.6787 - val_loss: 6145.4565\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5202.2144 - val_loss: 6086.0684\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5167.0200 - val_loss: 6060.7520\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5137.7847 - val_loss: 6136.6538\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5106.9995 - val_loss: 5984.0439\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5074.5381 - val_loss: 6020.6328\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5052.7812 - val_loss: 5882.5972\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5023.4551 - val_loss: 5976.9507\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4990.0015 - val_loss: 5878.3760\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 4952.9355 - val_loss: 5809.2007\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4924.7490 - val_loss: 5848.0581\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4895.2710 - val_loss: 5830.0156\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4869.8926 - val_loss: 5729.8374\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 4855.5000 - val_loss: 5763.1597\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 1s 40ms/step - loss: 4867.1362 - val_loss: 5626.1748\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4828.1045 - val_loss: 5598.9160\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4789.3457 - val_loss: 5616.3896\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4735.6074 - val_loss: 5567.1489\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4694.9419 - val_loss: 5496.0522\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4662.6533 - val_loss: 5455.5137\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4639.2935 - val_loss: 5461.1641\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4600.5938 - val_loss: 5392.1997\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4574.2134 - val_loss: 5371.9668\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4541.2900 - val_loss: 5288.2466\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4512.9062 - val_loss: 5336.2056\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4493.0132 - val_loss: 5207.2710\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4466.0859 - val_loss: 5199.5918\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 4434.1421 - val_loss: 5251.3540\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4417.1689 - val_loss: 5119.2681\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4378.1226 - val_loss: 5104.8438\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 4336.0742 - val_loss: 5075.4272\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 4314.6157 - val_loss: 5092.5791\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 4286.5581 - val_loss: 5021.0146\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4253.0342 - val_loss: 4965.2051\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4225.9419 - val_loss: 4932.3521\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4202.8652 - val_loss: 4901.3882\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4172.5566 - val_loss: 4876.0054\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4141.8848 - val_loss: 4826.4961\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4116.2046 - val_loss: 4804.7095\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4086.6731 - val_loss: 4767.9834\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 4060.1697 - val_loss: 4743.8813\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4036.6316 - val_loss: 4716.3081\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4013.3425 - val_loss: 4719.9043\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3989.3035 - val_loss: 4692.7681\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3975.9409 - val_loss: 4653.1523\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3965.0955 - val_loss: 4703.9365\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 3957.7444 - val_loss: 4585.3428\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3956.5374 - val_loss: 4565.3965\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 3894.3662 - val_loss: 4544.1172\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 3849.4185 - val_loss: 4501.1582\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3824.1489 - val_loss: 4479.4512\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3799.4114 - val_loss: 4428.0493\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3759.0820 - val_loss: 4444.7339\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3742.4058 - val_loss: 4404.1426\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3712.2549 - val_loss: 4414.8188\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3694.4788 - val_loss: 4334.3281\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3677.7510 - val_loss: 4304.3184\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3655.3521 - val_loss: 4293.2075\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3654.8623 - val_loss: 4270.3223\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3602.9148 - val_loss: 4253.9580\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3587.3420 - val_loss: 4304.9189\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3577.6331 - val_loss: 4190.0356\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3539.5532 - val_loss: 4206.5962\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3502.1392 - val_loss: 4098.4473\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3477.1711 - val_loss: 4121.6245\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 3461.8057 - val_loss: 4106.7808\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 3430.1238 - val_loss: 4009.5200\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 3410.6763 - val_loss: 4054.7104\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3388.8735 - val_loss: 4072.7600\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3363.5525 - val_loss: 3956.3115\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3340.0737 - val_loss: 3984.1467\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3335.0442 - val_loss: 4001.9207\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3312.9302 - val_loss: 3894.9402\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3311.5457 - val_loss: 3938.6841\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3293.0310 - val_loss: 3863.4644\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3242.1196 - val_loss: 3882.1145\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3214.8386 - val_loss: 3797.9167\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3199.5857 - val_loss: 3747.4644\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3153.6985 - val_loss: 3793.2661\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3134.5459 - val_loss: 3735.4385\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3107.7859 - val_loss: 3745.2578\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3091.5430 - val_loss: 3644.6238\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3073.5002 - val_loss: 3591.3713\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 3067.7458 - val_loss: 3739.4192\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 3146.6963 - val_loss: 3642.2981\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3144.8818 - val_loss: 3565.5498\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 3100.7109 - val_loss: 3513.9309\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3020.3123 - val_loss: 3508.2913\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2996.0608 - val_loss: 3496.3452\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2958.0181 - val_loss: 3485.6160\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2926.7742 - val_loss: 3498.4363\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2925.6614 - val_loss: 3397.4905\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 2888.6616 - val_loss: 3409.2654\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2878.6201 - val_loss: 3401.8672\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2890.5042 - val_loss: 3436.5374\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2823.5999 - val_loss: 3296.1987\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2789.3066 - val_loss: 3307.9504\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2772.2703 - val_loss: 3259.7014\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2743.3081 - val_loss: 3256.3025\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2720.6250 - val_loss: 3236.1863\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 2689.9268 - val_loss: 3197.5222\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 2679.3528 - val_loss: 3169.4001\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2692.5710 - val_loss: 3157.5989\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2650.2251 - val_loss: 3155.3933\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2654.4468 - val_loss: 3075.2849\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2627.2048 - val_loss: 3084.7534\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2573.8948 - val_loss: 3037.5564\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 2555.8521 - val_loss: 3050.4639\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2563.4133 - val_loss: 3024.6824\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2554.3218 - val_loss: 2947.4062\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2536.4675 - val_loss: 2945.6750\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2518.4124 - val_loss: 2908.1147\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2501.8770 - val_loss: 2920.0339\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2478.9268 - val_loss: 2889.0186\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2428.1174 - val_loss: 2851.7998\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2410.1221 - val_loss: 2831.9739\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2389.2900 - val_loss: 2799.8704\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2374.7605 - val_loss: 2800.9976\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2355.1121 - val_loss: 2795.4941\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 2334.9216 - val_loss: 2756.2095\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2317.9507 - val_loss: 2907.9541\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2314.2441 - val_loss: 2716.8623\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2379.0198 - val_loss: 2799.7517\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 2334.0840 - val_loss: 2691.3916\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2330.3550 - val_loss: 2683.2009\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2284.3364 - val_loss: 2623.0049\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2236.6765 - val_loss: 2641.4795\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2245.5178 - val_loss: 2645.6228\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2255.9504 - val_loss: 2689.6650\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2212.1394 - val_loss: 2579.4365\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2185.8677 - val_loss: 2603.9019\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2151.4343 - val_loss: 2598.5129\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2150.8584 - val_loss: 2567.6836\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 2129.3000 - val_loss: 2648.2280\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2117.8862 - val_loss: 2551.0833\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 2085.5957 - val_loss: 2486.4287\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 2049.9675 - val_loss: 2456.8623\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 2032.1462 - val_loss: 2452.8645\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 2031.5983 - val_loss: 2447.6431\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 2002.6233 - val_loss: 2416.2134\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1989.2971 - val_loss: 2398.9141\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1974.7446 - val_loss: 2363.4224\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1947.7788 - val_loss: 2325.6628\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1934.5050 - val_loss: 2328.5864\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1920.3431 - val_loss: 2332.5994\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1909.2695 - val_loss: 2321.6389\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1886.0977 - val_loss: 2281.3728\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1873.5767 - val_loss: 2251.1055\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1878.3948 - val_loss: 2222.4927\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1855.6760 - val_loss: 2214.9905\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1832.7388 - val_loss: 2189.1904\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1822.6956 - val_loss: 2166.9346\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 1799.8794 - val_loss: 2181.3210\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1821.4082 - val_loss: 2144.1790\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1780.2677 - val_loss: 2182.7561\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1756.8025 - val_loss: 2128.5315\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1751.2738 - val_loss: 2089.9695\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1751.3365 - val_loss: 2162.0986\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1716.0714 - val_loss: 2047.3167\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1700.6063 - val_loss: 2074.4404\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1681.6589 - val_loss: 2033.6694\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1667.2502 - val_loss: 2012.5288\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1658.0868 - val_loss: 1993.1055\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1653.1432 - val_loss: 1968.5920\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1640.4948 - val_loss: 1976.8423\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1635.0780 - val_loss: 1941.4249\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1615.0809 - val_loss: 1977.2769\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1602.5953 - val_loss: 1931.6506\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 1591.1831 - val_loss: 1908.0330\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1579.6210 - val_loss: 2002.0748\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1612.0059 - val_loss: 1979.8744\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1559.4006 - val_loss: 1918.5269\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1550.8484 - val_loss: 1862.3904\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1520.6743 - val_loss: 1847.9585\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1514.4580 - val_loss: 1860.4303\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1520.4166 - val_loss: 1843.5011\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1481.3068 - val_loss: 1815.7424\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1488.9319 - val_loss: 1765.9631\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1471.3052 - val_loss: 1780.9564\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1445.5171 - val_loss: 1740.5405\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1434.8151 - val_loss: 1735.2938\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1416.2006 - val_loss: 1740.1377\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1405.8470 - val_loss: 1729.9292\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1398.2842 - val_loss: 1705.6074\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1386.5386 - val_loss: 1692.8784\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1367.3979 - val_loss: 1674.5614\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1352.2065 - val_loss: 1654.2338\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1340.6990 - val_loss: 1674.3281\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1329.1495 - val_loss: 1625.0870\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1308.7050 - val_loss: 1619.0308\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1294.6608 - val_loss: 1622.7183\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1283.4248 - val_loss: 1599.2482\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1285.2612 - val_loss: 1572.9227\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1275.4006 - val_loss: 1578.4230\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1263.3767 - val_loss: 1532.7456\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1266.8273 - val_loss: 1505.4927\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1254.5607 - val_loss: 1559.6978\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1231.5037 - val_loss: 1508.3267\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1225.2493 - val_loss: 1544.3547\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1237.3083 - val_loss: 1488.2076\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1223.7279 - val_loss: 1443.6379\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1192.9457 - val_loss: 1480.8014\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1180.3145 - val_loss: 1459.0480\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 1181.5448 - val_loss: 1444.3713\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1161.2153 - val_loss: 1455.3628\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1170.8052 - val_loss: 1426.6321\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1169.0225 - val_loss: 1396.5201\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1155.3130 - val_loss: 1368.3169\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1139.6361 - val_loss: 1365.2739\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1129.2550 - val_loss: 1410.4788\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1111.5414 - val_loss: 1389.5983\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1095.8517 - val_loss: 1394.9769\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1086.7161 - val_loss: 1334.5165\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1078.8774 - val_loss: 1430.5436\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1070.4596 - val_loss: 1325.2673\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1056.5687 - val_loss: 1342.3081\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1049.4097 - val_loss: 1407.8755\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1038.5474 - val_loss: 1347.8351\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1026.2345 - val_loss: 1373.0151\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 1029.7427 - val_loss: 1323.0830\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1030.6558 - val_loss: 1403.2909\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1034.1177 - val_loss: 1326.0798\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1052.5881 - val_loss: 1298.8524\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1024.5962 - val_loss: 1374.2258\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1030.3408 - val_loss: 1384.8434\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1059.4292 - val_loss: 1397.7491\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1051.9882 - val_loss: 1313.6158\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1075.4956 - val_loss: 1213.0396\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1090.6682 - val_loss: 1420.8602\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1014.3301 - val_loss: 1262.6587\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 975.8138 - val_loss: 1261.3619\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 958.7283 - val_loss: 1218.4506\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 941.2584 - val_loss: 1215.4091\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 932.3447 - val_loss: 1203.8113\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 920.1343 - val_loss: 1235.8705\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 905.2642 - val_loss: 1260.8763\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 911.7114 - val_loss: 1210.4395\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 905.3975 - val_loss: 1202.4929\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 893.9265 - val_loss: 1187.0934\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 886.8701 - val_loss: 1109.3530\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 860.6370 - val_loss: 1102.7704\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 865.8841 - val_loss: 1113.8571\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 849.0381 - val_loss: 1122.5109\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 825.6956 - val_loss: 1051.9897\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 817.9362 - val_loss: 1097.8645\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 813.1653 - val_loss: 1077.4083\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 806.9423 - val_loss: 1047.4517\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 807.8135 - val_loss: 1011.6044\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 830.4866 - val_loss: 1064.4855\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 793.7295 - val_loss: 1079.1708\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 784.2460 - val_loss: 1059.3099\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 769.7562 - val_loss: 1018.5364\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 757.3615 - val_loss: 1014.5512\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 747.9353 - val_loss: 947.2191\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 744.7600 - val_loss: 1002.5319\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 745.7574 - val_loss: 1001.7686\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 750.2460 - val_loss: 1037.7153\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 733.6617 - val_loss: 1074.2623\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 727.2711 - val_loss: 934.9601\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 722.5366 - val_loss: 988.8112\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 722.5185 - val_loss: 953.7111\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 719.1722 - val_loss: 1055.9690\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 719.7048 - val_loss: 929.9481\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 699.6441 - val_loss: 918.0090\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 689.9292 - val_loss: 924.9949\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 679.3356 - val_loss: 969.0818\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 670.4173 - val_loss: 928.4454\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 682.0515 - val_loss: 947.8790\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 670.7975 - val_loss: 992.2676\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-10-24 02:39:52           64\n",
      "config.json                                    2023-10-24 02:39:52         2641\n",
      "variables.h5                                   2023-10-24 02:39:52       461544\n",
      "Done!\n",
      "Epoch 1/1000\n",
      "18/18 [==============================] - 7s 90ms/step - loss: 96822.0312 - val_loss: 108141.2422\n",
      "Epoch 2/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 96550.7969 - val_loss: 107726.9688\n",
      "Epoch 3/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 96022.6875 - val_loss: 106987.7188\n",
      "Epoch 4/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 95190.3750 - val_loss: 105910.2500\n",
      "Epoch 5/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 94160.7109 - val_loss: 104899.7344\n",
      "Epoch 6/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 93316.3438 - val_loss: 104088.1250\n",
      "Epoch 7/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 92664.7188 - val_loss: 103443.1250\n",
      "Epoch 8/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 92125.4609 - val_loss: 102922.0312\n",
      "Epoch 9/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 91664.1797 - val_loss: 102475.2578\n",
      "Epoch 10/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 91271.3672 - val_loss: 102069.3672\n",
      "Epoch 11/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 90904.7812 - val_loss: 101679.6562\n",
      "Epoch 12/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 90556.7422 - val_loss: 101307.0312\n",
      "Epoch 13/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 90219.4453 - val_loss: 100959.7188\n",
      "Epoch 14/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 89900.7188 - val_loss: 100617.7188\n",
      "Epoch 15/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 89588.7656 - val_loss: 100283.2734\n",
      "Epoch 16/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 89280.6562 - val_loss: 99963.6250\n",
      "Epoch 17/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 88982.1562 - val_loss: 99649.5391\n",
      "Epoch 18/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 88694.8828 - val_loss: 99327.5156\n",
      "Epoch 19/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 88402.0547 - val_loss: 99019.4609\n",
      "Epoch 20/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 88114.7500 - val_loss: 98721.1328\n",
      "Epoch 21/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 87840.4688 - val_loss: 98413.7656\n",
      "Epoch 22/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 87562.6484 - val_loss: 98110.5234\n",
      "Epoch 23/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 87282.5391 - val_loss: 97819.7812\n",
      "Epoch 24/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 87012.1562 - val_loss: 97528.3438\n",
      "Epoch 25/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86743.6406 - val_loss: 97236.3438\n",
      "Epoch 26/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 86474.4062 - val_loss: 96948.6406\n",
      "Epoch 27/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 86209.5391 - val_loss: 96661.2812\n",
      "Epoch 28/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85945.6250 - val_loss: 96375.3906\n",
      "Epoch 29/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85682.0547 - val_loss: 96093.1641\n",
      "Epoch 30/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85423.6016 - val_loss: 95809.2031\n",
      "Epoch 31/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 85161.7578 - val_loss: 95531.1953\n",
      "Epoch 32/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 84907.3750 - val_loss: 95249.6797\n",
      "Epoch 33/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 84644.8203 - val_loss: 94982.2812\n",
      "Epoch 34/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 84395.2734 - val_loss: 94706.0859\n",
      "Epoch 35/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 84141.3125 - val_loss: 94431.5547\n",
      "Epoch 36/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 83888.6719 - val_loss: 94161.5156\n",
      "Epoch 37/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 83641.5391 - val_loss: 93886.4531\n",
      "Epoch 38/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 83391.4297 - val_loss: 93614.8594\n",
      "Epoch 39/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 83140.2266 - val_loss: 93352.3984\n",
      "Epoch 40/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 82893.3281 - val_loss: 93089.5156\n",
      "Epoch 41/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 82652.7422 - val_loss: 92818.5469\n",
      "Epoch 42/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 82405.9141 - val_loss: 92554.0234\n",
      "Epoch 43/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 82163.0000 - val_loss: 92291.4141\n",
      "Epoch 44/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 81922.4219 - val_loss: 92026.4375\n",
      "Epoch 45/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 81679.1562 - val_loss: 91765.8594\n",
      "Epoch 46/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 81436.3750 - val_loss: 91512.8203\n",
      "Epoch 47/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 81205.0000 - val_loss: 91245.3125\n",
      "Epoch 48/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 80963.0547 - val_loss: 90986.6250\n",
      "Epoch 49/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 80722.5312 - val_loss: 90735.7188\n",
      "Epoch 50/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 80493.6562 - val_loss: 90471.8047\n",
      "Epoch 51/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 80254.4062 - val_loss: 90216.7656\n",
      "Epoch 52/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 80020.1953 - val_loss: 89962.3359\n",
      "Epoch 53/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 79786.2031 - val_loss: 89709.6641\n",
      "Epoch 54/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 79555.2266 - val_loss: 89455.2031\n",
      "Epoch 55/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 79320.4609 - val_loss: 89205.6719\n",
      "Epoch 56/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 79090.7812 - val_loss: 88954.1094\n",
      "Epoch 57/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 78857.8750 - val_loss: 88704.5156\n",
      "Epoch 58/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 78625.9688 - val_loss: 88455.8828\n",
      "Epoch 59/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 78399.5625 - val_loss: 88201.4141\n",
      "Epoch 60/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 78167.6562 - val_loss: 87953.0703\n",
      "Epoch 61/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 77936.9062 - val_loss: 87710.2500\n",
      "Epoch 62/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 77712.4922 - val_loss: 87457.9844\n",
      "Epoch 63/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 77482.8828 - val_loss: 87212.9688\n",
      "Epoch 64/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 77259.8047 - val_loss: 86963.0781\n",
      "Epoch 65/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 77031.7812 - val_loss: 86716.4531\n",
      "Epoch 66/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 76802.4141 - val_loss: 86477.2500\n",
      "Epoch 67/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 76581.7656 - val_loss: 86234.5156\n",
      "Epoch 68/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 76357.5234 - val_loss: 85991.6562\n",
      "Epoch 69/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 76132.7578 - val_loss: 85747.0078\n",
      "Epoch 70/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 75912.1562 - val_loss: 85500.6875\n",
      "Epoch 71/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 75689.3125 - val_loss: 85253.8438\n",
      "Epoch 72/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75466.0000 - val_loss: 85014.4219\n",
      "Epoch 73/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75243.4531 - val_loss: 84775.0625\n",
      "Epoch 74/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 75024.3594 - val_loss: 84536.2812\n",
      "Epoch 75/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 74807.6172 - val_loss: 84292.8984\n",
      "Epoch 76/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 74586.7812 - val_loss: 84054.7500\n",
      "Epoch 77/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 74370.8984 - val_loss: 83815.8359\n",
      "Epoch 78/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 74148.6328 - val_loss: 83585.6406\n",
      "Epoch 79/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 73938.6875 - val_loss: 83346.0234\n",
      "Epoch 80/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 73719.2578 - val_loss: 83112.4922\n",
      "Epoch 81/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 73507.1406 - val_loss: 82873.4062\n",
      "Epoch 82/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 73288.2812 - val_loss: 82645.5469\n",
      "Epoch 83/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 73074.9141 - val_loss: 82415.8828\n",
      "Epoch 84/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 72865.2812 - val_loss: 82181.3438\n",
      "Epoch 85/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72651.4062 - val_loss: 81949.1641\n",
      "Epoch 86/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 72438.9922 - val_loss: 81718.7266\n",
      "Epoch 87/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 72226.9219 - val_loss: 81492.2422\n",
      "Epoch 88/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 72019.6719 - val_loss: 81258.5469\n",
      "Epoch 89/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 71807.2422 - val_loss: 81029.8750\n",
      "Epoch 90/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 71599.9688 - val_loss: 80797.4297\n",
      "Epoch 91/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 71389.0469 - val_loss: 80569.7891\n",
      "Epoch 92/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 71181.3594 - val_loss: 80341.3438\n",
      "Epoch 93/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 70972.0859 - val_loss: 80117.0078\n",
      "Epoch 94/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 70768.6172 - val_loss: 79885.9453\n",
      "Epoch 95/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 70556.5000 - val_loss: 79665.9922\n",
      "Epoch 96/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 70353.5703 - val_loss: 79440.9844\n",
      "Epoch 97/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 70148.7188 - val_loss: 79215.1719\n",
      "Epoch 98/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 69943.7656 - val_loss: 78990.2266\n",
      "Epoch 99/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 69737.9297 - val_loss: 78769.0547\n",
      "Epoch 100/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 69537.0312 - val_loss: 78542.3047\n",
      "Epoch 101/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 69330.7188 - val_loss: 78322.8359\n",
      "Epoch 102/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 69130.3281 - val_loss: 78099.8984\n",
      "Epoch 103/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 68927.6562 - val_loss: 77879.0625\n",
      "Epoch 104/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68726.0938 - val_loss: 77657.0000\n",
      "Epoch 105/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 68526.7500 - val_loss: 77434.9688\n",
      "Epoch 106/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 68321.9062 - val_loss: 77224.0703\n",
      "Epoch 107/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 68126.5703 - val_loss: 77002.2109\n",
      "Epoch 108/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 67928.5547 - val_loss: 76778.9297\n",
      "Epoch 109/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 67727.5391 - val_loss: 76560.9141\n",
      "Epoch 110/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 67527.2812 - val_loss: 76347.8750\n",
      "Epoch 111/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 67332.5703 - val_loss: 76130.9062\n",
      "Epoch 112/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 67133.8906 - val_loss: 75915.8906\n",
      "Epoch 113/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 66936.3828 - val_loss: 75703.1797\n",
      "Epoch 114/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 66743.2422 - val_loss: 75485.1250\n",
      "Epoch 115/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 66544.1953 - val_loss: 75272.0469\n",
      "Epoch 116/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 66352.7031 - val_loss: 75054.9453\n",
      "Epoch 117/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 66150.2734 - val_loss: 74852.2266\n",
      "Epoch 118/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 65961.5703 - val_loss: 74636.2891\n",
      "Epoch 119/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65764.2656 - val_loss: 74423.9062\n",
      "Epoch 120/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65570.5859 - val_loss: 74209.0000\n",
      "Epoch 121/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 65374.3477 - val_loss: 73998.2500\n",
      "Epoch 122/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 65181.3555 - val_loss: 73788.3672\n",
      "Epoch 123/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 64990.7227 - val_loss: 73575.4688\n",
      "Epoch 124/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 64800.2305 - val_loss: 73368.0859\n",
      "Epoch 125/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 64603.5625 - val_loss: 73155.5234\n",
      "Epoch 126/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 64415.0703 - val_loss: 72946.6406\n",
      "Epoch 127/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 64219.9531 - val_loss: 72739.2109\n",
      "Epoch 128/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 64029.7656 - val_loss: 72527.3281\n",
      "Epoch 129/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 63837.7500 - val_loss: 72320.4609\n",
      "Epoch 130/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 63650.4023 - val_loss: 72111.8750\n",
      "Epoch 131/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 63462.1445 - val_loss: 71904.9141\n",
      "Epoch 132/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 63272.8555 - val_loss: 71700.2344\n",
      "Epoch 133/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 63082.2031 - val_loss: 71494.1797\n",
      "Epoch 134/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62896.2695 - val_loss: 71291.6953\n",
      "Epoch 135/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62709.9102 - val_loss: 71087.6641\n",
      "Epoch 136/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62519.7656 - val_loss: 70879.1016\n",
      "Epoch 137/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 62332.4023 - val_loss: 70681.2812\n",
      "Epoch 138/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 62150.5703 - val_loss: 70470.6641\n",
      "Epoch 139/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61961.2695 - val_loss: 70266.1562\n",
      "Epoch 140/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 61778.8203 - val_loss: 70063.4062\n",
      "Epoch 141/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 61592.8320 - val_loss: 69859.3594\n",
      "Epoch 142/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 61409.1680 - val_loss: 69656.9141\n",
      "Epoch 143/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 61223.8203 - val_loss: 69454.9844\n",
      "Epoch 144/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 61040.7969 - val_loss: 69251.7500\n",
      "Epoch 145/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 60854.7930 - val_loss: 69058.8906\n",
      "Epoch 146/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 60675.1250 - val_loss: 68856.6484\n",
      "Epoch 147/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 60493.4844 - val_loss: 68655.2656\n",
      "Epoch 148/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60309.5156 - val_loss: 68460.8047\n",
      "Epoch 149/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 60132.2930 - val_loss: 68255.2891\n",
      "Epoch 150/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 59948.4805 - val_loss: 68057.3906\n",
      "Epoch 151/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 59769.5000 - val_loss: 67857.7500\n",
      "Epoch 152/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 59588.3945 - val_loss: 67664.4062\n",
      "Epoch 153/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 59410.7930 - val_loss: 67464.5547\n",
      "Epoch 154/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 59230.4023 - val_loss: 67269.1641\n",
      "Epoch 155/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 59050.2656 - val_loss: 67073.8828\n",
      "Epoch 156/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 58871.8477 - val_loss: 66883.0469\n",
      "Epoch 157/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 58697.6680 - val_loss: 66682.0938\n",
      "Epoch 158/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 58519.2695 - val_loss: 66483.9375\n",
      "Epoch 159/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 58339.7031 - val_loss: 66295.3203\n",
      "Epoch 160/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 58166.4180 - val_loss: 66099.5000\n",
      "Epoch 161/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 57991.5898 - val_loss: 65904.9453\n",
      "Epoch 162/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 57815.0547 - val_loss: 65711.9141\n",
      "Epoch 163/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 57638.4453 - val_loss: 65520.8594\n",
      "Epoch 164/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 57465.4062 - val_loss: 65326.8594\n",
      "Epoch 165/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 57291.9805 - val_loss: 65129.8320\n",
      "Epoch 166/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 57116.9414 - val_loss: 64941.1406\n",
      "Epoch 167/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 56943.2578 - val_loss: 64749.7227\n",
      "Epoch 168/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 56771.7148 - val_loss: 64556.7930\n",
      "Epoch 169/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 56598.0859 - val_loss: 64365.8594\n",
      "Epoch 170/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 56423.9883 - val_loss: 64182.2500\n",
      "Epoch 171/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 56255.3672 - val_loss: 63991.4023\n",
      "Epoch 172/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 56081.9258 - val_loss: 63801.5781\n",
      "Epoch 173/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 55911.1406 - val_loss: 63613.5703\n",
      "Epoch 174/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 55741.2734 - val_loss: 63422.1797\n",
      "Epoch 175/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55567.3594 - val_loss: 63247.3750\n",
      "Epoch 176/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 55409.4609 - val_loss: 63057.8320\n",
      "Epoch 177/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 55236.0078 - val_loss: 62875.2031\n",
      "Epoch 178/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 55069.9062 - val_loss: 62688.0977\n",
      "Epoch 179/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54900.5156 - val_loss: 62492.2578\n",
      "Epoch 180/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 54729.4922 - val_loss: 62306.0273\n",
      "Epoch 181/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 54558.2305 - val_loss: 62129.2930\n",
      "Epoch 182/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 54395.7500 - val_loss: 61939.3047\n",
      "Epoch 183/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54228.1602 - val_loss: 61748.8281\n",
      "Epoch 184/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 54058.7344 - val_loss: 61568.3398\n",
      "Epoch 185/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 53891.9844 - val_loss: 61379.9219\n",
      "Epoch 186/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53726.9180 - val_loss: 61194.2227\n",
      "Epoch 187/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53558.4570 - val_loss: 61009.6680\n",
      "Epoch 188/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53394.1523 - val_loss: 60826.6875\n",
      "Epoch 189/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 53229.4258 - val_loss: 60650.4102\n",
      "Epoch 190/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 53063.0430 - val_loss: 60471.4570\n",
      "Epoch 191/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 52903.3203 - val_loss: 60287.4570\n",
      "Epoch 192/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 52744.1406 - val_loss: 60110.6523\n",
      "Epoch 193/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 52579.0430 - val_loss: 59931.4727\n",
      "Epoch 194/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52415.6953 - val_loss: 59752.9219\n",
      "Epoch 195/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 52252.4219 - val_loss: 59560.3594\n",
      "Epoch 196/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 52084.9648 - val_loss: 59392.9375\n",
      "Epoch 197/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 51922.3398 - val_loss: 59199.9570\n",
      "Epoch 198/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 51761.1680 - val_loss: 59018.7852\n",
      "Epoch 199/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 51599.7656 - val_loss: 58843.7070\n",
      "Epoch 200/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51439.1289 - val_loss: 58660.2344\n",
      "Epoch 201/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 51276.4727 - val_loss: 58477.7031\n",
      "Epoch 202/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 51123.2031 - val_loss: 58326.3750\n",
      "Epoch 203/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 50967.4531 - val_loss: 58140.8359\n",
      "Epoch 204/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 50809.0781 - val_loss: 57952.3594\n",
      "Epoch 205/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 50647.4219 - val_loss: 57787.1797\n",
      "Epoch 206/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50486.1406 - val_loss: 57602.7930\n",
      "Epoch 207/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 50324.9531 - val_loss: 57425.7109\n",
      "Epoch 208/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 50167.3086 - val_loss: 57245.4844\n",
      "Epoch 209/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 50006.7031 - val_loss: 57076.0781\n",
      "Epoch 210/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 49848.2031 - val_loss: 56905.1953\n",
      "Epoch 211/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 49694.6875 - val_loss: 56737.2656\n",
      "Epoch 212/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 49538.1250 - val_loss: 56559.7656\n",
      "Epoch 213/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 49380.8008 - val_loss: 56372.5625\n",
      "Epoch 214/1000\n",
      "18/18 [==============================] - 0s 14ms/step - loss: 49221.9648 - val_loss: 56200.4648\n",
      "Epoch 215/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 49068.0469 - val_loss: 56032.4023\n",
      "Epoch 216/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 48913.3867 - val_loss: 55867.3281\n",
      "Epoch 217/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 48754.3789 - val_loss: 55695.2930\n",
      "Epoch 218/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 48603.5391 - val_loss: 55518.1992\n",
      "Epoch 219/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 48451.0117 - val_loss: 55345.5508\n",
      "Epoch 220/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 48293.1289 - val_loss: 55171.7148\n",
      "Epoch 221/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 48139.3359 - val_loss: 54999.5156\n",
      "Epoch 222/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 47985.7539 - val_loss: 54821.6367\n",
      "Epoch 223/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 47830.0469 - val_loss: 54658.0781\n",
      "Epoch 224/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 47678.9180 - val_loss: 54489.0391\n",
      "Epoch 225/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 47523.9219 - val_loss: 54321.8320\n",
      "Epoch 226/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47378.3789 - val_loss: 54135.4023\n",
      "Epoch 227/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47230.8281 - val_loss: 53976.2969\n",
      "Epoch 228/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 47078.6641 - val_loss: 53815.3828\n",
      "Epoch 229/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46925.4102 - val_loss: 53630.9883\n",
      "Epoch 230/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46773.4141 - val_loss: 53456.1289\n",
      "Epoch 231/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46617.1953 - val_loss: 53293.3047\n",
      "Epoch 232/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 46465.1367 - val_loss: 53126.3711\n",
      "Epoch 233/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 46315.1094 - val_loss: 52965.1680\n",
      "Epoch 234/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 46163.2773 - val_loss: 52802.5977\n",
      "Epoch 235/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 46017.5156 - val_loss: 52625.3281\n",
      "Epoch 236/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 45863.2812 - val_loss: 52463.1719\n",
      "Epoch 237/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 45718.6719 - val_loss: 52294.9883\n",
      "Epoch 238/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 45566.6602 - val_loss: 52131.8086\n",
      "Epoch 239/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 45420.6523 - val_loss: 51966.9492\n",
      "Epoch 240/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 45270.3867 - val_loss: 51808.3750\n",
      "Epoch 241/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 45125.2305 - val_loss: 51635.9102\n",
      "Epoch 242/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 44978.9805 - val_loss: 51473.3281\n",
      "Epoch 243/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 44834.5938 - val_loss: 51307.1914\n",
      "Epoch 244/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 44685.8398 - val_loss: 51143.9141\n",
      "Epoch 245/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 44538.4727 - val_loss: 50985.0391\n",
      "Epoch 246/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 44395.4219 - val_loss: 50815.4141\n",
      "Epoch 247/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 44248.7500 - val_loss: 50652.8203\n",
      "Epoch 248/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 44102.4219 - val_loss: 50493.1445\n",
      "Epoch 249/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43957.6719 - val_loss: 50334.7852\n",
      "Epoch 250/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43814.8398 - val_loss: 50173.4258\n",
      "Epoch 251/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 43670.5586 - val_loss: 50012.3477\n",
      "Epoch 252/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 43528.3750 - val_loss: 49849.4805\n",
      "Epoch 253/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 43384.6641 - val_loss: 49690.5820\n",
      "Epoch 254/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 43239.9570 - val_loss: 49532.7031\n",
      "Epoch 255/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 43102.2266 - val_loss: 49372.7070\n",
      "Epoch 256/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 42958.1211 - val_loss: 49223.8359\n",
      "Epoch 257/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42820.3750 - val_loss: 49059.5156\n",
      "Epoch 258/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42675.4844 - val_loss: 48901.7070\n",
      "Epoch 259/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 42536.3906 - val_loss: 48747.2656\n",
      "Epoch 260/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 42395.1172 - val_loss: 48587.2852\n",
      "Epoch 261/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42256.1367 - val_loss: 48430.4062\n",
      "Epoch 262/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 42116.8906 - val_loss: 48267.7500\n",
      "Epoch 263/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41979.7773 - val_loss: 48140.7148\n",
      "Epoch 264/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41843.8867 - val_loss: 47971.0273\n",
      "Epoch 265/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41697.5469 - val_loss: 47817.8945\n",
      "Epoch 266/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41562.7852 - val_loss: 47650.4141\n",
      "Epoch 267/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41433.0195 - val_loss: 47489.1172\n",
      "Epoch 268/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 41285.1094 - val_loss: 47341.6758\n",
      "Epoch 269/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 41149.6484 - val_loss: 47191.7344\n",
      "Epoch 270/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 41006.9453 - val_loss: 47037.4805\n",
      "Epoch 271/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 40882.0742 - val_loss: 46874.8203\n",
      "Epoch 272/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 40733.8828 - val_loss: 46725.7227\n",
      "Epoch 273/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 40597.9258 - val_loss: 46571.2070\n",
      "Epoch 274/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 40458.2891 - val_loss: 46420.5938\n",
      "Epoch 275/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 40328.1719 - val_loss: 46269.9180\n",
      "Epoch 276/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 40193.6250 - val_loss: 46113.8750\n",
      "Epoch 277/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 40052.6523 - val_loss: 45961.2500\n",
      "Epoch 278/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 39916.8125 - val_loss: 45810.3672\n",
      "Epoch 279/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 39785.0352 - val_loss: 45661.3164\n",
      "Epoch 280/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 39650.3047 - val_loss: 45509.0234\n",
      "Epoch 281/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 39516.8984 - val_loss: 45355.3125\n",
      "Epoch 282/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39381.2695 - val_loss: 45205.5703\n",
      "Epoch 283/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 39245.1133 - val_loss: 45062.2969\n",
      "Epoch 284/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 39117.5664 - val_loss: 44907.0781\n",
      "Epoch 285/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 38981.2500 - val_loss: 44761.3672\n",
      "Epoch 286/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 38846.6055 - val_loss: 44613.6602\n",
      "Epoch 287/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 38719.7148 - val_loss: 44460.9531\n",
      "Epoch 288/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 38587.5312 - val_loss: 44318.0781\n",
      "Epoch 289/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 38456.3828 - val_loss: 44168.7891\n",
      "Epoch 290/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 38327.3242 - val_loss: 44015.9844\n",
      "Epoch 291/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 38191.8828 - val_loss: 43872.0781\n",
      "Epoch 292/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 38060.3672 - val_loss: 43730.2031\n",
      "Epoch 293/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37933.5000 - val_loss: 43581.2969\n",
      "Epoch 294/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37804.9688 - val_loss: 43433.9219\n",
      "Epoch 295/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37672.8398 - val_loss: 43289.5352\n",
      "Epoch 296/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37546.8945 - val_loss: 43145.1484\n",
      "Epoch 297/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 37416.6406 - val_loss: 43000.4336\n",
      "Epoch 298/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 37286.8477 - val_loss: 42859.1211\n",
      "Epoch 299/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 37161.1875 - val_loss: 42712.5781\n",
      "Epoch 300/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 37031.0664 - val_loss: 42572.3008\n",
      "Epoch 301/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 36904.4922 - val_loss: 42429.3086\n",
      "Epoch 302/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 36780.0352 - val_loss: 42282.9375\n",
      "Epoch 303/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 36649.7891 - val_loss: 42143.2930\n",
      "Epoch 304/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 36525.6172 - val_loss: 42000.1680\n",
      "Epoch 305/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 36397.5391 - val_loss: 41857.7812\n",
      "Epoch 306/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 36273.1094 - val_loss: 41715.5352\n",
      "Epoch 307/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 36147.9531 - val_loss: 41574.3281\n",
      "Epoch 308/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 36028.7969 - val_loss: 41438.5000\n",
      "Epoch 309/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 35905.1094 - val_loss: 41298.9375\n",
      "Epoch 310/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35780.7539 - val_loss: 41153.1953\n",
      "Epoch 311/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 35648.2852 - val_loss: 41017.0156\n",
      "Epoch 312/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35525.1289 - val_loss: 40878.9023\n",
      "Epoch 313/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 35405.7930 - val_loss: 40738.6641\n",
      "Epoch 314/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 35279.8086 - val_loss: 40600.0469\n",
      "Epoch 315/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 35158.1094 - val_loss: 40472.1016\n",
      "Epoch 316/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 35035.1250 - val_loss: 40321.2266\n",
      "Epoch 317/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 34909.9844 - val_loss: 40202.4258\n",
      "Epoch 318/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 34799.0742 - val_loss: 40047.2852\n",
      "Epoch 319/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34674.2734 - val_loss: 39909.2305\n",
      "Epoch 320/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 34553.7305 - val_loss: 39771.2070\n",
      "Epoch 321/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 34429.6797 - val_loss: 39632.6406\n",
      "Epoch 322/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 34303.4023 - val_loss: 39504.8242\n",
      "Epoch 323/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 34188.8047 - val_loss: 39364.7852\n",
      "Epoch 324/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 34063.7539 - val_loss: 39228.1094\n",
      "Epoch 325/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 33946.0039 - val_loss: 39087.8398\n",
      "Epoch 326/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 33820.6406 - val_loss: 38958.5938\n",
      "Epoch 327/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 33705.1797 - val_loss: 38820.0898\n",
      "Epoch 328/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 33585.1875 - val_loss: 38684.1875\n",
      "Epoch 329/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 33465.2656 - val_loss: 38549.5469\n",
      "Epoch 330/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 33346.3906 - val_loss: 38422.0078\n",
      "Epoch 331/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 33234.2422 - val_loss: 38281.9219\n",
      "Epoch 332/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 33113.1875 - val_loss: 38151.0352\n",
      "Epoch 333/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32993.3945 - val_loss: 38026.0703\n",
      "Epoch 334/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32877.4141 - val_loss: 37901.1094\n",
      "Epoch 335/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 32760.1699 - val_loss: 37760.3555\n",
      "Epoch 336/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 32651.2578 - val_loss: 37633.9492\n",
      "Epoch 337/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 32530.2227 - val_loss: 37504.2031\n",
      "Epoch 338/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 32414.1641 - val_loss: 37367.7617\n",
      "Epoch 339/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 32300.8789 - val_loss: 37239.5898\n",
      "Epoch 340/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 32194.1016 - val_loss: 37106.4570\n",
      "Epoch 341/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 32078.7598 - val_loss: 36978.4727\n",
      "Epoch 342/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 31958.6602 - val_loss: 36850.3555\n",
      "Epoch 343/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31838.1484 - val_loss: 36726.6211\n",
      "Epoch 344/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31724.5000 - val_loss: 36589.6367\n",
      "Epoch 345/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 31612.3672 - val_loss: 36482.1406\n",
      "Epoch 346/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 31505.8613 - val_loss: 36356.3828\n",
      "Epoch 347/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 31411.9375 - val_loss: 36228.3359\n",
      "Epoch 348/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 31281.3516 - val_loss: 36094.3242\n",
      "Epoch 349/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 31170.5488 - val_loss: 35952.5312\n",
      "Epoch 350/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 31066.9297 - val_loss: 35859.7031\n",
      "Epoch 351/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 30975.9473 - val_loss: 35704.7266\n",
      "Epoch 352/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 30828.7051 - val_loss: 35575.2500\n",
      "Epoch 353/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 30715.1387 - val_loss: 35446.2109\n",
      "Epoch 354/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 30602.1387 - val_loss: 35315.8984\n",
      "Epoch 355/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 30488.1250 - val_loss: 35186.2344\n",
      "Epoch 356/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 30377.1602 - val_loss: 35060.4141\n",
      "Epoch 357/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 30262.3672 - val_loss: 34943.0820\n",
      "Epoch 358/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 30165.6074 - val_loss: 34816.7383\n",
      "Epoch 359/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 30043.3887 - val_loss: 34691.3789\n",
      "Epoch 360/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 29928.2988 - val_loss: 34570.3320\n",
      "Epoch 361/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29829.0547 - val_loss: 34441.7773\n",
      "Epoch 362/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29719.1875 - val_loss: 34337.0703\n",
      "Epoch 363/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29615.7676 - val_loss: 34211.9961\n",
      "Epoch 364/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 29505.9590 - val_loss: 34085.8945\n",
      "Epoch 365/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29392.5488 - val_loss: 33949.0898\n",
      "Epoch 366/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29283.0527 - val_loss: 33825.7695\n",
      "Epoch 367/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 29173.9551 - val_loss: 33697.9453\n",
      "Epoch 368/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 29067.8711 - val_loss: 33574.0234\n",
      "Epoch 369/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28963.1914 - val_loss: 33454.7539\n",
      "Epoch 370/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28852.6895 - val_loss: 33354.3164\n",
      "Epoch 371/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28741.3027 - val_loss: 33229.8438\n",
      "Epoch 372/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28641.0117 - val_loss: 33085.4180\n",
      "Epoch 373/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28532.8867 - val_loss: 32989.2578\n",
      "Epoch 374/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 28428.4453 - val_loss: 32855.8906\n",
      "Epoch 375/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 28327.7520 - val_loss: 32729.1172\n",
      "Epoch 376/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 28221.2871 - val_loss: 32637.7637\n",
      "Epoch 377/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 28142.5371 - val_loss: 32522.7500\n",
      "Epoch 378/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 28053.8633 - val_loss: 32401.3789\n",
      "Epoch 379/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 27932.9512 - val_loss: 32286.5039\n",
      "Epoch 380/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27813.6211 - val_loss: 32144.3301\n",
      "Epoch 381/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27706.8438 - val_loss: 32029.6875\n",
      "Epoch 382/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 27599.1699 - val_loss: 31897.2578\n",
      "Epoch 383/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 27497.8906 - val_loss: 31778.4590\n",
      "Epoch 384/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 27389.7578 - val_loss: 31668.1074\n",
      "Epoch 385/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 27283.1035 - val_loss: 31548.6953\n",
      "Epoch 386/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 27179.2773 - val_loss: 31430.3652\n",
      "Epoch 387/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 27075.1133 - val_loss: 31319.1660\n",
      "Epoch 388/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26976.8770 - val_loss: 31206.0410\n",
      "Epoch 389/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26872.8965 - val_loss: 31089.2500\n",
      "Epoch 390/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26772.2188 - val_loss: 30970.5234\n",
      "Epoch 391/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26669.0430 - val_loss: 30856.6797\n",
      "Epoch 392/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 26567.3750 - val_loss: 30745.6035\n",
      "Epoch 393/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 26467.8203 - val_loss: 30628.4648\n",
      "Epoch 394/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 26367.0703 - val_loss: 30517.6152\n",
      "Epoch 395/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 26266.2109 - val_loss: 30405.3926\n",
      "Epoch 396/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26170.3555 - val_loss: 30288.2539\n",
      "Epoch 397/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 26074.3418 - val_loss: 30178.5078\n",
      "Epoch 398/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 25968.4902 - val_loss: 30058.9785\n",
      "Epoch 399/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 25868.2871 - val_loss: 29947.9297\n",
      "Epoch 400/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 25770.8184 - val_loss: 29835.5176\n",
      "Epoch 401/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25671.2441 - val_loss: 29725.1836\n",
      "Epoch 402/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25575.4785 - val_loss: 29611.9062\n",
      "Epoch 403/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25474.3262 - val_loss: 29501.8887\n",
      "Epoch 404/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 25378.4824 - val_loss: 29389.0859\n",
      "Epoch 405/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25281.9902 - val_loss: 29280.0078\n",
      "Epoch 406/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25187.9473 - val_loss: 29163.6387\n",
      "Epoch 407/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 25087.0918 - val_loss: 29056.9609\n",
      "Epoch 408/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 24994.9824 - val_loss: 28943.2734\n",
      "Epoch 409/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 24895.0703 - val_loss: 28836.5312\n",
      "Epoch 410/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 24801.5879 - val_loss: 28728.6758\n",
      "Epoch 411/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 24712.2148 - val_loss: 28617.1797\n",
      "Epoch 412/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 24619.7012 - val_loss: 28525.7441\n",
      "Epoch 413/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 24532.4141 - val_loss: 28409.0977\n",
      "Epoch 414/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 24425.5586 - val_loss: 28293.0234\n",
      "Epoch 415/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 24332.2539 - val_loss: 28208.6387\n",
      "Epoch 416/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 24244.2461 - val_loss: 28089.8516\n",
      "Epoch 417/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24147.0859 - val_loss: 27978.1465\n",
      "Epoch 418/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 24051.0586 - val_loss: 27868.2012\n",
      "Epoch 419/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23956.0371 - val_loss: 27765.3223\n",
      "Epoch 420/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 23860.2422 - val_loss: 27651.3125\n",
      "Epoch 421/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23770.3652 - val_loss: 27539.8652\n",
      "Epoch 422/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23671.9277 - val_loss: 27445.3125\n",
      "Epoch 423/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 23581.7070 - val_loss: 27334.6934\n",
      "Epoch 424/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 23485.7539 - val_loss: 27228.9512\n",
      "Epoch 425/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 23395.7090 - val_loss: 27121.1602\n",
      "Epoch 426/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 23302.7109 - val_loss: 27018.3516\n",
      "Epoch 427/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 23216.0371 - val_loss: 26925.2598\n",
      "Epoch 428/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 23123.3066 - val_loss: 26818.0820\n",
      "Epoch 429/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 23034.9824 - val_loss: 26710.3320\n",
      "Epoch 430/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 22952.4707 - val_loss: 26615.3945\n",
      "Epoch 431/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22855.4023 - val_loss: 26504.9668\n",
      "Epoch 432/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22765.7832 - val_loss: 26385.6992\n",
      "Epoch 433/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22667.7480 - val_loss: 26284.1797\n",
      "Epoch 434/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22585.8242 - val_loss: 26190.0527\n",
      "Epoch 435/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22487.3340 - val_loss: 26083.5859\n",
      "Epoch 436/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22399.9277 - val_loss: 25977.8691\n",
      "Epoch 437/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22309.8730 - val_loss: 25876.9961\n",
      "Epoch 438/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 22223.5859 - val_loss: 25769.0078\n",
      "Epoch 439/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22135.5918 - val_loss: 25670.7871\n",
      "Epoch 440/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 22045.1113 - val_loss: 25575.1172\n",
      "Epoch 441/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 21954.1426 - val_loss: 25473.7207\n",
      "Epoch 442/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21861.7578 - val_loss: 25380.0625\n",
      "Epoch 443/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 21776.6191 - val_loss: 25272.5645\n",
      "Epoch 444/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21693.9590 - val_loss: 25167.1523\n",
      "Epoch 445/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 21613.3828 - val_loss: 25087.5215\n",
      "Epoch 446/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21514.2344 - val_loss: 24967.5469\n",
      "Epoch 447/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 21428.9141 - val_loss: 24869.7891\n",
      "Epoch 448/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 21342.3418 - val_loss: 24761.9551\n",
      "Epoch 449/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21256.5371 - val_loss: 24665.6641\n",
      "Epoch 450/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 21176.0840 - val_loss: 24579.4688\n",
      "Epoch 451/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21092.3633 - val_loss: 24481.2832\n",
      "Epoch 452/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 21004.5566 - val_loss: 24396.7949\n",
      "Epoch 453/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 20917.8770 - val_loss: 24284.5449\n",
      "Epoch 454/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20837.7207 - val_loss: 24195.3164\n",
      "Epoch 455/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20753.4609 - val_loss: 24082.7266\n",
      "Epoch 456/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 20670.9121 - val_loss: 23985.3359\n",
      "Epoch 457/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20577.7578 - val_loss: 23902.8184\n",
      "Epoch 458/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 20500.8047 - val_loss: 23800.5859\n",
      "Epoch 459/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 20421.8965 - val_loss: 23708.6289\n",
      "Epoch 460/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20334.3203 - val_loss: 23608.6152\n",
      "Epoch 461/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 20251.1094 - val_loss: 23508.6250\n",
      "Epoch 462/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 20168.6543 - val_loss: 23419.6191\n",
      "Epoch 463/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 20082.9922 - val_loss: 23334.0039\n",
      "Epoch 464/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 19996.5215 - val_loss: 23234.4785\n",
      "Epoch 465/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 19920.8047 - val_loss: 23130.6172\n",
      "Epoch 466/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19829.6602 - val_loss: 23039.7715\n",
      "Epoch 467/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19747.7480 - val_loss: 22949.2402\n",
      "Epoch 468/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 19672.8418 - val_loss: 22855.7402\n",
      "Epoch 469/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 19582.9199 - val_loss: 22756.2480\n",
      "Epoch 470/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19500.4062 - val_loss: 22658.1133\n",
      "Epoch 471/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19419.7539 - val_loss: 22569.9961\n",
      "Epoch 472/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 19341.9922 - val_loss: 22477.6855\n",
      "Epoch 473/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 19257.8398 - val_loss: 22383.8477\n",
      "Epoch 474/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 19176.7148 - val_loss: 22301.9707\n",
      "Epoch 475/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 19104.7324 - val_loss: 22205.3359\n",
      "Epoch 476/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 19023.0996 - val_loss: 22137.6973\n",
      "Epoch 477/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18943.1230 - val_loss: 22024.2109\n",
      "Epoch 478/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18863.2168 - val_loss: 21938.5000\n",
      "Epoch 479/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 18777.9004 - val_loss: 21847.0742\n",
      "Epoch 480/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18697.9648 - val_loss: 21760.6172\n",
      "Epoch 481/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 18623.8516 - val_loss: 21665.2598\n",
      "Epoch 482/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 18544.0898 - val_loss: 21588.2422\n",
      "Epoch 483/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 18463.8691 - val_loss: 21486.1680\n",
      "Epoch 484/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18384.6738 - val_loss: 21432.8965\n",
      "Epoch 485/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18309.2734 - val_loss: 21299.2988\n",
      "Epoch 486/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 18230.1777 - val_loss: 21233.4473\n",
      "Epoch 487/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18179.2637 - val_loss: 21155.9629\n",
      "Epoch 488/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 18125.9102 - val_loss: 21064.3652\n",
      "Epoch 489/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 18048.1445 - val_loss: 20981.3164\n",
      "Epoch 490/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17968.7031 - val_loss: 20888.9863\n",
      "Epoch 491/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 17909.3750 - val_loss: 20819.6875\n",
      "Epoch 492/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 17842.5801 - val_loss: 20725.2402\n",
      "Epoch 493/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17755.6621 - val_loss: 20625.7578\n",
      "Epoch 494/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17665.0391 - val_loss: 20527.6328\n",
      "Epoch 495/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17588.4570 - val_loss: 20417.5059\n",
      "Epoch 496/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 17507.0703 - val_loss: 20356.4746\n",
      "Epoch 497/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17428.5254 - val_loss: 20248.5020\n",
      "Epoch 498/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 17343.1348 - val_loss: 20162.6172\n",
      "Epoch 499/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 17262.8867 - val_loss: 20079.9766\n",
      "Epoch 500/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 17177.5234 - val_loss: 19992.8691\n",
      "Epoch 501/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17104.5176 - val_loss: 19896.4453\n",
      "Epoch 502/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 17031.3652 - val_loss: 19804.3828\n",
      "Epoch 503/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16957.4941 - val_loss: 19725.8652\n",
      "Epoch 504/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16887.7812 - val_loss: 19636.0996\n",
      "Epoch 505/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 16808.9453 - val_loss: 19586.9062\n",
      "Epoch 506/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16736.7383 - val_loss: 19486.8301\n",
      "Epoch 507/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 16661.9102 - val_loss: 19392.0391\n",
      "Epoch 508/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16585.9688 - val_loss: 19310.8398\n",
      "Epoch 509/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16521.7578 - val_loss: 19232.8867\n",
      "Epoch 510/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 16450.2402 - val_loss: 19149.8984\n",
      "Epoch 511/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 16372.8242 - val_loss: 19057.0508\n",
      "Epoch 512/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 16307.4492 - val_loss: 18986.1074\n",
      "Epoch 513/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16233.6445 - val_loss: 18902.4180\n",
      "Epoch 514/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 16160.2051 - val_loss: 18820.1758\n",
      "Epoch 515/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 16091.3994 - val_loss: 18734.9902\n",
      "Epoch 516/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 16013.6367 - val_loss: 18639.0430\n",
      "Epoch 517/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 15945.3818 - val_loss: 18570.6289\n",
      "Epoch 518/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 15878.5381 - val_loss: 18482.1328\n",
      "Epoch 519/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 15796.0518 - val_loss: 18408.8438\n",
      "Epoch 520/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 15729.8213 - val_loss: 18318.9062\n",
      "Epoch 521/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15664.0918 - val_loss: 18246.8535\n",
      "Epoch 522/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 15599.1758 - val_loss: 18166.6113\n",
      "Epoch 523/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 15519.8193 - val_loss: 18072.8711\n",
      "Epoch 524/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15446.5869 - val_loss: 17991.0410\n",
      "Epoch 525/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15383.9648 - val_loss: 17915.0488\n",
      "Epoch 526/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15306.4414 - val_loss: 17827.7031\n",
      "Epoch 527/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15236.8262 - val_loss: 17752.3164\n",
      "Epoch 528/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 15164.7568 - val_loss: 17677.6172\n",
      "Epoch 529/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15094.6826 - val_loss: 17595.8027\n",
      "Epoch 530/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 15029.0420 - val_loss: 17506.4238\n",
      "Epoch 531/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14962.0605 - val_loss: 17438.2656\n",
      "Epoch 532/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14895.8926 - val_loss: 17362.0664\n",
      "Epoch 533/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 14824.3174 - val_loss: 17289.8574\n",
      "Epoch 534/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 14758.1299 - val_loss: 17200.6055\n",
      "Epoch 535/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 14692.0312 - val_loss: 17132.3203\n",
      "Epoch 536/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 14625.6367 - val_loss: 17054.0117\n",
      "Epoch 537/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 14555.2109 - val_loss: 16972.0410\n",
      "Epoch 538/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 14487.8633 - val_loss: 16894.4453\n",
      "Epoch 539/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14423.2656 - val_loss: 16819.2930\n",
      "Epoch 540/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14354.1406 - val_loss: 16741.0156\n",
      "Epoch 541/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14291.5850 - val_loss: 16669.9082\n",
      "Epoch 542/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14224.0859 - val_loss: 16591.5488\n",
      "Epoch 543/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14157.9033 - val_loss: 16524.9766\n",
      "Epoch 544/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 14093.8555 - val_loss: 16441.6855\n",
      "Epoch 545/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 14034.2637 - val_loss: 16389.3652\n",
      "Epoch 546/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13973.7803 - val_loss: 16302.7500\n",
      "Epoch 547/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13907.2793 - val_loss: 16211.8164\n",
      "Epoch 548/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13846.4736 - val_loss: 16147.5625\n",
      "Epoch 549/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13781.9102 - val_loss: 16084.4463\n",
      "Epoch 550/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13737.8320 - val_loss: 15999.6787\n",
      "Epoch 551/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 13649.2754 - val_loss: 15923.4980\n",
      "Epoch 552/1000\n",
      "18/18 [==============================] - 1s 37ms/step - loss: 13590.3389 - val_loss: 15843.7461\n",
      "Epoch 553/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 13521.5244 - val_loss: 15775.0000\n",
      "Epoch 554/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13453.7031 - val_loss: 15706.7539\n",
      "Epoch 555/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 13391.8379 - val_loss: 15628.4062\n",
      "Epoch 556/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 13328.5381 - val_loss: 15565.5850\n",
      "Epoch 557/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13275.1221 - val_loss: 15482.4170\n",
      "Epoch 558/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13209.4180 - val_loss: 15402.8945\n",
      "Epoch 559/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13149.2051 - val_loss: 15330.3330\n",
      "Epoch 560/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13082.4697 - val_loss: 15281.5645\n",
      "Epoch 561/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 13052.7324 - val_loss: 15226.5674\n",
      "Epoch 562/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12995.6318 - val_loss: 15151.1836\n",
      "Epoch 563/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12929.0088 - val_loss: 15087.6836\n",
      "Epoch 564/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12870.1016 - val_loss: 14998.8213\n",
      "Epoch 565/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12805.4580 - val_loss: 14904.2861\n",
      "Epoch 566/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 12735.8740 - val_loss: 14845.5762\n",
      "Epoch 567/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 12673.1533 - val_loss: 14771.5820\n",
      "Epoch 568/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 12612.1709 - val_loss: 14783.6230\n",
      "Epoch 569/1000\n",
      "18/18 [==============================] - 1s 34ms/step - loss: 12579.7412 - val_loss: 14645.6943\n",
      "Epoch 570/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 12502.7207 - val_loss: 14550.0479\n",
      "Epoch 571/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12438.0508 - val_loss: 14492.9941\n",
      "Epoch 572/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12382.3223 - val_loss: 14447.0156\n",
      "Epoch 573/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 12339.8262 - val_loss: 14422.3545\n",
      "Epoch 574/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 12273.4893 - val_loss: 14300.6270\n",
      "Epoch 575/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12194.9531 - val_loss: 14245.4570\n",
      "Epoch 576/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 12143.3525 - val_loss: 14236.0117\n",
      "Epoch 577/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 12078.8789 - val_loss: 14104.9375\n",
      "Epoch 578/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 12028.8428 - val_loss: 14012.0332\n",
      "Epoch 579/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11968.9688 - val_loss: 13954.1250\n",
      "Epoch 580/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 11895.2871 - val_loss: 13883.3604\n",
      "Epoch 581/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 11840.3291 - val_loss: 13868.5117\n",
      "Epoch 582/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 11776.9102 - val_loss: 13782.1045\n",
      "Epoch 583/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 11716.0293 - val_loss: 13733.2510\n",
      "Epoch 584/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11669.6387 - val_loss: 13648.7695\n",
      "Epoch 585/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 11606.1621 - val_loss: 13586.6943\n",
      "Epoch 586/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 11544.6309 - val_loss: 13517.1084\n",
      "Epoch 587/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 11491.1650 - val_loss: 13489.9912\n",
      "Epoch 588/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11433.6133 - val_loss: 13396.2373\n",
      "Epoch 589/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11377.6260 - val_loss: 13329.1064\n",
      "Epoch 590/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11320.6504 - val_loss: 13253.3555\n",
      "Epoch 591/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11260.8223 - val_loss: 13212.6035\n",
      "Epoch 592/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11206.4326 - val_loss: 13115.7861\n",
      "Epoch 593/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 11150.9854 - val_loss: 13091.7305\n",
      "Epoch 594/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 11100.0039 - val_loss: 12968.3213\n",
      "Epoch 595/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 11044.0625 - val_loss: 12947.5195\n",
      "Epoch 596/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10993.2627 - val_loss: 12865.0586\n",
      "Epoch 597/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 10930.5283 - val_loss: 12834.7227\n",
      "Epoch 598/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10875.7812 - val_loss: 12757.4961\n",
      "Epoch 599/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 10823.3574 - val_loss: 12663.0361\n",
      "Epoch 600/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10772.6006 - val_loss: 12632.3350\n",
      "Epoch 601/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10711.1416 - val_loss: 12538.3994\n",
      "Epoch 602/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 10665.1445 - val_loss: 12507.3662\n",
      "Epoch 603/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 10607.4062 - val_loss: 12453.2773\n",
      "Epoch 604/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 10550.2754 - val_loss: 12392.0908\n",
      "Epoch 605/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10498.1025 - val_loss: 12305.6201\n",
      "Epoch 606/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10450.7969 - val_loss: 12289.9258\n",
      "Epoch 607/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10398.5654 - val_loss: 12203.0000\n",
      "Epoch 608/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 10343.5586 - val_loss: 12125.4014\n",
      "Epoch 609/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10292.0586 - val_loss: 12100.6338\n",
      "Epoch 610/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 10232.4688 - val_loss: 12038.1318\n",
      "Epoch 611/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 10186.9326 - val_loss: 11972.9434\n",
      "Epoch 612/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 10132.5557 - val_loss: 11904.3760\n",
      "Epoch 613/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 10079.3359 - val_loss: 11860.4365\n",
      "Epoch 614/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 10028.9258 - val_loss: 11755.0381\n",
      "Epoch 615/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 9974.1816 - val_loss: 11726.7607\n",
      "Epoch 616/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9930.4355 - val_loss: 11646.7256\n",
      "Epoch 617/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9871.1914 - val_loss: 11597.4902\n",
      "Epoch 618/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9824.2070 - val_loss: 11502.5996\n",
      "Epoch 619/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9776.2773 - val_loss: 11453.7061\n",
      "Epoch 620/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 9729.9570 - val_loss: 11395.4141\n",
      "Epoch 621/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 9679.8730 - val_loss: 11342.3193\n",
      "Epoch 622/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9631.8438 - val_loss: 11289.5664\n",
      "Epoch 623/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9578.5898 - val_loss: 11213.6143\n",
      "Epoch 624/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 9554.4209 - val_loss: 11203.6289\n",
      "Epoch 625/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 9554.3955 - val_loss: 11165.3301\n",
      "Epoch 626/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 9484.8643 - val_loss: 11074.4355\n",
      "Epoch 627/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9416.8730 - val_loss: 11002.9395\n",
      "Epoch 628/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 9351.8994 - val_loss: 10978.9395\n",
      "Epoch 629/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 9298.7432 - val_loss: 10946.3428\n",
      "Epoch 630/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9254.0957 - val_loss: 10835.1543\n",
      "Epoch 631/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 9192.3506 - val_loss: 10778.6406\n",
      "Epoch 632/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9144.2129 - val_loss: 10737.1230\n",
      "Epoch 633/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9098.0791 - val_loss: 10695.0547\n",
      "Epoch 634/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 9052.0801 - val_loss: 10626.3867\n",
      "Epoch 635/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 9008.2617 - val_loss: 10559.7461\n",
      "Epoch 636/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 8956.7725 - val_loss: 10503.8838\n",
      "Epoch 637/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 8903.9863 - val_loss: 10436.9414\n",
      "Epoch 638/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8854.9014 - val_loss: 10335.5117\n",
      "Epoch 639/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8816.6895 - val_loss: 10327.7305\n",
      "Epoch 640/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8763.8789 - val_loss: 10278.8555\n",
      "Epoch 641/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8719.8301 - val_loss: 10237.1680\n",
      "Epoch 642/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 8671.4346 - val_loss: 10166.1514\n",
      "Epoch 643/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 8626.8320 - val_loss: 10142.7227\n",
      "Epoch 644/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 8594.9248 - val_loss: 10095.7598\n",
      "Epoch 645/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8555.3320 - val_loss: 10032.5371\n",
      "Epoch 646/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8503.7275 - val_loss: 10001.0742\n",
      "Epoch 647/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8455.4072 - val_loss: 9913.4102\n",
      "Epoch 648/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8450.3252 - val_loss: 9962.4639\n",
      "Epoch 649/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8385.3574 - val_loss: 9791.8662\n",
      "Epoch 650/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8329.7373 - val_loss: 9733.7080\n",
      "Epoch 651/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8292.7930 - val_loss: 9685.6523\n",
      "Epoch 652/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 8260.4219 - val_loss: 9716.5820\n",
      "Epoch 653/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 8208.3486 - val_loss: 9570.3262\n",
      "Epoch 654/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 8158.6050 - val_loss: 9583.4365\n",
      "Epoch 655/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 8127.1006 - val_loss: 9460.4707\n",
      "Epoch 656/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8073.2588 - val_loss: 9443.9062\n",
      "Epoch 657/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 8034.4697 - val_loss: 9431.4785\n",
      "Epoch 658/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7996.9688 - val_loss: 9418.4248\n",
      "Epoch 659/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 7953.6572 - val_loss: 9315.8887\n",
      "Epoch 660/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 7899.1597 - val_loss: 9286.6211\n",
      "Epoch 661/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7852.9341 - val_loss: 9192.5869\n",
      "Epoch 662/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7807.8706 - val_loss: 9140.5547\n",
      "Epoch 663/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7760.0200 - val_loss: 9116.8750\n",
      "Epoch 664/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7724.5957 - val_loss: 9051.3672\n",
      "Epoch 665/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7680.3770 - val_loss: 8998.0586\n",
      "Epoch 666/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7637.0781 - val_loss: 8970.1836\n",
      "Epoch 667/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7593.5903 - val_loss: 8912.2959\n",
      "Epoch 668/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7553.3394 - val_loss: 8833.9258\n",
      "Epoch 669/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7513.9116 - val_loss: 8811.4990\n",
      "Epoch 670/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 7498.8223 - val_loss: 8805.6113\n",
      "Epoch 671/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 7529.2163 - val_loss: 8858.8643\n",
      "Epoch 672/1000\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 7498.1040 - val_loss: 8610.2480\n",
      "Epoch 673/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 7377.7524 - val_loss: 8570.8477\n",
      "Epoch 674/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 7351.8994 - val_loss: 8574.9307\n",
      "Epoch 675/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 7328.8169 - val_loss: 8597.8477\n",
      "Epoch 676/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7284.3574 - val_loss: 8441.5723\n",
      "Epoch 677/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7224.6079 - val_loss: 8375.8770\n",
      "Epoch 678/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7175.2363 - val_loss: 8361.3369\n",
      "Epoch 679/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7126.1206 - val_loss: 8328.2666\n",
      "Epoch 680/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 7085.8774 - val_loss: 8232.3965\n",
      "Epoch 681/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7042.5059 - val_loss: 8214.3545\n",
      "Epoch 682/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 7002.4165 - val_loss: 8151.2612\n",
      "Epoch 683/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6961.7598 - val_loss: 8102.5581\n",
      "Epoch 684/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6921.2749 - val_loss: 8050.0356\n",
      "Epoch 685/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6878.5029 - val_loss: 8001.2021\n",
      "Epoch 686/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6837.5879 - val_loss: 7984.0737\n",
      "Epoch 687/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6804.8481 - val_loss: 7925.0166\n",
      "Epoch 688/1000\n",
      "18/18 [==============================] - 1s 32ms/step - loss: 6761.3735 - val_loss: 7875.1807\n",
      "Epoch 689/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 6722.5103 - val_loss: 7841.6006\n",
      "Epoch 690/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6685.1655 - val_loss: 7787.9209\n",
      "Epoch 691/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6649.2036 - val_loss: 7748.3540\n",
      "Epoch 692/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6614.6411 - val_loss: 7700.5469\n",
      "Epoch 693/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6580.9458 - val_loss: 7663.2012\n",
      "Epoch 694/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6536.1465 - val_loss: 7615.0522\n",
      "Epoch 695/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6498.8066 - val_loss: 7550.8013\n",
      "Epoch 696/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6465.4624 - val_loss: 7576.0020\n",
      "Epoch 697/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6433.0332 - val_loss: 7467.0522\n",
      "Epoch 698/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6398.6846 - val_loss: 7542.8750\n",
      "Epoch 699/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 6397.5396 - val_loss: 7413.9834\n",
      "Epoch 700/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6345.2075 - val_loss: 7403.5850\n",
      "Epoch 701/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6292.5176 - val_loss: 7395.3340\n",
      "Epoch 702/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6273.1973 - val_loss: 7357.0996\n",
      "Epoch 703/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 6221.3784 - val_loss: 7261.9590\n",
      "Epoch 704/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 6192.8374 - val_loss: 7194.9512\n",
      "Epoch 705/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 6154.9849 - val_loss: 7137.2612\n",
      "Epoch 706/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 6124.8906 - val_loss: 7140.3804\n",
      "Epoch 707/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6086.4473 - val_loss: 7077.7422\n",
      "Epoch 708/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 6049.0122 - val_loss: 7023.8555\n",
      "Epoch 709/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 6001.2178 - val_loss: 6987.4595\n",
      "Epoch 710/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5967.6694 - val_loss: 6951.2759\n",
      "Epoch 711/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5926.9766 - val_loss: 6894.0898\n",
      "Epoch 712/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5896.6182 - val_loss: 6914.0269\n",
      "Epoch 713/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5870.0942 - val_loss: 6848.9004\n",
      "Epoch 714/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5827.0801 - val_loss: 6787.6719\n",
      "Epoch 715/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5797.3398 - val_loss: 6724.4937\n",
      "Epoch 716/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5789.2144 - val_loss: 6763.7954\n",
      "Epoch 717/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5767.1807 - val_loss: 6685.4141\n",
      "Epoch 718/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5713.0566 - val_loss: 6658.1230\n",
      "Epoch 719/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5676.4370 - val_loss: 6582.6626\n",
      "Epoch 720/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5636.2017 - val_loss: 6568.3218\n",
      "Epoch 721/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 5597.5723 - val_loss: 6524.2368\n",
      "Epoch 722/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5562.8467 - val_loss: 6469.2295\n",
      "Epoch 723/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 5537.4370 - val_loss: 6502.8813\n",
      "Epoch 724/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5541.5371 - val_loss: 6482.4199\n",
      "Epoch 725/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5493.7285 - val_loss: 6408.3623\n",
      "Epoch 726/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5496.7207 - val_loss: 6400.6846\n",
      "Epoch 727/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5428.4194 - val_loss: 6332.9434\n",
      "Epoch 728/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5384.8247 - val_loss: 6273.1235\n",
      "Epoch 729/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5334.0024 - val_loss: 6202.0728\n",
      "Epoch 730/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5311.6118 - val_loss: 6182.4663\n",
      "Epoch 731/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5279.2554 - val_loss: 6124.3521\n",
      "Epoch 732/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5250.5532 - val_loss: 6078.9375\n",
      "Epoch 733/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5228.3374 - val_loss: 6079.2310\n",
      "Epoch 734/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 5216.7173 - val_loss: 6071.9912\n",
      "Epoch 735/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 5177.3213 - val_loss: 6009.4209\n",
      "Epoch 736/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5126.7866 - val_loss: 5927.9702\n",
      "Epoch 737/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 5084.6899 - val_loss: 5919.2783\n",
      "Epoch 738/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 5085.0327 - val_loss: 5912.8823\n",
      "Epoch 739/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 5043.4551 - val_loss: 5874.4434\n",
      "Epoch 740/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 5009.1250 - val_loss: 5822.9287\n",
      "Epoch 741/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 5013.4185 - val_loss: 5796.8237\n",
      "Epoch 742/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4941.7368 - val_loss: 5752.9629\n",
      "Epoch 743/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4906.9775 - val_loss: 5732.3003\n",
      "Epoch 744/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4861.4580 - val_loss: 5704.9087\n",
      "Epoch 745/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 4845.9385 - val_loss: 5642.6572\n",
      "Epoch 746/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 4826.0840 - val_loss: 5623.4653\n",
      "Epoch 747/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4782.7871 - val_loss: 5580.7715\n",
      "Epoch 748/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 4747.0762 - val_loss: 5547.7598\n",
      "Epoch 749/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 4720.3784 - val_loss: 5516.7910\n",
      "Epoch 750/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4694.5972 - val_loss: 5480.5547\n",
      "Epoch 751/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4662.0786 - val_loss: 5463.0879\n",
      "Epoch 752/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 4628.5630 - val_loss: 5426.8486\n",
      "Epoch 753/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4604.0439 - val_loss: 5373.6636\n",
      "Epoch 754/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4561.8560 - val_loss: 5326.4033\n",
      "Epoch 755/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4538.5361 - val_loss: 5300.0518\n",
      "Epoch 756/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4512.1982 - val_loss: 5263.1016\n",
      "Epoch 757/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 4486.2251 - val_loss: 5225.6011\n",
      "Epoch 758/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 4455.2358 - val_loss: 5211.7607\n",
      "Epoch 759/1000\n",
      "18/18 [==============================] - 1s 33ms/step - loss: 4434.6772 - val_loss: 5183.5996\n",
      "Epoch 760/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4420.0176 - val_loss: 5143.4834\n",
      "Epoch 761/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 4370.2993 - val_loss: 5098.6621\n",
      "Epoch 762/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 4341.2461 - val_loss: 5091.4766\n",
      "Epoch 763/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4313.2925 - val_loss: 5047.2339\n",
      "Epoch 764/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 4291.5703 - val_loss: 5012.7769\n",
      "Epoch 765/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4259.9048 - val_loss: 4995.7832\n",
      "Epoch 766/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 4227.8223 - val_loss: 4939.9990\n",
      "Epoch 767/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 4214.7954 - val_loss: 4921.7783\n",
      "Epoch 768/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 4179.4067 - val_loss: 4915.3853\n",
      "Epoch 769/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4149.3306 - val_loss: 4879.9697\n",
      "Epoch 770/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4128.5308 - val_loss: 4876.2310\n",
      "Epoch 771/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4096.1914 - val_loss: 4808.3984\n",
      "Epoch 772/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4072.5369 - val_loss: 4788.9609\n",
      "Epoch 773/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 4073.0959 - val_loss: 4877.5742\n",
      "Epoch 774/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 4041.3740 - val_loss: 4727.7979\n",
      "Epoch 775/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 4009.1965 - val_loss: 4693.1465\n",
      "Epoch 776/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 3987.6060 - val_loss: 4626.2725\n",
      "Epoch 777/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3953.8030 - val_loss: 4647.7144\n",
      "Epoch 778/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3961.9041 - val_loss: 4756.9971\n",
      "Epoch 779/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3949.5168 - val_loss: 4634.1270\n",
      "Epoch 780/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3893.9353 - val_loss: 4550.1309\n",
      "Epoch 781/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 3879.0381 - val_loss: 4449.5840\n",
      "Epoch 782/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3829.7527 - val_loss: 4431.2432\n",
      "Epoch 783/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3819.7327 - val_loss: 4432.5947\n",
      "Epoch 784/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 3804.0574 - val_loss: 4386.1426\n",
      "Epoch 785/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3766.5083 - val_loss: 4379.7153\n",
      "Epoch 786/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3750.8906 - val_loss: 4345.3042\n",
      "Epoch 787/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3724.2378 - val_loss: 4352.5488\n",
      "Epoch 788/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3708.5525 - val_loss: 4392.4297\n",
      "Epoch 789/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3714.7908 - val_loss: 4280.0596\n",
      "Epoch 790/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3682.2842 - val_loss: 4275.7998\n",
      "Epoch 791/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 3621.6099 - val_loss: 4278.0156\n",
      "Epoch 792/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3681.0569 - val_loss: 4276.5146\n",
      "Epoch 793/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 3597.5964 - val_loss: 4180.4448\n",
      "Epoch 794/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 3532.1785 - val_loss: 4129.1460\n",
      "Epoch 795/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 3519.2507 - val_loss: 4110.4165\n",
      "Epoch 796/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3484.6340 - val_loss: 4093.7334\n",
      "Epoch 797/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3470.4182 - val_loss: 4040.6201\n",
      "Epoch 798/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 3430.4521 - val_loss: 4007.8628\n",
      "Epoch 799/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3401.4717 - val_loss: 3980.6650\n",
      "Epoch 800/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3374.7266 - val_loss: 3957.7666\n",
      "Epoch 801/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3350.1025 - val_loss: 3908.8816\n",
      "Epoch 802/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3324.3154 - val_loss: 3892.7075\n",
      "Epoch 803/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3315.0361 - val_loss: 3891.0391\n",
      "Epoch 804/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 3282.3093 - val_loss: 3859.0681\n",
      "Epoch 805/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 3255.6597 - val_loss: 3798.9778\n",
      "Epoch 806/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3226.1284 - val_loss: 3791.3884\n",
      "Epoch 807/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 3203.8186 - val_loss: 3762.5017\n",
      "Epoch 808/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 3203.3311 - val_loss: 3742.1692\n",
      "Epoch 809/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3177.3655 - val_loss: 3721.4932\n",
      "Epoch 810/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3146.5200 - val_loss: 3674.6702\n",
      "Epoch 811/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 3115.5852 - val_loss: 3649.0222\n",
      "Epoch 812/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 3096.1189 - val_loss: 3631.0386\n",
      "Epoch 813/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3069.2119 - val_loss: 3587.8801\n",
      "Epoch 814/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 3049.9944 - val_loss: 3571.0876\n",
      "Epoch 815/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3027.9565 - val_loss: 3537.9023\n",
      "Epoch 816/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 3009.6401 - val_loss: 3490.1257\n",
      "Epoch 817/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2988.8643 - val_loss: 3477.8481\n",
      "Epoch 818/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2965.7893 - val_loss: 3480.1125\n",
      "Epoch 819/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2949.6528 - val_loss: 3450.0781\n",
      "Epoch 820/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2927.5557 - val_loss: 3402.0613\n",
      "Epoch 821/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2916.7666 - val_loss: 3414.1255\n",
      "Epoch 822/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2910.7090 - val_loss: 3459.7920\n",
      "Epoch 823/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2893.6001 - val_loss: 3363.8228\n",
      "Epoch 824/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2856.2815 - val_loss: 3347.9055\n",
      "Epoch 825/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2823.5806 - val_loss: 3354.7422\n",
      "Epoch 826/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2801.2197 - val_loss: 3360.8420\n",
      "Epoch 827/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2800.5872 - val_loss: 3287.0173\n",
      "Epoch 828/1000\n",
      "18/18 [==============================] - 0s 26ms/step - loss: 2773.0154 - val_loss: 3288.1118\n",
      "Epoch 829/1000\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 2752.6951 - val_loss: 3218.3818\n",
      "Epoch 830/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2737.8701 - val_loss: 3206.2378\n",
      "Epoch 831/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2712.5286 - val_loss: 3222.1396\n",
      "Epoch 832/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2692.5410 - val_loss: 3192.2192\n",
      "Epoch 833/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2711.4404 - val_loss: 3267.8586\n",
      "Epoch 834/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2724.9072 - val_loss: 3103.7383\n",
      "Epoch 835/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2691.9817 - val_loss: 3059.6912\n",
      "Epoch 836/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2659.2266 - val_loss: 3100.4805\n",
      "Epoch 837/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2656.0024 - val_loss: 3120.0547\n",
      "Epoch 838/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2736.6794 - val_loss: 3152.2847\n",
      "Epoch 839/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2633.9919 - val_loss: 3092.9932\n",
      "Epoch 840/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2583.7795 - val_loss: 3085.5903\n",
      "Epoch 841/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2559.7080 - val_loss: 3018.8879\n",
      "Epoch 842/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2512.1409 - val_loss: 2970.3604\n",
      "Epoch 843/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 2502.9700 - val_loss: 3031.7903\n",
      "Epoch 844/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 2511.3394 - val_loss: 2940.9531\n",
      "Epoch 845/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 2442.5190 - val_loss: 2863.3545\n",
      "Epoch 846/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 2428.3655 - val_loss: 2843.1580\n",
      "Epoch 847/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2414.4956 - val_loss: 2956.6555\n",
      "Epoch 848/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 2410.9082 - val_loss: 2806.9087\n",
      "Epoch 849/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2408.9812 - val_loss: 2849.5029\n",
      "Epoch 850/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2383.8452 - val_loss: 2792.9717\n",
      "Epoch 851/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2418.6792 - val_loss: 3013.3464\n",
      "Epoch 852/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2387.5632 - val_loss: 2735.5742\n",
      "Epoch 853/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 2339.0835 - val_loss: 2804.5679\n",
      "Epoch 854/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2332.8804 - val_loss: 2690.4380\n",
      "Epoch 855/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2290.9382 - val_loss: 2698.4531\n",
      "Epoch 856/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2268.8135 - val_loss: 2688.6379\n",
      "Epoch 857/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2271.7849 - val_loss: 2633.5029\n",
      "Epoch 858/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 2223.1907 - val_loss: 2581.1067\n",
      "Epoch 859/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2203.5479 - val_loss: 2592.5181\n",
      "Epoch 860/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 2187.0103 - val_loss: 2568.6831\n",
      "Epoch 861/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 2187.9590 - val_loss: 2543.6096\n",
      "Epoch 862/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2190.1797 - val_loss: 2506.3494\n",
      "Epoch 863/1000\n",
      "18/18 [==============================] - 1s 26ms/step - loss: 2161.5442 - val_loss: 2540.5168\n",
      "Epoch 864/1000\n",
      "18/18 [==============================] - 0s 27ms/step - loss: 2134.0825 - val_loss: 2591.3477\n",
      "Epoch 865/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2117.2905 - val_loss: 2515.1777\n",
      "Epoch 866/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2094.4385 - val_loss: 2542.3486\n",
      "Epoch 867/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 2078.7971 - val_loss: 2455.8081\n",
      "Epoch 868/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2047.2886 - val_loss: 2396.3274\n",
      "Epoch 869/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 2040.2222 - val_loss: 2436.4080\n",
      "Epoch 870/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2044.4073 - val_loss: 2402.9114\n",
      "Epoch 871/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 2011.0896 - val_loss: 2360.6116\n",
      "Epoch 872/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1983.5603 - val_loss: 2304.0056\n",
      "Epoch 873/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1962.4478 - val_loss: 2311.6155\n",
      "Epoch 874/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1943.5425 - val_loss: 2305.9395\n",
      "Epoch 875/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1922.8638 - val_loss: 2334.6470\n",
      "Epoch 876/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1910.0951 - val_loss: 2268.4165\n",
      "Epoch 877/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1895.7212 - val_loss: 2241.0356\n",
      "Epoch 878/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1874.8650 - val_loss: 2225.3557\n",
      "Epoch 879/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1870.5120 - val_loss: 2204.0408\n",
      "Epoch 880/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 1847.8867 - val_loss: 2198.0635\n",
      "Epoch 881/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1844.8066 - val_loss: 2232.0537\n",
      "Epoch 882/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1846.6326 - val_loss: 2227.6030\n",
      "Epoch 883/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1844.9012 - val_loss: 2162.0576\n",
      "Epoch 884/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1796.1927 - val_loss: 2137.8623\n",
      "Epoch 885/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1775.7323 - val_loss: 2105.9175\n",
      "Epoch 886/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1762.9673 - val_loss: 2095.1121\n",
      "Epoch 887/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1747.8871 - val_loss: 2087.0251\n",
      "Epoch 888/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1732.2546 - val_loss: 2054.9846\n",
      "Epoch 889/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1719.9282 - val_loss: 2035.0026\n",
      "Epoch 890/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1706.3458 - val_loss: 2016.0510\n",
      "Epoch 891/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1689.7069 - val_loss: 2026.4403\n",
      "Epoch 892/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1693.6466 - val_loss: 2049.4514\n",
      "Epoch 893/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1666.4312 - val_loss: 2005.6180\n",
      "Epoch 894/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1651.1445 - val_loss: 1980.4043\n",
      "Epoch 895/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1635.7837 - val_loss: 1999.1775\n",
      "Epoch 896/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1623.8386 - val_loss: 1949.7144\n",
      "Epoch 897/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1615.4790 - val_loss: 1887.9526\n",
      "Epoch 898/1000\n",
      "18/18 [==============================] - 1s 29ms/step - loss: 1606.3810 - val_loss: 1892.1654\n",
      "Epoch 899/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1592.2667 - val_loss: 1893.4509\n",
      "Epoch 900/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1578.7947 - val_loss: 1897.6942\n",
      "Epoch 901/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1561.8546 - val_loss: 1850.8429\n",
      "Epoch 902/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1541.9900 - val_loss: 1842.8650\n",
      "Epoch 903/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1531.4458 - val_loss: 1832.3080\n",
      "Epoch 904/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1516.2061 - val_loss: 1816.3617\n",
      "Epoch 905/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1504.0494 - val_loss: 1803.4302\n",
      "Epoch 906/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1492.5298 - val_loss: 1765.0955\n",
      "Epoch 907/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1494.8285 - val_loss: 1861.8440\n",
      "Epoch 908/1000\n",
      "18/18 [==============================] - 0s 16ms/step - loss: 1489.0687 - val_loss: 1857.8407\n",
      "Epoch 909/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1493.3147 - val_loss: 1751.3448\n",
      "Epoch 910/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1482.7264 - val_loss: 1868.1686\n",
      "Epoch 911/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1519.4438 - val_loss: 1831.0764\n",
      "Epoch 912/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1501.6785 - val_loss: 1812.4990\n",
      "Epoch 913/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1486.1714 - val_loss: 1877.1146\n",
      "Epoch 914/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1580.8921 - val_loss: 1832.5063\n",
      "Epoch 915/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1520.4203 - val_loss: 1804.2606\n",
      "Epoch 916/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1487.5363 - val_loss: 1796.3724\n",
      "Epoch 917/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1476.1804 - val_loss: 1685.2555\n",
      "Epoch 918/1000\n",
      "18/18 [==============================] - 0s 15ms/step - loss: 1415.2690 - val_loss: 1655.5090\n",
      "Epoch 919/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1380.2173 - val_loss: 1641.5039\n",
      "Epoch 920/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1361.8984 - val_loss: 1641.1929\n",
      "Epoch 921/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1340.2291 - val_loss: 1615.4127\n",
      "Epoch 922/1000\n",
      "18/18 [==============================] - 0s 23ms/step - loss: 1351.2001 - val_loss: 1603.9918\n",
      "Epoch 923/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1312.9242 - val_loss: 1602.3892\n",
      "Epoch 924/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1329.6956 - val_loss: 1586.2280\n",
      "Epoch 925/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1325.0383 - val_loss: 1627.0009\n",
      "Epoch 926/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1309.2775 - val_loss: 1550.1316\n",
      "Epoch 927/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1298.6890 - val_loss: 1596.5579\n",
      "Epoch 928/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1283.8812 - val_loss: 1537.0201\n",
      "Epoch 929/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1268.1696 - val_loss: 1511.9532\n",
      "Epoch 930/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1257.4546 - val_loss: 1480.5037\n",
      "Epoch 931/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1264.5516 - val_loss: 1515.2036\n",
      "Epoch 932/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1264.8590 - val_loss: 1538.8772\n",
      "Epoch 933/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1242.1167 - val_loss: 1606.1478\n",
      "Epoch 934/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 1271.2601 - val_loss: 1541.6443\n",
      "Epoch 935/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1234.0576 - val_loss: 1452.8448\n",
      "Epoch 936/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1210.6771 - val_loss: 1432.5270\n",
      "Epoch 937/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1188.5629 - val_loss: 1381.0448\n",
      "Epoch 938/1000\n",
      "18/18 [==============================] - 0s 25ms/step - loss: 1165.7201 - val_loss: 1478.5490\n",
      "Epoch 939/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1149.6995 - val_loss: 1433.1659\n",
      "Epoch 940/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1136.7686 - val_loss: 1430.3319\n",
      "Epoch 941/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1133.8640 - val_loss: 1426.5631\n",
      "Epoch 942/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1118.0225 - val_loss: 1363.6012\n",
      "Epoch 943/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 1118.8940 - val_loss: 1414.4567\n",
      "Epoch 944/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1105.4542 - val_loss: 1400.7830\n",
      "Epoch 945/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1097.4768 - val_loss: 1390.1913\n",
      "Epoch 946/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1066.5649 - val_loss: 1355.6113\n",
      "Epoch 947/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1075.3862 - val_loss: 1325.6775\n",
      "Epoch 948/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 1048.4089 - val_loss: 1352.5620\n",
      "Epoch 949/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 1038.1626 - val_loss: 1354.8058\n",
      "Epoch 950/1000\n",
      "18/18 [==============================] - 0s 29ms/step - loss: 1025.8409 - val_loss: 1340.9214\n",
      "Epoch 951/1000\n",
      "18/18 [==============================] - 1s 31ms/step - loss: 1036.8180 - val_loss: 1263.5052\n",
      "Epoch 952/1000\n",
      "18/18 [==============================] - 0s 21ms/step - loss: 1034.1714 - val_loss: 1313.3008\n",
      "Epoch 953/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 1020.5355 - val_loss: 1308.9121\n",
      "Epoch 954/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 1017.8214 - val_loss: 1305.3613\n",
      "Epoch 955/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 999.2691 - val_loss: 1258.1230\n",
      "Epoch 956/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 988.4913 - val_loss: 1243.9236\n",
      "Epoch 957/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 976.2739 - val_loss: 1243.5005\n",
      "Epoch 958/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 973.8591 - val_loss: 1257.1180\n",
      "Epoch 959/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 970.6252 - val_loss: 1234.5089\n",
      "Epoch 960/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 960.7347 - val_loss: 1214.7179\n",
      "Epoch 961/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 971.0552 - val_loss: 1229.4243\n",
      "Epoch 962/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 948.6878 - val_loss: 1192.4766\n",
      "Epoch 963/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 932.8468 - val_loss: 1214.1931\n",
      "Epoch 964/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 926.5904 - val_loss: 1226.8242\n",
      "Epoch 965/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 899.3815 - val_loss: 1203.4790\n",
      "Epoch 966/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 886.5835 - val_loss: 1192.6906\n",
      "Epoch 967/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 877.5613 - val_loss: 1168.7762\n",
      "Epoch 968/1000\n",
      "18/18 [==============================] - 1s 35ms/step - loss: 867.7429 - val_loss: 1171.8306\n",
      "Epoch 969/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 865.5909 - val_loss: 1209.9465\n",
      "Epoch 970/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 861.3121 - val_loss: 1136.7778\n",
      "Epoch 971/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 847.7491 - val_loss: 1131.3262\n",
      "Epoch 972/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 840.0721 - val_loss: 1194.2732\n",
      "Epoch 973/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 835.4780 - val_loss: 1103.9736\n",
      "Epoch 974/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 834.1360 - val_loss: 1067.7021\n",
      "Epoch 975/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 828.1581 - val_loss: 1068.8193\n",
      "Epoch 976/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 830.7703 - val_loss: 1081.7113\n",
      "Epoch 977/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 813.2495 - val_loss: 1060.4946\n",
      "Epoch 978/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 807.7384 - val_loss: 1053.4731\n",
      "Epoch 979/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 796.1621 - val_loss: 1060.1362\n",
      "Epoch 980/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 781.1862 - val_loss: 1081.5815\n",
      "Epoch 981/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 779.4609 - val_loss: 1120.5055\n",
      "Epoch 982/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 771.9680 - val_loss: 1080.8364\n",
      "Epoch 983/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 761.3915 - val_loss: 1105.5441\n",
      "Epoch 984/1000\n",
      "18/18 [==============================] - 0s 28ms/step - loss: 759.2347 - val_loss: 1048.2533\n",
      "Epoch 985/1000\n",
      "18/18 [==============================] - 1s 30ms/step - loss: 768.9172 - val_loss: 1013.9147\n",
      "Epoch 986/1000\n",
      "18/18 [==============================] - 0s 22ms/step - loss: 750.0408 - val_loss: 988.1382\n",
      "Epoch 987/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 777.6506 - val_loss: 968.6025\n",
      "Epoch 988/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 758.7808 - val_loss: 1115.6534\n",
      "Epoch 989/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 761.1452 - val_loss: 935.3926\n",
      "Epoch 990/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 744.9570 - val_loss: 962.7280\n",
      "Epoch 991/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 734.5332 - val_loss: 958.4757\n",
      "Epoch 992/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 721.3511 - val_loss: 1052.1395\n",
      "Epoch 993/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 877.7970 - val_loss: 954.2292\n",
      "Epoch 994/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 820.4848 - val_loss: 1027.6720\n",
      "Epoch 995/1000\n",
      "18/18 [==============================] - 0s 17ms/step - loss: 775.3728 - val_loss: 951.2469\n",
      "Epoch 996/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 778.1381 - val_loss: 1059.1377\n",
      "Epoch 997/1000\n",
      "18/18 [==============================] - 0s 20ms/step - loss: 873.3187 - val_loss: 944.8959\n",
      "Epoch 998/1000\n",
      "18/18 [==============================] - 0s 18ms/step - loss: 790.9757 - val_loss: 950.0179\n",
      "Epoch 999/1000\n",
      "18/18 [==============================] - 0s 19ms/step - loss: 909.5823 - val_loss: 1104.4517\n",
      "Epoch 1000/1000\n",
      "18/18 [==============================] - 0s 24ms/step - loss: 833.0422 - val_loss: 1060.2468\n",
      "Keras weights file (<HDF5 file \"variables.h5\" (mode r+)>) saving:\n",
      "...layers\n",
      "......dense\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "......lstm\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "......lstm_1\n",
      ".........cell\n",
      "............vars\n",
      "...............0\n",
      "...............1\n",
      "...............2\n",
      ".........vars\n",
      "...metrics\n",
      "......mean\n",
      ".........vars\n",
      "............0\n",
      "............1\n",
      "...optimizer\n",
      "......vars\n",
      ".........0\n",
      ".........1\n",
      ".........10\n",
      ".........11\n",
      ".........12\n",
      ".........13\n",
      ".........14\n",
      ".........15\n",
      ".........16\n",
      ".........2\n",
      ".........3\n",
      ".........4\n",
      ".........5\n",
      ".........6\n",
      ".........7\n",
      ".........8\n",
      ".........9\n",
      "...vars\n",
      "Keras model archive saving:\n",
      "File Name                                             Modified             Size\n",
      "metadata.json                                  2023-10-24 03:19:54           64\n",
      "config.json                                    2023-10-24 03:19:54         2641\n",
      "variables.h5                                   2023-10-24 03:19:55       461544\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'solar_generation')\n",
    "        joblib.dump(xgb, 'my_models/models/solar_generation_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'solar_generation')\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'solar_generation')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'solar_generation')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/solar_generation_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/solar_generation_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'solar_generation',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/solar_generation_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ab787-e32b-46d3-85ae-62dac941cd32",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e126c5a-4598-475a-a22b-001c1d1da927",
   "metadata": {},
   "source": [
    "### LightGBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dbe62f7-aa7c-4b50-88d1-7911ef439a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LightGBM_Model(b,hpt,feature):\n",
    "\n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_cooling_demand.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        # Create an AdaBoost model with LightGBM as the base estimator\n",
    "        #adaboost_model = AdaBoostRegressor(base_estimator=grid_search_mean, n_estimators=50)\n",
    "        #adaboost_model.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Done!\")\n",
    "        return grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        'verbose':-1,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        # Create an AdaBoost model with LightGBM as the base estimator\n",
    "        #adaboost_model = AdaBoostRegressor(base_estimator=gbm, n_estimators=50)\n",
    "        #adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "        return gbm#adaboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a4eb7-7354-489d-9be9-5b96f581b0f7",
   "metadata": {},
   "source": [
    "### XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c1069a8-60aa-44ec-9c7f-dbd6588ecb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def XGBoost_Model(b,hpt,feature):\n",
    "    \n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_'+str(feature)+'.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    reg = XGBRegressor(n_estimators=100)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50)\n",
    "\n",
    "    return reg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0578c-a0d3-4710-85aa-10d0fe5b25f4",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96430fdc-557d-4e7f-9995-3c6ad418da3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(b,hpt,feature):\n",
    "\n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_cooling_demand.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    # Reshape data for LSTM input (samples, sequence_length, num_features)\n",
    "    X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Use early stopping to prevent overfitting\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3293d557-b44e-41e5-8811-cb148cec1387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomKerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, build_fn, input_shape, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.input_shape = input_shape\n",
    "        self.kwargs = kwargs\n",
    "        self.estimator = KerasRegressor(build_fn=self.build_fn, **self.kwargs)\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        # Reshape input data for LSTM (if necessary)\n",
    "        if X.ndim == 2:\n",
    "            X = np.reshape(X, (X.shape[0], self.input_shape[0], self.input_shape[1]))\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Reshape input data for LSTM (if necessary)\n",
    "        if X.ndim == 2:\n",
    "            X = np.reshape(X, (X.shape[0], self.input_shape[0], self.input_shape[1]))\n",
    "        # Get predictions\n",
    "        predictions = self.estimator.predict(X)\n",
    "        # Reshape predictions back to 2D array\n",
    "        predictions = np.reshape(predictions, (-1, 1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94e87328-a232-416b-969f-82bdd4b76576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(learning_rate=0.001, units=50, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, input_shape=(1, num_features)))\n",
    "    model.add(Dense(units=1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f65ec4e1-134d-4d0c-b2e5-8b87c4c55dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function that returns the LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "024ea8fa-812f-4f1e-b0c0-ae8886e8c379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Fusion_Model(b,hpt,feature,lstm_model,lightgbm_model):\n",
    "    \n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_'+str(feature)+'.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Create an ensemble model using VotingRegressor\n",
    "    ensemble_model = VotingRegressor(estimators=[('lstm', lstm_model), ('lgbm', lightgbm_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b38e0e-c673-41fe-8a97-b1890cc25c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6c123-ac24-4957-b317-74a0d5ec6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ce45e-3ec4-4765-a8da-5568a4e5aabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f4244-379d-4021-bd9a-dd69ce80ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ba147-6d10-4b20-8cb5-56cb16f6cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560235de-5577-4919-bdf6-1021ef6f79e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b85efd-8c1a-43bb-82a3-9d1ca6e195fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc2b52-6236-4670-89da-86023cbed3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cb36f-9613-48eb-90be-cffe73c682b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0fd6a-fc08-4de4-9682-9cc373d5a018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fa69f-e93f-427d-bee1-d415a68da321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725c757-8501-4b1e-b9cc-b9e71372a9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0a531-5522-4c3a-a99f-fb61b9d50d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
