{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaaa4c5-871d-4a4d-bab0-4b18ac8f4f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the Datasets\n",
    "filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "# Building information\n",
    "b_1 = pd.read_csv(filepath + 'Building_1.csv')\n",
    "b_2 = pd.read_csv(filepath + 'Building_2.csv')\n",
    "b_3 = pd.read_csv(filepath + 'Building_3.csv')\n",
    "\n",
    "# Other information\n",
    "carbon_int = pd.read_csv(filepath + 'carbon_intensity.csv')\n",
    "pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "# Building level combine the dfs\n",
    "comb_b_1 = pd.concat([b_1.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_2 = pd.concat([b_2.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_3 = pd.concat([b_3.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Make a list of the buildings\n",
    "b_list = [comb_b_1,comb_b_2,comb_b_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9375f433-049f-4bef-bd38-7f04176885c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataframes contain inf\n",
    "\n",
    "# Building 1\n",
    "d = np.isfinite(comb_b_1) \n",
    "\n",
    "# Building 2\n",
    "d = np.isfinite(comb_b_2) \n",
    "\n",
    "\n",
    "# Building 3\n",
    "d = np.isfinite(comb_b_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86ddbdb-0110-437c-ac53-65d2eddc65de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the titles\n",
    "b_list_clear = []\n",
    "\n",
    "for b in b_list:\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    b.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in b.columns.values]\n",
    "    b_list_clear.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7414601-9b7a-4173-b2d9-e0ffc395c892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3c530e-34c0-4a9e-ac13-f4f78e2c18af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost Models\n",
    "\n",
    "def XGBoost_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50,\n",
    "           verbose=False)\n",
    "     \n",
    "    y_pred  = reg.predict(X_test)\n",
    "    \n",
    "    # Generate the df\n",
    "    df = pd.DataFrame(\n",
    "        {'Actual Value': y_test,\n",
    "        'Predicted Value': y_pred\n",
    "        })\n",
    "\n",
    "    return df, reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a84c794-ae07-4b51-9b8c-5c6722394b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM Models\n",
    "\n",
    "# Generating the LightGBM\n",
    "\n",
    "def LightGBM_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_mean  = grid_search_mean.predict(X_test)\n",
    "    \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred_mean\n",
    "            })\n",
    "     \n",
    "        return df, grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred\n",
    "            })\n",
    "     \n",
    "        return df, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f207434d-97f7-4cd8-bda9-238301ce8514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429e4788-f351-4756-a93f-7829aaebe1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.) Cooling Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Cooling_Load__kWh_.csv')\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Cooling Load (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/cooling_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,False)\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_load_model_b'+str(i)+'.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/cooling_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27452a-1127-41fc-a893-6c5d95c34309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.) DHW Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['DHW Heating (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/dhw_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_load_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/dhw_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a83cc-268d-4cb1-9877-775741ed0c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Equipment Electric Power (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['Equipment Electric Power (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2834e4-4804-489c-a3d6-af83d8d552e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neighbour Level: Carbon Intensity (kgCO2e/kWh) ; Solar Generation (W/kW)\n",
    "\n",
    "# 1.) Carbon Intensity (kgCO2e/kWh)\n",
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_list_clear[0].reset_index(drop=True),\n",
    "                  b_list_clear[1].reset_index(drop=True),\n",
    "                  b_list_clear[2].reset_index(drop=True)])\n",
    "    \n",
    "# Generate the x,y\n",
    "X = comb\n",
    "y = comb['kg_CO2/kWh']\n",
    "\n",
    "# Generate the test,train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "    xgb.save_model('my_models/models/Carbon_Intensity_Power_model'+str(i)+'.json')\n",
    "if model_type == 'lgb':\n",
    "    df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_hyper.pkl')\n",
    "    #lgb.booster_.save_model('my_models/models/Carbon_Intensity_Power_model_hyper.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97252705-78b9-47eb-9f8c-9d43ea70974a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Solar Generation (W/kW)\n",
    "sg = []\n",
    "i = 1\n",
    "\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Solar_Generation__W_kW_.csv')\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Solar Generation (W/kW)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/solar_generation_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/solar_generation_model_b'+str(i)+'_hyper.txt')\n",
    "        \n",
    "    sg.append(df)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f803d1-2147-441d-b81e-e6ba3d3eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0602038-da7f-431b-953b-1bb651df694d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a9782-0f28-4740-9d24-b77843561a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8db2cc-8054-4ea2-8220-43de2b430118",
   "metadata": {},
   "source": [
    "### FastAI Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1e86d-7f6e-4785-b153-8e2076cd67ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timeseries_fastai.imports import *\n",
    "from timeseries_fastai.core import *\n",
    "from timeseries_fastai.data import *\n",
    "from timeseries_fastai.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaa2e8a-9daa-49f7-9d8b-09c75569eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "PATH = Path.cwd().parent\n",
    "df_train, df_test = load_df_ucr(PATH, 'Adiac')\n",
    "x_cols = df_train.columns[0:-2].to_list()\n",
    "dls = TSDataLoaders.from_dfs(df_train, df_test, x_cols=x_cols, label_col='target', bs=16)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc490-672a-43ce-b598-361aa5c0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = create_inception(1, len(dls.vocab))\n",
    "learn = Learner(dls, inception, metrics=[accuracy])\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dce875-c3b2-4d0b-8b88-c7a87fec0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919da4-085e-44d0-b2f9-1b6f3d1bf51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5842d6-363b-443a-ad1c-cc973ad2b05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397b1b9-30db-4028-ba4b-dea174caa9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a0d31-ec58-4b17-acdc-d2dc49df840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e06583-710d-4df3-9965-ec642b22c929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e28d1-5254-4e21-b7c4-7fb38d71a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe233854-bf7d-4a80-bfed-81810000b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73419dd6-584b-4e11-8484-0d6ff286ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af48f-cc40-4dec-b919-0d7a9a270b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74af4548-880e-487b-a639-d613ba14caa1",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba062f91-4daa-4f65-ad4a-b028f0f7030e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14a165a-d411-4cc4-9cc1-74e999435b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping the Features\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b74d9ad-c656-4b1a-be5e-edfaf2842d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a573e102-9041-4e76-8998-35445f86f858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a114b7b5-58cd-4a68-b82c-766a76667c46",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4071c164-b5b6-4eae-910f-081322985fe4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/p37/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-10-23 16:49:36.916873: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:49:36.917005: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-23 16:49:36.917023: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install category_encoders\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load\n",
    "import joblib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "from citylearn.citylearn import CityLearnEnv\n",
    "from my_models.user_model import SubmissionModel\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import logging\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5489a18-4f56-45ac-b34d-2cf9bf6bb33f",
   "metadata": {},
   "source": [
    "## Simulator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05333283-0a9d-4ca3-ae1c-6ce1378e18a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a test env\n",
    "class WrapperEnv:\n",
    "    \"\"\"\n",
    "    Env to wrap provide Citylearn Env data without providing full env\n",
    "    Preventing attribute access outside of the available functions\n",
    "    \"\"\"\n",
    "    def __init__(self, env_data):\n",
    "        self.observation_names = env_data['observation_names']\n",
    "        self.action_names = env_data['action_names']\n",
    "        self.observation_space = env_data['observation_space']\n",
    "        self.action_space = env_data['action_space']\n",
    "        self.time_steps = env_data['time_steps']\n",
    "        self.seconds_per_time_step = env_data['seconds_per_time_step']\n",
    "        self.random_seed = env_data['random_seed']\n",
    "        self.buildings_metadata = env_data['buildings_metadata']\n",
    "        self.episode_tracker = env_data['episode_tracker']\n",
    "    \n",
    "    def get_metadata(self):\n",
    "        return {'buildings': self.buildings_metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0049ca9f-53b0-417c-9f3b-13293825d09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_citylearn_env(config):\n",
    "    env = CityLearnEnv(config.SCHEMA)\n",
    "\n",
    "    env_data = dict(\n",
    "        observation_names = env.observation_names,\n",
    "        action_names = env.action_names,\n",
    "        observation_space = env.observation_space,\n",
    "        action_space = env.action_space,\n",
    "        time_steps = 720,\n",
    "        buildings_metadata = env.get_metadata()['buildings'],\n",
    "        num_buildings = len(env.buildings),\n",
    "        building_names = [b.name for b in env.buildings],\n",
    "        b0_pv_capacity = env.buildings[0].pv.nominal_power,\n",
    "    )\n",
    "\n",
    "    # Turn off actions for all buildings and do not simulate power outage (forecasting only).\n",
    "    for b in env.buildings:\n",
    "        b.ignore_dynamics = True\n",
    "        b.simulate_power_outage = False\n",
    "\n",
    "    return env, env_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0fe70e10-5cce-4035-8bd9-7486201d83b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    data_dir = './data/'\n",
    "    SCHEMA = os.path.join(data_dir, 'schemas/warm_up/schema.json')\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adf5221e-57fb-44ee-85b0-1fa6605e63b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env, env_data = create_citylearn_env(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15054c39-c5e2-477f-93fa-0a22f69b6242",
   "metadata": {},
   "source": [
    "## Generation of the Features\n",
    "\n",
    "\n",
    "TODO: Add the other features!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1783afd-efc0-4205-aa31-3bda2673da08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dataframes\n",
    "\n",
    "b_1_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_2_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_3_dataframe = pd.DataFrame(columns=['day_type', 'hour', 'outdoor_dry_bulb_temperature', 'outdoor_dry_bulb_temperature_predicted_6h', \n",
    "                                      'outdoor_dry_bulb_temperature_predicted_12h', 'outdoor_dry_bulb_temperature_predicted_24h', 'diffuse_solar_irradiance',\n",
    "                                      'diffuse_solar_irradiance_predicted_6h', 'diffuse_solar_irradiance_predicted_12h', \n",
    "                                      'diffuse_solar_irradiance_predicted_24h', 'direct_solar_irradiance', 'direct_solar_irradiance_predicted_6h',\n",
    "                                      'direct_solar_irradiance_predicted_12h', 'direct_solar_irradiance_predicted_24h', 'carbon_intensity', \n",
    "                                      'indoor_dry_bulb_temperature', 'non_shiftable_load', 'solar_generation', 'dhw_storage_soc', 'electrical_storage_soc', \n",
    "                                      'electricity_pricing', 'electricity_pricing_predicted_6h', \n",
    "                                      'electricity_pricing_predicted_12h', 'electricity_pricing_predicted_24h', 'cooling_demand',\n",
    "                                      'dhw_demand','indoor_dry_bulb_temperature_set_point','occupant_count','net_electricity_consumption'])\n",
    "\n",
    "b_dataframe_list = [b_1_dataframe,b_2_dataframe,b_3_dataframe]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70c42120-ce5a-46d1-af63-a279e2425823",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.67788136], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx, b in enumerate(env.buildings):\n",
    "    \n",
    "    con = b.net_electricity_consumption\n",
    "    print(str(len(con)))\n",
    "    \n",
    "env.buildings[0].net_electricity_consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0db48ddf-2417-4ca8-9663-70c05a33e7b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the Datasets for the different buildings:\n",
    "# Here I only need to simulate the ones, which are not present in the dataset:\n",
    "\n",
    "for idx, b in enumerate(env.buildings):\n",
    "    indoor_dry_bulb_temperature           = b.energy_simulation.indoor_dry_bulb_temperature\n",
    "    non_shiftable_load                    = b.energy_simulation.non_shiftable_load\n",
    "    solar_generation                      = b.energy_simulation.solar_generation\n",
    "    dhw_storage_soc                       = b.dhw_storage.soc\n",
    "    electrical_storage_soc                = b.electrical_storage.soc\n",
    "    cooling_demand                        = b.energy_simulation.cooling_demand\n",
    "    dhw_demand                            = b.energy_simulation.dhw_demand\n",
    "    indoor_dry_bulb_temperature_set_point = b.energy_simulation.indoor_dry_bulb_temperature_set_point\n",
    "    occupant_count                        = b.occupant_count.repeat(720)\n",
    "    net_electricity_consumption           = b.net_electricity_consumption.repeat(720)\n",
    "    \n",
    "    # After the generation of the different features I will add the global features (which are independend from the houses!)\n",
    "    day_type         = env.buildings[0].energy_simulation.day_type\n",
    "    hour             = env.buildings[0].energy_simulation.hour\n",
    "    carbon_intensity = env.buildings[0].carbon_intensity.carbon_intensity\n",
    "\n",
    "    # Loading the local features\n",
    "    filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "    pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "    weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "    electricity_pricing                = pricing['Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_6h   = pricing['6h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_12h  = pricing['12h Prediction Electricity Pricing [$/kWh]']\n",
    "    electricity_pricing_predicted_24h  = pricing['24h Prediction Electricity Pricing [$/kWh]']\n",
    "\n",
    "    outdoor_dry_bulb_temperature                = weather['Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_6h   = weather['6h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_12h  = weather['12h Outdoor Drybulb Temperature (C)']\n",
    "    outdoor_dry_bulb_temperature_predicted_24h  = weather['24h Outdoor Drybulb Temperature (C)']\n",
    "\n",
    "    diffuse_solar_irradiance                    = weather['Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_6h       = weather['6h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_12h      = weather['12h Diffuse Solar Radiation (W/m2)']\n",
    "    diffuse_solar_irradiance_predicted_24h      = weather['24h Diffuse Solar Radiation (W/m2)']\n",
    "\n",
    "    direct_solar_irradiance                     = weather['Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_6h        = weather['6h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_12h       = weather['12h Direct Solar Radiation (W/m2)']\n",
    "    direct_solar_irradiance_predicted_24h       = weather['24h Direct Solar Radiation (W/m2)']\n",
    "    \n",
    "    # Generate the Dataframe for the training\n",
    "    b_dataframe_list[idx]['day_type']                                   = day_type\n",
    "    b_dataframe_list[idx]['hour']                                       = hour\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature']               = outdoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_6h']  = outdoor_dry_bulb_temperature_predicted_6h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_12h'] = outdoor_dry_bulb_temperature_predicted_12h\n",
    "    b_dataframe_list[idx]['outdoor_dry_bulb_temperature_predicted_24h'] = outdoor_dry_bulb_temperature_predicted_24h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance']                   = diffuse_solar_irradiance\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_6h']      = diffuse_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_12h']     = diffuse_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['diffuse_solar_irradiance_predicted_24h']     = diffuse_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance']                    = direct_solar_irradiance\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_6h']       = direct_solar_irradiance_predicted_6h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_12h']      = direct_solar_irradiance_predicted_12h\n",
    "    b_dataframe_list[idx]['direct_solar_irradiance_predicted_24h']      = direct_solar_irradiance_predicted_24h\n",
    "    b_dataframe_list[idx]['carbon_intensity']                           = carbon_intensity\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature']                = indoor_dry_bulb_temperature\n",
    "    b_dataframe_list[idx]['non_shiftable_load']                         = non_shiftable_load\n",
    "    b_dataframe_list[idx]['solar_generation']                           = solar_generation\n",
    "    b_dataframe_list[idx]['dhw_storage_soc']                            = dhw_storage_soc\n",
    "    b_dataframe_list[idx]['electrical_storage_soc']                     = electrical_storage_soc\n",
    "    b_dataframe_list[idx]['electricity_pricing']                        = electricity_pricing\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_6h']           = electricity_pricing_predicted_6h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_12h']          = electricity_pricing_predicted_12h\n",
    "    b_dataframe_list[idx]['electricity_pricing_predicted_24h']          = electricity_pricing_predicted_24h\n",
    "    b_dataframe_list[idx]['cooling_demand']                             = cooling_demand\n",
    "    b_dataframe_list[idx]['dhw_demand']                                 = dhw_demand\n",
    "    b_dataframe_list[idx]['indoor_dry_bulb_temperature_set_point']      = indoor_dry_bulb_temperature_set_point\n",
    "    b_dataframe_list[idx]['occupant_count']                             = occupant_count\n",
    "    b_dataframe_list[idx]['net_electricity_consumption']                = net_electricity_consumption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b36edbc-8963-4cf9-853e-c087c493193c",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a402aa4b-066a-4024-806a-f07878d5f764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the important features into files\n",
    "b = 1\n",
    "for data in b_dataframe_list:\n",
    "    feature_selection(data,'cooling_demand')\n",
    "    feature_selection(data,'dhw_demand')\n",
    "    feature_selection(data,'non_shiftable_load')\n",
    "    feature_selection(data,'carbon_intensity')\n",
    "    feature_selection(data,'solar_generation')\n",
    "    b = b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc97c1a-68e1-4d74-a6e1-301ff68e91a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_selection(data,obs_feature):\n",
    "    # Split the dataset into features and target\n",
    "    X = data\n",
    "    y = data[obs_feature]\n",
    "    \n",
    "    # Apply Information Gain\n",
    "    ig = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create a dictionary of feature importance scores\n",
    "    feature_scores = {}\n",
    "    i = 0\n",
    "    for (columnName, columnData) in data.items():\n",
    "        feature_scores[columnName] = ig[i]\n",
    "        i = i + 1\n",
    "    # Sort the features by importance score in descending order\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    f_l = []\n",
    "    s_l = []\n",
    "    a_l = []\n",
    "    a_l_s = []\n",
    "    # Print the feature importance scores and the sorted features\n",
    "    for feature, score in sorted_features:\n",
    "        a_l.append(feature)\n",
    "        a_l_s.append(score)\n",
    "        if score > 0.10:\n",
    "            # save the features\n",
    "            f_l.append(feature)\n",
    "            s_l.append(score)\n",
    "            \n",
    "    dic = {'feature': f_l, 'score': s_l}\n",
    "    dic_a = {'feature': a_l, 'score': a_l_s}\n",
    "    df2 = pd.DataFrame(dic_a)\n",
    "    df = pd.DataFrame(dic)\n",
    "    df.to_csv('data/features/feature_importance_'+str(obs_feature)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae84e00c-1958-4f58-9c60-8de58a0e39e4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Train the Predictors (LightGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b41fd673-11e2-4f20-a660-fb36934ccd2c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'fusion'\n",
    "hyperparameter = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d0382c-bd19-474a-b753-fa3e54dbeb9f",
   "metadata": {},
   "source": [
    "## Building Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7a8265-0e7c-4c65-836c-6bb7a55701e1",
   "metadata": {},
   "source": [
    "### 1.) Cooling Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da7752-a409-4bf3-a5ed-fc0d82380079",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    print(\"Building Model!\")\n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'cooling_demand')\n",
    "        joblib.dump(xgb, 'my_models/models/cooling_demand_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'cooling_demand')\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_demand_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'cooling_demand')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'cooling_demand')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/cooling_demand_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/cooling_demand_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'cooling_demand',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/cooling_demand_model_b'+str(i)+'.pkl')\n",
    "\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a5d417-bec7-49b8-8f1a-2b30b199bbf1",
   "metadata": {},
   "source": [
    "### 2.) DHW Load (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2291829-e34d-491d-a21f-9f6b8c981d10",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'dhw_demand')\n",
    "        joblib.dump(xgb, 'my_models/models/dhw_demand_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'dhw_demand')\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_demand_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'dhw_demand')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'dhw_demand')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/dhw_demand_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/dhw_demand_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'dhw_demand',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/dhw_demand_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f10a61-a65d-4a70-ad5f-01f02f0a2049",
   "metadata": {},
   "source": [
    "### 3.) Equipment Electric Power (kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ecb764-a3e2-4266-a1ae-1da596ce021f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        joblib.dump(xgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_new_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_new_2_hyper.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'non_shiftable_load')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/Equipment_Electric_Power_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/Equipment_Electric_Power_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'non_shiftable_load',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/Equipment_Electric_Power_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5143b8-6eb1-424a-975f-434b42934d7c",
   "metadata": {},
   "source": [
    "# Neighbourhood Level Predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b6668b0-ba09-47d6-84f6-a4b392d12377",
   "metadata": {},
   "source": [
    "### 1.) Carbon Intensity (kgCO2e/kWh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836e4946-9e37-4a24-83a7-9ea2b756110e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_dataframe_list[0].reset_index(drop=True),\n",
    "                  b_dataframe_list[1].reset_index(drop=True),\n",
    "                  b_dataframe_list[2].reset_index(drop=True)])\n",
    "    \n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    xgb = XGBoost_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    joblib.dump(xgb, 'my_models/models/Carbon_Intensity_Power_model_xgb.pkl')\n",
    "if model_type == 'lgb':\n",
    "    lgb = LightGBM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_lightgbm.pkl')\n",
    "if model_type == 'fusion':\n",
    "    lgb_model  = LightGBM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "    lstm_model = LSTM_Model(comb,hyperparameter,'carbon_intensity')\n",
    "        \n",
    "    joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/Carbon_Intensity_model_2.pkl')\n",
    "    joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/Carbon_Intensity_model_2.pkl')\n",
    "\n",
    "    #fusion_model = Fusion_Model(b,hyperparameter,'carbon_intensity',lstm_model,lgb_model)\n",
    "    #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/Carbon_Intensity_model'+str(i)+'.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b99ab8e-9d57-4554-96b5-6f69cc0041f3",
   "metadata": {},
   "source": [
    "### 2.) Solar Generation (W/kW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d128e16-9ebc-4318-864e-53f440826011",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "for b in b_dataframe_list:\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        xgb = XGBoost_Model(b,hyperparameter,'solar_generation')\n",
    "        joblib.dump(xgb, 'my_models/models/solar_generation_model_b'+str(i)+'_xgb.pkl')\n",
    "    if model_type == 'lgb':\n",
    "        lgb = LightGBM_Model(b,hyperparameter,'solar_generation')\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_lightgbm.pkl')\n",
    "    if model_type == 'fusion':\n",
    "        lgb_model  = LightGBM_Model(b,hyperparameter,'solar_generation')\n",
    "        lstm_model = LSTM_Model(b,hyperparameter,'solar_generation')\n",
    "        \n",
    "        joblib.dump(lgb_model, 'my_models/models/fusion/LightGBM/solar_generation_model_b'+str(i)+'_2.pkl')\n",
    "        joblib.dump(lstm_model, 'my_models/models/fusion/LSTM/solar_generation_model_b'+str(i)+'_2.pkl')\n",
    "        \n",
    "        #fusion_model = Fusion_Model(b,hyperparameter,'solar_generation',lstm_model,lgb_model)\n",
    "        #joblib.dump(fusion_model, 'my_models/models/fusion/Fusion/solar_generation_model_b'+str(i)+'.pkl')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302ab787-e32b-46d3-85ae-62dac941cd32",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e126c5a-4598-475a-a22b-001c1d1da927",
   "metadata": {},
   "source": [
    "### LightGBM Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2dbe62f7-aa7c-4b50-88d1-7911ef439a74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LightGBM_Model(b,hpt,feature):\n",
    "\n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_cooling_demand.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        # Create an AdaBoost model with LightGBM as the base estimator\n",
    "        #adaboost_model = AdaBoostRegressor(base_estimator=grid_search_mean, n_estimators=50)\n",
    "        #adaboost_model.fit(X_train, y_train)\n",
    "        \n",
    "        print(\"Done!\")\n",
    "        return grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        'verbose':-1,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        # Create an AdaBoost model with LightGBM as the base estimator\n",
    "        #adaboost_model = AdaBoostRegressor(base_estimator=gbm, n_estimators=50)\n",
    "        #adaboost_model.fit(X_train, y_train)\n",
    "\n",
    "        return gbm#adaboost_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a4eb7-7354-489d-9be9-5b96f581b0f7",
   "metadata": {},
   "source": [
    "### XGBoost Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9c1069a8-60aa-44ec-9c7f-dbd6588ecb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def XGBoost_Model(b,hpt,feature):\n",
    "    \n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_'+str(feature)+'.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    reg = XGBRegressor(n_estimators=100)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50)\n",
    "\n",
    "    return reg\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0578c-a0d3-4710-85aa-10d0fe5b25f4",
   "metadata": {},
   "source": [
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96430fdc-557d-4e7f-9995-3c6ad418da3c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LSTM_Model(b,hpt,feature):\n",
    "\n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_cooling_demand.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    # Reshape data for LSTM input (samples, sequence_length, num_features)\n",
    "    X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(units=1))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Use early stopping to prevent overfitting\n",
    "    #early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "\n",
    "    model.fit(X_train, y_train, epochs=1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3293d557-b44e-41e5-8811-cb148cec1387",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class CustomKerasRegressor(BaseEstimator, RegressorMixin):\n",
    "    def __init__(self, build_fn, input_shape, **kwargs):\n",
    "        self.build_fn = build_fn\n",
    "        self.input_shape = input_shape\n",
    "        self.kwargs = kwargs\n",
    "        self.estimator = KerasRegressor(build_fn=self.build_fn, **self.kwargs)\n",
    "\n",
    "    def fit(self, X, y, **fit_params):\n",
    "        # Reshape input data for LSTM (if necessary)\n",
    "        if X.ndim == 2:\n",
    "            X = np.reshape(X, (X.shape[0], self.input_shape[0], self.input_shape[1]))\n",
    "        self.estimator.fit(X, y, **fit_params)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Reshape input data for LSTM (if necessary)\n",
    "        if X.ndim == 2:\n",
    "            X = np.reshape(X, (X.shape[0], self.input_shape[0], self.input_shape[1]))\n",
    "        # Get predictions\n",
    "        predictions = self.estimator.predict(X)\n",
    "        # Reshape predictions back to 2D array\n",
    "        predictions = np.reshape(predictions, (-1, 1))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94e87328-a232-416b-969f-82bdd4b76576",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_lstm_model(learning_rate=0.001, units=50, dropout_rate=0.0):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=units, input_shape=(1, num_features)))\n",
    "    model.add(Dense(units=1))\n",
    "    optimizer = Adam(learning_rate=learning_rate)\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f65ec4e1-134d-4d0c-b2e5-8b87c4c55dae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a function that returns the LSTM model\n",
    "def create_lstm_model(input_shape):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    model.add(LSTM(units=50, return_sequences=True))\n",
    "    model.add(LSTM(units=50))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "024ea8fa-812f-4f1e-b0c0-ae8886e8c379",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def Fusion_Model(b,hpt,feature,lstm_model,lightgbm_model):\n",
    "    \n",
    "    # Load the feature selection\n",
    "    f_l = pd.read_csv('data/features/feature_importance_'+str(feature)+'.csv')\n",
    "    \n",
    "    \n",
    "    # Generate the x,y\n",
    "    features = b#[f_l['feature']]\n",
    "    target   = b[feature]\n",
    "\n",
    "    \n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42, shuffle=False)\n",
    "    \n",
    "    X_train = np.reshape(X_train.values, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "    X_test = np.reshape(X_test.values, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "    \n",
    "    # Create an ensemble model using VotingRegressor\n",
    "    ensemble_model = VotingRegressor(estimators=[('lstm', lstm_model), ('lgbm', lightgbm_model)])\n",
    "    ensemble_model.fit(X_train, y_train)\n",
    "    \n",
    "    return ensemble_model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b38e0e-c673-41fe-8a97-b1890cc25c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a6c123-ac24-4957-b317-74a0d5ec6731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5ce45e-3ec4-4765-a8da-5568a4e5aabf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2f4244-379d-4021-bd9a-dd69ce80ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9ba147-6d10-4b20-8cb5-56cb16f6cc30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560235de-5577-4919-bdf6-1021ef6f79e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b85efd-8c1a-43bb-82a3-9d1ca6e195fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddc2b52-6236-4670-89da-86023cbed3b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52cb36f-9613-48eb-90be-cffe73c682b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0fd6a-fc08-4de4-9682-9cc373d5a018",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5fa69f-e93f-427d-bee1-d415a68da321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0725c757-8501-4b1e-b9cc-b9e71372a9ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a0a531-5522-4c3a-a99f-fb61b9d50d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
