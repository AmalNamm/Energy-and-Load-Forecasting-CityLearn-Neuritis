{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f69be91b-2ff3-415d-9d3f-ee5d8afdac1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightgbm -q\n",
    "!pip install category_encoders -q\n",
    "!pip install xgboost -q\n",
    "!pip install timeseries-fastai -q\n",
    "!pip install pandas\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import category_encoders as ce\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import re\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from joblib import dump, load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ade4be24-7052-4988-9ff4-6dd4d1219f71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3deeacf-a80e-4852-b991-bc7ece7c833e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaaaa4c5-871d-4a4d-bab0-4b18ac8f4f98",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Loading the Datasets\n",
    "filepath = 'data/schemas/warm_up/'\n",
    "\n",
    "# Building information\n",
    "b_1 = pd.read_csv(filepath + 'Building_1.csv')\n",
    "b_2 = pd.read_csv(filepath + 'Building_2.csv')\n",
    "b_3 = pd.read_csv(filepath + 'Building_3.csv')\n",
    "\n",
    "# Other information\n",
    "carbon_int = pd.read_csv(filepath + 'carbon_intensity.csv')\n",
    "pricing    = pd.read_csv(filepath + 'pricing.csv')\n",
    "weather    = pd.read_csv(filepath + 'weather.csv')\n",
    "\n",
    "# Building level combine the dfs\n",
    "comb_b_1 = pd.concat([b_1.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_2 = pd.concat([b_2.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "comb_b_3 = pd.concat([b_3.reset_index(drop=True),\n",
    "                      carbon_int.reset_index(drop=True),\n",
    "                      pricing.reset_index(drop=True),\n",
    "                      weather.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Make a list of the buildings\n",
    "b_list = [comb_b_1,comb_b_2,comb_b_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9375f433-049f-4bef-bd38-7f04176885c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check if the dataframes contain inf\n",
    "\n",
    "# Building 1\n",
    "d = np.isfinite(comb_b_1) \n",
    "\n",
    "# Building 2\n",
    "d = np.isfinite(comb_b_2) \n",
    "\n",
    "\n",
    "# Building 3\n",
    "d = np.isfinite(comb_b_3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e86ddbdb-0110-437c-ac53-65d2eddc65de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fix the titles\n",
    "b_list_clear = []\n",
    "\n",
    "for b in b_list:\n",
    "    regex = re.compile(r\"\\[|\\]|<\", re.IGNORECASE)\n",
    "    b.columns = [regex.sub(\"_\", col) if any(x in str(col) for x in set(('[', ']', '<'))) else col for col in b.columns.values]\n",
    "    b_list_clear.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7414601-9b7a-4173-b2d9-e0ffc395c892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e3c530e-34c0-4a9e-ac13-f4f78e2c18af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGBoost Models\n",
    "\n",
    "def XGBoost_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    reg = XGBRegressor(n_estimators=1000)\n",
    "    reg.fit(X_train, y_train,\n",
    "            eval_set=[(X_train, y_train), (X_test, y_test)],\n",
    "            early_stopping_rounds=50,\n",
    "           verbose=False)\n",
    "     \n",
    "    y_pred  = reg.predict(X_test)\n",
    "    \n",
    "    # Generate the df\n",
    "    df = pd.DataFrame(\n",
    "        {'Actual Value': y_test,\n",
    "        'Predicted Value': y_pred\n",
    "        })\n",
    "\n",
    "    return df, reg\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a84c794-ae07-4b51-9b8c-5c6722394b82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LightGBM Models\n",
    "\n",
    "# Generating the LightGBM\n",
    "\n",
    "def LightGBM_Model(X_train, X_test, y_train, y_test,hpt):\n",
    "\n",
    "    if hpt == True:\n",
    "        params = {\n",
    "            'max_depth':        [3, 4, 5],\n",
    "            'num_leaves':       [10, 15, 20],\n",
    "            'learning_rate':    [0.05, 0.1, 0.15],\n",
    "            'n_estimators':     [50, 100, 200],\n",
    "            'subsample':        [0.5, 0.7, 0.9],\n",
    "            'colsample_bytree': [0.5, 0.7, 0.9],\n",
    "            'reg_alpha':        [0.01, 0.1, 1],\n",
    "            'reg_lambda':       [0.01, 0.1, 1],\n",
    "            'verbose':[-1]\n",
    "        }\n",
    "    \n",
    "        lgb_mean = LGBMRegressor(boosting_type='gbdt', objective='regression')\n",
    "        grid_search_mean = GridSearchCV(lgb_mean, params, cv=5, n_jobs=-1)\n",
    "        grid_search_mean.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred_mean  = grid_search_mean.predict(X_test)\n",
    "    \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred_mean\n",
    "            })\n",
    "     \n",
    "        return df, grid_search_mean\n",
    "    \n",
    "    \n",
    "    else:\n",
    "        lgb_params = {\n",
    "        'n_jobs': 1,\n",
    "        'max_depth': 4,\n",
    "        'min_data_in_leaf': 10,\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'subsample': 0.9,\n",
    "        'n_estimators': 80,\n",
    "        'learning_rate': 0.1,\n",
    "        'colsample_bytree': 0.9,\n",
    "        'steps':48,\n",
    "        }\n",
    "        \n",
    "        # fitting the model\n",
    "        gbm = LGBMRegressor(**lgb_params)\n",
    "        gbm.fit(X_train, y_train)\n",
    "        \n",
    "        y_pred = gbm.predict(X_test)\n",
    "        \n",
    "        # Generate the df\n",
    "        df = pd.DataFrame(\n",
    "            {'Actual Value': y_test,\n",
    "             'Predicted Value': y_pred\n",
    "            })\n",
    "     \n",
    "        return df, gbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f207434d-97f7-4cd8-bda9-238301ce8514",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_type = 'lgb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "429e4788-f351-4756-a93f-7829aaebe1b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 1.) Cooling Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Cooling_Load__kWh_.csv')\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Cooling Load (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/cooling_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/cooling_load_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/cooling_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e27452a-1127-41fc-a893-6c5d95c34309",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 2.) DHW Load (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['DHW Heating (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/dhw_load_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/dhw_load_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/dhw_load_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14a83cc-268d-4cb1-9877-775741ed0c68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Equipment Electric Power (kWh)\n",
    "i = 1\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Generate the x,y\n",
    "    X = b\n",
    "    y = b['Equipment Electric Power (kWh)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/Equipment_Electric_Power_model_b'+str(i)+'_hyper.txt')\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2834e4-4804-489c-a3d6-af83d8d552e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Neighbour Level: Carbon Intensity (kgCO2e/kWh) ; Solar Generation (W/kW)\n",
    "\n",
    "# 1.) Carbon Intensity (kgCO2e/kWh)\n",
    "# combine the datasets to one since we only have one CI \n",
    "comb = pd.concat([b_list_clear[0].reset_index(drop=True),\n",
    "                  b_list_clear[1].reset_index(drop=True),\n",
    "                  b_list_clear[2].reset_index(drop=True)])\n",
    "    \n",
    "# Generate the x,y\n",
    "X = comb\n",
    "y = comb['kg_CO2/kWh']\n",
    "\n",
    "# Generate the test,train \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "\n",
    "    \n",
    "if model_type == 'xgb':\n",
    "    df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "    xgb.save_model('my_models/models/Carbon_Intensity_Power_model'+str(i)+'.json')\n",
    "if model_type == 'lgb':\n",
    "    df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "    joblib.dump(lgb, 'my_models/models/Carbon_Intensity_Power_model_hyper.pkl')\n",
    "    #lgb.booster_.save_model('my_models/models/Carbon_Intensity_Power_model_hyper.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97252705-78b9-47eb-9f8c-9d43ea70974a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 3.) Solar Generation (W/kW)\n",
    "sg = []\n",
    "i = 1\n",
    "\n",
    "for b in b_list_clear:\n",
    "    \n",
    "    # Load the feature importance\n",
    "    f_l = pd.read_csv('data/features/feature_importance_Solar_Generation__W_kW_.csv')\n",
    "\n",
    "    # Generate the x,y\n",
    "    X = b[f_l['feature']]\n",
    "    y = b['Solar Generation (W/kW)']\n",
    "\n",
    "    # Generate the test,train \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, shuffle=False)\n",
    "    \n",
    "    if model_type == 'xgb':\n",
    "        df, xgb = XGBoost_Model(X_train, X_test, y_train, y_test,False)\n",
    "        xgb.save_model('my_models/models/solar_generation_model_b'+str(i)+'.json')\n",
    "    if model_type == 'lgb':\n",
    "        df, lgb = LightGBM_Model(X_train, X_test, y_train, y_test,True)\n",
    "        joblib.dump(lgb, 'my_models/models/solar_generation_model_b'+str(i)+'_hyper.pkl')\n",
    "        #lgb.booster_.save_model('my_models/models/solar_generation_model_b'+str(i)+'_hyper.txt')\n",
    "        \n",
    "    sg.append(df)\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f803d1-2147-441d-b81e-e6ba3d3eb6e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0602038-da7f-431b-953b-1bb651df694d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530a9782-0f28-4740-9d24-b77843561a58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "af8db2cc-8054-4ea2-8220-43de2b430118",
   "metadata": {},
   "source": [
    "### FastAI Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d1e86d-7f6e-4785-b153-8e2076cd67ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from timeseries_fastai.imports import *\n",
    "from timeseries_fastai.core import *\n",
    "from timeseries_fastai.data import *\n",
    "from timeseries_fastai.models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ccaa2e8a-9daa-49f7-9d8b-09c75569eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading files from: /home/philaupk/work/CityLearn_Competition/Adiac\n",
      "Error loading files: /home/philaupk/work/CityLearn_Competition/Adiac\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m PATH \u001b[38;5;241m=\u001b[39m Path\u001b[38;5;241m.\u001b[39mcwd()\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m----> 2\u001b[0m df_train, df_test \u001b[38;5;241m=\u001b[39m load_df_ucr(PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAdiac\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m x_cols \u001b[38;5;241m=\u001b[39m df_train\u001b[38;5;241m.\u001b[39mcolumns[\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\u001b[38;5;241m.\u001b[39mto_list()\n\u001b[1;32m      4\u001b[0m dls \u001b[38;5;241m=\u001b[39m TSDataLoaders\u001b[38;5;241m.\u001b[39mfrom_dfs(df_train, df_test, x_cols\u001b[38;5;241m=\u001b[39mx_cols, label_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m, bs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "PATH = Path.cwd().parent\n",
    "df_train, df_test = load_df_ucr(PATH, 'Adiac')\n",
    "x_cols = df_train.columns[0:-2].to_list()\n",
    "dls = TSDataLoaders.from_dfs(df_train, df_test, x_cols=x_cols, label_col='target', bs=16)\n",
    "dls.show_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3bc490-672a-43ce-b598-361aa5c0211b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inception = create_inception(1, len(dls.vocab))\n",
    "learn = Learner(dls, inception, metrics=[accuracy])\n",
    "learn.fit_one_cycle(1, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dce875-c3b2-4d0b-8b88-c7a87fec0376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35919da4-085e-44d0-b2f9-1b6f3d1bf51a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5842d6-363b-443a-ad1c-cc973ad2b05a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f397b1b9-30db-4028-ba4b-dea174caa9d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337a0d31-ec58-4b17-acdc-d2dc49df840f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e06583-710d-4df3-9965-ec642b22c929",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7e28d1-5254-4e21-b7c4-7fb38d71a49f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe233854-bf7d-4a80-bfed-81810000b20e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73419dd6-584b-4e11-8484-0d6ff286ab62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133af48f-cc40-4dec-b919-0d7a9a270b99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74af4548-880e-487b-a639-d613ba14caa1",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba062f91-4daa-4f65-ad4a-b028f0f7030e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "\n",
    "# Save the important features into files\n",
    "b = 1\n",
    "for data in b_list_clear:\n",
    "    feature_selection(data,'Cooling Load (kWh)')\n",
    "    feature_selection(data,'DHW Heating (kWh)')\n",
    "    feature_selection(data,'Equipment Electric Power (kWh)')\n",
    "    feature_selection(data,'kg_CO2/kWh')\n",
    "    feature_selection(data,'Solar Generation (W/kW)')\n",
    "    b = b + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b74d9ad-c656-4b1a-be5e-edfaf2842d2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_selection(data,obs_feature):\n",
    "    # Split the dataset into features and target\n",
    "    X = data\n",
    "    y = data[obs_feature]\n",
    "    \n",
    "    # Apply Information Gain\n",
    "    ig = mutual_info_regression(X, y)\n",
    "\n",
    "    # Create a dictionary of feature importance scores\n",
    "    feature_scores = {}\n",
    "    i = 0\n",
    "    for (columnName, columnData) in data.iteritems():\n",
    "        feature_scores[columnName] = ig[i]\n",
    "        i = i + 1\n",
    "    # Sort the features by importance score in descending order\n",
    "    sorted_features = sorted(feature_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    f_l = []\n",
    "    s_l = []\n",
    "    # Print the feature importance scores and the sorted features\n",
    "    for feature, score in sorted_features:\n",
    "        if score > 0.10:\n",
    "            # save the features\n",
    "            f_l.append(feature)\n",
    "            s_l.append(score)\n",
    "            \n",
    "    dic = {'feature': f_l, 'score': s_l}\n",
    "    df = pd.DataFrame(dic)\n",
    "    obs_feature = obs_feature.replace(\" \", \"_\")\n",
    "    obs_feature = obs_feature.replace(\")\", \"_\")\n",
    "    obs_feature = obs_feature.replace(\"(\", \"_\")\n",
    "    obs_feature = obs_feature.replace(\"/\", \"_\")\n",
    "    df.to_csv('data/features/feature_importance_'+str(obs_feature)+'.csv')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a8f249-46ad-40a5-a2c1-d9224ff76963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
